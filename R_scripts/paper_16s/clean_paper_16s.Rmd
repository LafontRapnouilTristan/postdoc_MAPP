---
title: "R Notebook"
output: html_document
---

# Intro

The aim of this paper is to investigate microbial communities from northern Peatlands by mean of 16s Metabarcoding.
This investigation is both Taxonomic and Functional.

For about 200 hundred samples from the northern hemisphere we have:

- *Communities info*:  
    * Metabarcoding (16s - bacteria/archae)  
    * Bacteria and photoautotrophs abundances (cytometry)  
    * Enzyme activity (C, N and P cycles; 4 enzymes)  
- *Site bioclimatic data*:  
    * Coordinates  
    * Google Earth Engine (GEE) data  
    

## Metabarcoding

Raw sequencing output (ILLUMINA) were uploaded to Galaxy Toulouse server to be processed using FROGS 4.1 bioinformatic pipeline available on the platform.

### FROGS pipeline

#### I - Preprocess

**Sequencer**: ILLUMINA  
**Input type**: .TAR archive  
**File**: .TAR archive with \*R1.fastq.gz and \*R2.fastq.gz for each sample  
**Merged reads**: NO  
*Read 1 &2 size*: 250  
**Mismatch rate**: 0.1  
**Merge software**: Vsearch  
**Keep unmerged**: NO  
**Amplicon size**: min 200 - max 490  
**Primers**: YES  
**5'**: Forward primer sequence (GTGYCAGCMGCCGCGGT)  
**3'**: Reversed & complemented (ACTYAAAKGAATTGRCGGGG) (online: https://reverse-complement.com/)  

#### II - Clustering Swarm

With fastidious method & d=1 : effectively ASVs

**Aggregation distance**: 1  
**Refine clustering**: YES


#### III - Remove chimera


#### IV - Cluster Filtering

**Minimum prevalence**: NA  
**Minimum proportion/count**: 2  -- Remove rare (proportion) or ASVs with less than X sequences (X=2 => remove singletons)  
**Search contaminant**: On server PhiX database

#### V - Taxonomic Affiliation

Chose ref db (SILVA or Âµgreen)
Ask for RDP classifier too!


**Blast metrics**:

- **Query Coverage**: Percent of the query sequence length that is included in alignments against the sequence match.

- **E-value**: Indicates the number of hits or alignments that are expected to be seen by random chance with the same score or better. 
The lower the E-value, the more significant the alignment (the closer to 0, the better).
E-value is the default metric used to sort the Descriptions table. 

- **Percent Identity**: Percent of nucleotides or amino acids that are identical between the aligned query and database sequences. 
A query sequence can share low percent identity with a sequence and still be a significant hit. 
It is essential to take the E-value into account and look for similarity between conserved regions (this will be more evident at the amino acid level).


#### VI - Postprocess

NOT filtering assignation within FROGS
Produce assignation stats
Convert .BIOM to .TSV and give a sequence file to keep sequence info!! (More universal format even tho .BIOM is loadable into R for further analysis)

### FROGS Picrust2

[Picrust 2](https://huttenhower.sph.harvard.edu/picrust/) or Phylogenetic Investigation of Communities by Reconstruction of Unobserved States is a software for predicting functional abundances based only on marker gene sequences.

It allows for functional characterization of your microbial communities from 16s metabarcoding data.
We ran Picrust 2 from within the Galaxy Toulouse platform with their pipeline names FROGSFUNC.
The process is divided in three steps that we'll describe briefly but first we aggregate ASVs based on their similarity ,shared taxonomy and sequence coverage.
This step is named FROGS affiliation postprocess on Galaxy Toulouse.

#### Affiliation Postprocess

**Input**: FASTA file containing our sequence and BIOM file with ASVs abundance and taxonomy.  
**Is this amplicon hyper variable length**: NO
**Minimum Identity**: ASVs will be aggregated if they share the same taxonomy AND with at least X% identity. We chose X = 99.  
**Minimum Coverage**: ASVs will be aggregated if they share the same taxonomy AND with at least X% alignment coverage. We chose X = 99.  

#### I - Place sequence and copy numbers

It is the first step of PICRUSt2.
It inserts your study sequences into a reference tree.
By default, this reference tree is based on 20,000 16S sequences from genomes in the Integrated Microbial Genomes database.
The script performs this step, which specifically:
    * Aligns your study sequences with a multiple-sequence alignment of reference 16S, ITS or 18S sequences with HMMER.
    * Finds the most likely placements of your study sequences in the reference tree with EPA_NG or SEPP.
    * Produces a treefile with the most likely placement for each sequence as the new tips with GAPPA.
    * Predicts marker copy number based solely on the sequences of marker genes with PICRUSt2. The available marker genes are 16S, ITS and 18S.


**Input**: FASTA sequence file and BIOM file with ASVs abundance and taxonomy
**Taxonomy marker**: 16s  
**Placement Tool**: epa-ng
**Minimum alignment length**: 0.8 - Proportion of total length of an iput sequence that must align with reference sequences.
All other will be out.

#### II - Calculate Function abundance

It is the second step of PICRUSt2. It ables to predicts :
    * Functional abundances based solely on the sequences of marker genes with PICRUSt2. The available marker genes are 16S, ITS and 18S.
    * Functions, weighted by the relative abundance of ASVs in the community. Inferring the metagenomes of the communities with PICRUSt2.

There are three steps performed at this stage:
    * It runs hidden-state prediction (hsp) to predict function abundances with castor-R of each ASVs placed in the PICRUSt2 reference phylogenetic tree (FROGSFUNC_1_placeseqs_copynumber outputs).
    * The read depth per ASV is divided by the predicted marker (16S/ITS/18S) copy numbers. This is performed to help control for variation in marker copy numbers across organisms, which can result in interpretation issues. For instance, imagine an organism with five identical copies of the 16S gene that is at the same absolute abundance as an organism with one 16S gene. The ASV corresponding to the first organism would erroneously be inferred to be at higher relative abundance simply because this organism had more copies of the 16S gene.
    * The ASV read depths per sample (after normalizing by marker (16S/ITS/18S) copy number) are multiplied by the predicted function copy numbers per ASV.

**Input**: BIOM and FASTA files + TREE file (.nwk) and the MARKER file (.tsv) containing the copy number of the marker produced by the previous step.  
**Taxonomic marker**: 16s  
**Target function database**: EC & KO 
**NTSI cut-off**: 2 - Any sequence with NTSI > 2 is discarded. Nearest Sequenced Taxon Index (NSTI) is the phylogenetic distance between the ASV and the nearest sequenced reference genome. 
**Identity alignment cut_off**: 80 - Any sequence below this identity threshold agaisnt reference will be discarded.
**Coverage cut-off**: 80 - Same with coverage.
**HSP method**: mp - Hidden state prediction method used. We stick with the maximum parsimony default.

#### III - Calculate Pathways abundance

It is the last step of PICRUSt2. This script infers MetaCyc/KEGG pathway abundances based on EC or KO number abundances.
    * Regroups EC or KO numbers to MetaCyc or KEGG reactions, depending of the unstrat abundances input file.
    * Infers which MetaCyc or KEGG pathways are present based on these reactions with MinPath.
    * Calculates and returns the abundance of pathways identified as present.

Run twice, once for MetaCyc and once for KEGG.
 
 **Input**: TSV file with function abundance prediction from step II (EC - metacyc and KO - kegg).
 **Taxonomic marker**: 16s
 **Pathway reference**: MetaCyc and then Kegg according to the input file (EC - metacyc and KO - kegg).

# -----------------------------------
# -----------------------------------
# -----------------------------------

# A -  Load Packages & custom function

```{r}
EcophyCofog::Library(c("EcophyCofog","metabaR","readr","dplyr","magrittr","ggplot2","reshape2","patchwork","ggpubr","tidyr","forcats","phyloseq","cowplot","readxl","microeco","file2meco","RColorBrewer","vegan","sf","rnaturalearth","rnaturalearthdata","dendextend","GGally","ggvegan"))
```

```{r}
createAngleHJustCols <- function(labeldf) {        
    nn <- length(labeldf$y)
    halfn <- floor(nn/2)
    firsthalf <- rev(90 + seq(0,360, length.out = nn))
    secondhalf <- rev(-90 + seq(0,360, length.out = nn))
    angle <- numeric(nn)
    angle[1:halfn] <- firsthalf[1:halfn]
    angle[(halfn+1):nn] <- secondhalf[(halfn+1):nn]

    hjust <- numeric(nn)
    hjust[1:halfn] <- 0
    hjust[(halfn+1):nn] <- 1

    return(list(angle = angle, hjust = hjust))
}


fviz_nbclust_fixed <- function (x, FUNcluster = NULL, method = c("silhouette", "wss", 
    "gap_stat"), diss = NULL, k.max = 10, nboot = 100, verbose = interactive(), 
    barfill = "steelblue", barcolor = "steelblue", linecolor = "steelblue", 
    print.summary = TRUE, ...) 
{
    set.seed(123)
    if (k.max < 2) 
        stop("k.max must bet > = 2")
    method = match.arg(method)
    if (!inherits(x, c("data.frame", "matrix")) & !("Best.nc" %in% 
        names(x))) 
        stop("x should be an object of class matrix/data.frame or ", 
            "an object created by the function NbClust() [NbClust package].")
    if (inherits(x, "list") & "Best.nc" %in% names(x)) {
        best_nc <- x$Best.nc
        if (any(class(nb$Best.nc) == "numeric")) 
            print(best_nc)
        else if (any(class(nb$Best.nc) == "matrix")) 
            .viz_NbClust(x, print.summary, barfill, barcolor)
    }
    else if (is.null(FUNcluster)) 
        stop("The argument FUNcluster is required. ", "Possible values are kmeans, pam, hcut, clara, ...")
    else if (!is.function(FUNcluster)) {
        stop("The argument FUNcluster should be a function. ", 
            "Check if you're not overriding the specified function name somewhere.")
    }
    else if (method %in% c("silhouette", "wss")) {
        if (is.data.frame(x)) 
            x <- as.matrix(x)
        if (is.null(diss)) 
            diss <- stats::dist(x)
        v <- rep(0, k.max)
        if (method == "silhouette") {
            for (i in 2:k.max) {
                clust <- FUNcluster(x, i, ...)
                v[i] <- .get_ave_sil_width(diss, clust$cluster)
            }
        }
        else if (method == "wss") {
            for (i in 1:k.max) {
                clust <- FUNcluster(x, i, ...)
                v[i] <- .get_withinSS(diss, clust$cluster)
            }
        }
        df <- data.frame(clusters = as.factor(1:k.max), y = v, 
            stringsAsFactors = TRUE)
        ylab <- "Total Within Sum of Square"
        if (method == "silhouette") 
            ylab <- "Average silhouette width"
        p <- ggpubr::ggline(df, x = "clusters", y = "y", group = 1, 
            color = linecolor, ylab = ylab, xlab = "Number of clusters k", 
            main = "Optimal number of clusters")
        if (method == "silhouette") 
            p <- p + geom_vline(xintercept = which.max(v), linetype = 2, 
                color = linecolor)
        return(p)
    }
    else if (method == "gap_stat") {
        extra_args <- list(...)
        gap_stat <- cluster::clusGap(x, FUNcluster, K.max = k.max, 
            B = nboot, verbose = verbose, ...)
        if (!is.null(extra_args$maxSE)) 
            maxSE <- extra_args$maxSE
        else maxSE <- list(method = "firstSEmax", SE.factor = 1)
        p <- fviz_gap_stat(gap_stat, linecolor = linecolor, 
            maxSE = maxSE)
        return(p)
    }
}



.viz_NbClust <- function(x, print.summary = TRUE,
                         barfill = "steelblue", barcolor = "steelblue")
  {
     best_nc <- x$Best.nc
    if(any(class(best_nc) == "numeric")) print(best_nc)
     else if(any(class(best_nc) == "matrix")){
    best_nc <- as.data.frame(t(best_nc), stringsAsFactors = TRUE)
    best_nc$Number_clusters <- as.factor(best_nc$Number_clusters)
    
    # Summary
    if(print.summary){
      ss <- summary(best_nc$Number_clusters)
      cat ("Among all indices: \n===================\n")
      for(i in 1 :length(ss)){
        cat("*", ss[i], "proposed ", names(ss)[i], "as the best number of clusters\n" )
      }
      cat("\nConclusion\n=========================\n")
      cat("* According to the majority rule, the best number of clusters is ",
          names(which.max(ss)),  ".\n\n")
    }
    df <- data.frame(Number_clusters = names(ss), freq = ss, stringsAsFactors = TRUE )
    p <- ggpubr::ggbarplot(df,  x = "Number_clusters", y = "freq", fill = barfill, color = barcolor)+
      labs(x = "Number of clusters k", y = "Frequency among all indices",
           title = paste0("Optimal number of clusters - k = ", names(which.max(ss)) ))
    
    return(p)
  }
}





agg.table.taxo <- function(tab, tax.lvl="genus", tax.table) {
  tax.table <- tax.table[match(rownames(tab),
                               rownames(tax.table)),]
  message(paste('Table aggregation to the', tax.lvl, "level."))
  #message('Please be sure that the ASV/OTU table and the taxonomy table are ordered the same way')
  if(nrow(tab) != nrow(tax.table)) stop("The ASV/OTU table and the taxonomy table do not have the same number of rows")
  tax <- tax.table[,grep(tax.lvl, colnames(tax.table), ignore.case = T)]
  tax[is.na(tax)] <- "Unknown"
  tab <- aggregate(tab, by=list("taxo"=tax), FUN=sum)
  rownames(tab) <- tab[,1]  
  tab <- tab[,-1]
  return(tab)
}

get_density <- function(x, y, ...) {
  dens <- MASS::kde2d(x, y, ...)
  ix <- findInterval(x, dens$x)
  iy <- findInterval(y, dens$y)
  ii <- cbind(ix, iy)
  return(dens$z[ii])
}
```

# B - MetabaR Processing

## prepare metabarlist

```{r}
data_temp <- read_delim(file = "frogs_input/Galaxy169-[FROGS_BIOM_to_TSV__abundance.tsv].tsv", # read the tsv file
                        delim = "\t", escape_double = FALSE, 
                        trim_ws = TRUE)

reads_frame <- t(as.matrix(data_temp[,colnames(data_temp)[grepl("L001",colnames(data_temp))]])) # extract site per asvs reads count matrix
colnames(reads_frame) <- data_temp$observation_name #set colnames as cluster ID (asv 'names')


motus_frame <- data_temp[,colnames(data_temp)[!grepl("L001",colnames(data_temp))]] # extract asv information (taxonomy, counts etc)


motus_frame %<>% dplyr::rename(sequence=seed_sequence) # rename seed_sequence columns to sequence
motus_frame %<>% mutate(rdp_tax_and_bootstrap=gsub("\\(|\\)|;$","",rdp_tax_and_bootstrap,perl=T))

motus_frame %<>% mutate(blast_taxonomy=ifelse(blast_taxonomy=="no data","k__;p__;c__;o__;f__;g__;s__",blast_taxonomy))
motus_frame %<>% separate(rdp_tax_and_bootstrap,
                          into=c("Kingdom","boots_Kingdom",
                                 "Phylum","boots_Phylum",
                                 "Class","boots_Class",
                                 "Order","boots_Order",
                                 "Family","boots_Family",
                                 "Genus","boots_Genus",
                                 "Species","boots_Species"),
                          sep=";",
                          remove = F)%>%
    separate(blast_taxonomy,
             into=c("Kingdom_blast",
                    "Phylum_blast",
                    "Class_blast",
                    "Order_blast",
                    "Family_blast",
                    "Genus_blast",
                    "Species_blast"),
             sep=";",
             remove = F)%>%
    mutate(across(.cols=which(grepl("boots_",colnames(.))),.fns=as.numeric))

rownames(motus_frame) <- motus_frame$observation_name # use asv names as rownames of the df
pcr_frame <- data.frame(sample_id=colnames(data_temp)[grep("L001",colnames(data_temp))], type="sample",control_type=NA) # set pcr frame as required by metabaR
rownames(pcr_frame) <- pcr_frame$sample_id # set rownames as site/sample id

sample_frame <- data.frame(sample_id=colnames(data_temp)[grep("L001",colnames(data_temp))]) # create sample frame
rownames(sample_frame) <- sample_frame$sample_id # set rownames as site/sample id

metab_list <- metabarlist_generator(reads = reads_frame, # create metabarlist
                                    motus = motus_frame,
                                    pcrs = pcr_frame,
                                    samples = sample_frame)

rm(data_temp,motus_frame,pcr_frame,reads_frame,sample_frame) # remove temporary files
```



## Start MetabaR processing


### Evaluate PCRs on sequencing depths

Plot number of ASVs and reads per PCRs as well as their correlation.
Correlation between reads and richness are problematic as they might indicate insufficient sequencing depth.
```{r}
data_temp <- metab_list# get one metabarlist

# Compute the number of reads per pcr
data_temp$pcrs$nb_reads <- rowSums(data_temp$reads)

# Compute the number of asvs per pcr
data_temp$pcrs$nb_asvs <- rowSums(data_temp$reads>0)
metab_list <- data_temp
check1 <- reshape2::melt(data_temp$pcrs[,c("control_type", "nb_reads", "nb_asvs")])

p1 <- ggplot(data <- check1, aes(x=1, y=value)) + 
    geom_boxplot(outlier.shape = NA) + 
    theme_bw() + 
    geom_jitter(alpha=0.2) + 
    facet_wrap(~variable, scales = "free_y") +
    ggtitle("16s")+ 
    theme(axis.text.x = element_blank(),
          axis.title = element_blank(),
          plot.title = element_text(face="bold"))

p2 <-  ggplot(data_temp$pcrs, aes(x=nb_reads, y=nb_asvs)) + 
    geom_point() + 
    theme_bw() + 
    scale_y_log10() + 
    scale_x_log10() 

diagplot <- p1 + p2 + plot_layout(guides="collect") # sample 124 low reads?
rm(p1,p2,data_temp,check1,data)
diagplot
```

```{r}
ggsave("Figures/reads_and_asvs_raw.png",diagplot,width = 14)
```


All samples but one have more than 10000 reads. 
Remove this outlier

Flag pcrs according to seq depths
```{r}
data_temp <- metab_list

# Tag as ok pcrs with more than 10 000 reads
data_temp$pcrs$seqdepth_ok <- ifelse(data_temp$pcrs$nb_reads < 10e3, F, T)

# Overwrite
metab_list <- data_temp 

# proportion of innaceptable pcrs seq depth, control excluded!!
seq_depth_tab <- table(data_temp$pcrs$seqdepth_ok[data_temp$pcrs$type=="sample"]) /
    nrow(data_temp$pcrs[data_temp$pcrs$type=="sample",])
print(seq_depth_tab)
rm(data_temp)
```


### Remove non target ASVs

Tag non target ASVs
```{r}
non_target_prop <- NULL
non_targetconta_prop <- NULL

data_temp <- metab_list

#Flag ASVs corresponding to target (TRUE) vs. non-target (FALSE) taxa 
data_temp$motus$target_taxon <- grepl("Bacteria|Archaea", data_temp$motus$Kingdom)&!grepl("Chloroplast",data_temp$motus$Order)&!grepl("Mitochondria",data_temp$motus$Family)  # MITO and rickettsiales
non_targ_asvs <- data_temp$motus$observation_name[which(data_temp$motus$target_taxon==F)]
# Proportion of each of these over total number of ASVs
non_target_prop <- table(data_temp$motus$target_taxon) / nrow(data_temp$motus)
print(non_target_prop)
# Intersection with extraction contaminant flags (not contaminant = T)
non_target_prop <- table(data_temp$motus$target_taxon)
print(non_target_prop)

# Overwrite
metab_list <- data_temp
```


### Filter and format according to Assignment quality


Tag as poorly assigned Sequences with no assignment at the kingdom lvl (ie with RDP bootstrap values <70: boots_thshld choosen earlier) 
```{r}
boots_thshld <- 0.7 # define a RDP classifier bootstrap value under which we consider affiliation uncertain

# test <- NULL
data_temp <- metab_list
melty <- melt(data_temp$motus, id = c(colnames(data_temp$motus)[which(grepl("boots_",colnames(data_temp$motus))==F)] ))
melty$variable <- gsub("boots_","",melty$variable)
melty$variable <- as.factor(melty$variable)

melty$variable <- fct_relevel(melty$variable,"Kingdom","Phylum","Class","Order","Family","Genus","Species")


plot_tax_boots <-  ggplot(melty,aes(x=variable,y=as.numeric(value))) +
    geom_boxplot(aes(fill=variable))+
    theme_bw()+
    ggtitle("16s")+
    labs(y="conf %")+
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank(),
          axis.title.x = element_blank())+
    theme(legend.position = "n",
          plot.title = element_text(face = "bold"))

# Create a "confident taxonomy" (boots >= boots_thshld)
colnames_tmp <- c(gsub("boots_","",grep("boots_",colnames(data_temp$motus), value = T)))

for(j in 1:length(colnames_tmp)){
    
    col <- match(colnames_tmp[j],colnames(data_temp$motus))
    a <- data_temp$motus[,c(col,col+1)]
    tax_lvl <- paste0(tolower(substr(names(a)[2],7,7)),"__")
    conf <- a %>% mutate(col_temp=ifelse(.[[2]]<boots_thshld,gsub(".*",tax_lvl,.[[1]],perl=T),.[[1]]))
    data_temp$motus <- cbind(data_temp$motus,conf[,3])
    colnames(data_temp$motus)[ncol(data_temp$motus)]<- paste0(colnames_tmp[j],"_conf_rdp")
}

# Tag sequences not assigned below Kingdom
data_temp$motus %<>% mutate(good_assign = ifelse(Phylum_conf_rdp=="p__",F,T))

# Overwrite
metab_list <- data_temp
rm(data_temp,melty)

plot_tax_boots
```

### Display noise in ASVs

summarize noise in ASVs
```{r}
# color_scale (create a common scale across datasets)
a <- unlist(combn(c("untargeted_taxon","poorly_assigned"),1,simplify = F))
b <- c("poorly_assigned|untargeted_taxon")
myColors <- RColorBrewer::brewer.pal(8,"Set1")
names(myColors) <- levels(as.factor(c(a,b,"not_artefactual")))
colScale <- scale_fill_manual(name = "grp",values = myColors, drop=F)

data_temp <- metab_list

# Create a table of ASVs quality criteria 
# noise is identified as FALSE in data_temp, the "!" transforms it to TRUE 
asvs.qual <- !data_temp$motus[,c("target_taxon","good_assign")] #not_degraded 
colnames(asvs.qual) <- c("untargeted_taxon","poorly_assigned") #degraded_seq  

asv_noise_tab <- NULL
# Proportion of asvs potentially artifactual (TRUE) based on the criteria used
asv_noise_tab$motus <- prop.table(table(apply(asvs.qual, 1, sum) > 0))

# Corresponding proportion of artifactual reads (TRUE)
asv_noise_tab$reads <- prop.table(xtabs(data_temp$motus$observation_sum~apply(asvs.qual, 1, sum) > 0))

# Proportion of asvs and reads potentially artifactual for each criterion
apply(asvs.qual, 2, sum) / nrow(asvs.qual)
apply(asvs.qual, 2, function(x) sum(data_temp$motus$observation_sum[x])/sum(data_temp$motus$observation_sum))

tmp.asvs <- 
    apply(sapply(1:ncol(asvs.qual), function(x) {
        ifelse(asvs.qual[,x]==T, colnames(asvs.qual)[x], NA)}), 1, function(x) {
            paste(sort(unique(x)), collapse = "|")
        })
tmp.asvs <- as.data.frame(gsub("^$", "not_artefactual", tmp.asvs))
colnames(tmp.asvs) <-  "artefact_type"
tmp.asvs %<>% mutate(artefact_type=as.factor(artefact_type)  )

plot_noise_asv <- ggplot(tmp.asvs, aes(x=1, fill=artefact_type)) +
    geom_bar() +  xlim(0, 2) +
    labs(fill="Artifact type") + 
    coord_polar(theta="y") + theme_void() + 
    scale_fill_manual(name = "Noise type",values = myColors, drop=F) + 
    theme(legend.direction = "vertical") + 
    ggtitle("16s - ASVS noise")+
    theme(plot.title = element_text(face="bold"))

rm(tmp.asvs,asvs.qual,data_temp,myColors,colScale,a,b)

plot_noise_asv
```

```{r}
ggsave("Figures/noise_in_asvs.png",plot_noise_asv)
```


### Filter 


```{r}
# Use tag-jump corrected metabarlist with the threshold identified above
tmp <- metab_list

# Subset onASVs: we keep asvs that are defined as TRUE following the 
# criteria below (sum of x TRUE is equal to x with the rowSums function)
row.names(tmp$motus) <- colnames(tmp$reads)

tmp <- subset_metabarlist(tmp, "motus", 
                          indices = rowSums(tmp$motus[,c("good_assign", "target_taxon")]) == 2)# remove untargeted taxa and poorly assigned (no assignation @phylum)

# Subset on pcrs and keep only samples 
data_temp <- subset_metabarlist(tmp, "pcrs", 
                                indices = tmp$pcrs[,c("seqdepth_ok")] == TRUE & #, "replicating_pcr" 
                                    tmp$pcrs$type == "sample")

#update counts and reads.    
data_temp$motus$counts = colSums(data_temp$reads)
data_temp$pcrs$reads_post = rowSums(data_temp$reads)
data_temp$pcrs$asvs_post = rowSums(ifelse(data_temp$reads>0, T, F))

check <- melt(data_temp$pcrs[,c("nb_reads", "reads_post", 
                                "nb_asvs", "asvs_post")])
check$type <- ifelse(grepl("asvs", check$variable), "richness", "abundance")

summary_list <- summary_metabarlist(data_temp)

if(sum(colSums(data_temp$reads)==0)>0){print(paste0(folder_names[[i]]," empty asvs present"))}
if(sum(colSums(data_temp$reads)==0)>0){print(paste0(folder_names[[i]]," empty pcrs present"))}

sumpipeline_plots <- ggplot(data = check, aes(x = variable, y = value)) +
    geom_boxplot( color = "darkgrey") +
    geom_jitter(alpha=0.1, color = "darkgrey") +
    theme_bw() +
    facet_wrap(~type, scales = "free", ncol = 5) +
    theme(axis.text.x = element_text(angle=45, h=1),
          axis.title = element_blank()) +
    ggtitle("Effect of cleaning")

cleaned_metablist <- data_temp
rm(tmp,data_temp,check)
sumpipeline_plots
```

```{r}
ggsave("Figures/effect_of_cleaning_asvs_reads.png",sumpipeline_plots,width=14)
```

### Check effect of filter on reads and richness


```{r}
# Using the nb_reads and nb_asvs defined previously in the data_temp$pcrs table
data_temp <- cleaned_metablist

check1 <- reshape2::melt(data_temp$pcrs[,c("control_type", "reads_post", "asvs_post")])

p1 <- ggplot(data <- check1, aes(x=1, y=value)) + 
    geom_boxplot(outlier.shape = NA) + 
    theme_bw() + 
    geom_jitter(alpha=0.2) + 
    facet_wrap(~variable, scales = "free_y") +
    ggtitle("")+ 
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank(),
          axis.title.x = element_blank())

p2 <-  ggplot(data_temp$pcrs, aes(x=reads_post, y=asvs_post)) + 
    geom_point() + 
    theme_bw() + 
    geom_smooth(method="lm",color="darkorange")+ 
    theme(axis.title.x = element_blank())

diag_plots_post <-  p1 + p2 + plot_layout(guides="collect")
rm(p1,p2,data_temp,check1,data)

diag_plots_post
```


```{r}
ggsave("Figures/cor_asvs_reads_postcleaning.png",diag_plots_post,width=14)
```


OK we have strong correlation between richness and reads within samples (deseq2 or rarefaction?)
Will depend on questions (test link between bioclimatic/geographical variables and the number of reads)
Differential abundance implementation in this models.
Rarefaction?

## Data wrangling

### Transform to physeq lists


```{r}
data_temp_cleaned <- cleaned_metablist
data_temp <- metab_list

rownames(data_temp$motus) <- colnames(data_temp$reads)
# Get row data only for samples
tmp <- subset_metabarlist(data_temp, table = "pcrs",
                          indices = data_temp$pcrs$type == "sample")

tmpcl <- subset_metabarlist(data_temp_cleaned, table = "pcrs",
                            indices = data_temp_cleaned$pcrs$type == "sample")

# Format for phyloseq

otumat <- as.matrix(tmp$reads)
taxmat <- as.matrix(tmp$motus)
sammat <- left_join(tmp$samples,tmp$pcrs)
OTU <- otu_table(otumat, taxa_are_rows = F)
TAX <- tax_table(taxmat)
SAM <- sample_data(sammat)
rownames(SAM) <- SAM$sample_id
physeq <- phyloseq(OTU,TAX,SAM)
physeq

otumatcl <- as.matrix(tmpcl$reads)
taxmatcl <- as.matrix(tmpcl$motus)
sammatcl <- left_join(tmpcl$samples,tmpcl$pcrs)
OTUcl <- otu_table(otumatcl, taxa_are_rows = F)
TAXcl <- tax_table(taxmatcl)
SAMcl <- sample_data(sammatcl)
rownames(SAMcl) <- SAMcl$sample_id
physeqcl <- phyloseq(OTUcl,TAXcl,SAMcl)
```


```{r}
toremove <- grep("^metab|^cleaned|^physeq|non_targ_asvs|arrowMul|agg.table.taxo", ls(), invert=T, value=T)
rm(list = c(toremove, "toremove"))
gc()
```


remove unwanted samples (Vincent treatments and chile sample)
```{r}
data_temp <- physeqcl
data_temp <- subset_samples(data_temp, !grepl("23[1-7]|239|240|241|042-047|047-042|246b",data_temp@sam_data$sample_id))
data_temp@sam_data$reads_post <- rowSums(data_temp@otu_table)

data_temp@sam_data$reads_post = rowSums(data_temp@otu_table) # reads per samples
data_temp@sam_data$asvs_post = rowSums(ifelse(data_temp@otu_table>0, T, F)) # motus per samples
physeqcl <- data_temp
rm(data_temp)
```


### Transform to microeco

Load site metadata
```{r}
site_coordinates <- read.csv("../../ressource/Site_edaphic_data/site_coord_MAPP.csv")  # get site coordinates
site_coordinates %<>% 
    mutate(Sample=ifelse(nchar(Sample)<3,paste0("0",Sample),Sample))%>% # reformat 1 into 001 and 64 to 064 etc...
    mutate(Sample=ifelse(nchar(Sample)<3,paste0("0",Sample),Sample))
site_coordinates %<>% 
    mutate(Sample=ifelse(grepl("^8",Sample),paste0("0",Sample),Sample)) # fix 87a and 87b to 087a and 087b

#add a little jitter to avoid exactly similar coordinates
site_coordinates$X2 <- site_coordinates$X
site_coordinates$Y2 <- site_coordinates$Y
site_coordinates$X2[which(duplicated(site_coordinates$X2))] <- jitter(site_coordinates$X2[which(duplicated(site_coordinates$X2))] ,amount = 8.983112*10^-6)
site_coordinates$Y2[which(duplicated(site_coordinates$Y2))] <- jitter(site_coordinates$Y2[which(duplicated(site_coordinates$Y2))] ,amount = 8.983112*10^-6)

write.csv(site_coordinates[,c("Sample","Y","X","Country")],"../../ressource/Site_edaphic_data/site_coord_MAPP-ecoR.csv",row.names = F)

site_ecoregions <- read.csv("../../ressource/Site_edaphic_data/MAPP_ecoR_with_Ecoregions.csv")

site_ecoregions %<>% 
    mutate(Sample=ifelse(nchar(Sample)<3,paste0("0",Sample),Sample))%>% # reformat 1 into 001 and 64 to 064 etc...
    mutate(Sample=ifelse(nchar(Sample)<3,paste0("0",Sample),Sample))
site_ecoregions %<>% 
    mutate(Sample=ifelse(grepl("^8",Sample),paste0("0",Sample),Sample)) # fix 87a and 87b to 087a and 087b

site_coordinates <- left_join(site_coordinates,site_ecoregions,by = "Sample")
```


```{r}
meco_16s <- phyloseq2meco(physeqcl)

meco_16s$sample_table %<>% mutate(Sample = gsub("[A-Z]|-|(?=_).*","",sample_id,perl = T))

# check for diff between sites coordinates obtained form vicent and samples remaining in the final analysis
setdiff(site_coordinates$Sample,meco_16s$sample_table$Sample) # we willingly removed 231-7|239|240|241 / 042 and 047 are mixed up what about : 115/124/199/200/201/205/206/208/209/227/252/253/258

# add coordinates to the datasets
meco_16s$sample_table %<>% left_join(site_coordinates)

# reset rownames
rownames(meco_16s$sample_table) <- meco_16s$sample_table$sample_id

meco_16s$tidy_dataset() #tidy datasets

# Compute the number of reads per pcr
meco_16s$sample_table$nb_reads <- colSums(meco_16s$otu_table)

# Compute the number of asvs per pcr
meco_16s$sample_table$nb_reads <- colSums(meco_16s$otu_table>0)

gc()
```

# C - Explore 16s communities

Samples 256 and 87 are duplicated (a and b). 
256b and 87a are retained because of their higher sequencing depth.
```{r}
colSums(meco_16s$otu_table[,grepl("256",colnames(meco_16s$otu_table))]);colSums(meco_16s$otu_table[,grepl("87",colnames(meco_16s$otu_table))])
```

Moreover we lack geographical info about samples 116, 119 and 166 and samples 042 and 047 have been mixed and can't be exploited.

```{r}
meco_16s$otu_table <- meco_16s$otu_table[,!grepl("256a|87b|116|119|166",colnames(meco_16s$otu_table))] # remove these samples
meco_16s$filter_pollution(taxa = c("mitochondria", "chloroplast")) # remove chloroplast and mitochondria if some passed the previous filter
meco_16s$tidy_dataset() # tidy the microeco object

# Compute the number of reads per pcr
meco_16s$sample_table$nb_reads <- colSums(meco_16s$otu_table)

# Compute the number of asvs per pcr
meco_16s$sample_table$nb_reads <- colSums(meco_16s$otu_table>0)
```

We finally removed all unwanted samples and thus taxa.

## Investigate singletons

Visualize number of singletons
```{r}
data_temp <- meco_16s # get data

n_single_asv <- sum(rowSums(data_temp$otu_table>0)==1) # number of single asvs (those that are present exactly once across all sites)
n_non_single_asv <- sum(rowSums(data_temp$otu_table>0)>1) # number of non single asvs
n_single_reads <- sum(data_temp$otu_table[which(rowSums(data_temp$otu_table>0)==1),]) # number of reads from the data set that correspond to asv singletons (sum of reads on singletons subset)
n_non_single_reads <- sum(data_temp$otu_table[which(rowSums(data_temp$otu_table>0)>1),]) # same but for non singletons

df_tmp <- data.frame(asv_val=c(n_single_asv,n_non_single_asv),
                     read_val=c(n_single_reads,n_non_single_reads),
                     type=c("n_single","n_non_single"))
df_tmp %<>% mutate(pct_asvs=asv_val/sum(asv_val), # convert to %
                   pct_reads=read_val/sum(data_temp$otu_table))%>%
    reshape2::melt()%>%
    filter(grepl("pct",variable))

singletons <- ggplot(df_tmp,aes(x = variable,y = value, fill=type))+
    geom_bar(position="stack",stat = "identity")+
    theme_classic2()+
    scale_fill_manual(values = c("lightseagreen","mediumvioletred"))+
    theme(plot.title = element_text(face='bold'))+
    ylab("% of singletons")+
    xlab("ASVs vs Reads")+
    scale_y_continuous(expand = c(0,0))


alpha <- colSums(data_temp$otu_table!=0) # sample alpha diversity as the number of non null rows (asvs)
single_asv <-  colSums(filter(data_temp$otu_table,rowSums(data_temp$otu_table>0)==1)>1) # number of singletons asvs within sample as the number of asvs restricted to this sample (subset rowsums) and with one read (==1)
# non_single_asv2 <- colSums(data_temp$otu_table>1)
non_single_asv <- alpha-single_asv # ASVs that might be singletons within the sample but not the dataset 
df_tmp <- data.frame(value = c(rbind(single_asv,non_single_asv)),
                     type=c("n_single","n_non_single"),
                     sample=rep(1:ncol(data_temp$otu_table),each=2))%>%
    group_by(sample)%>%
    mutate(val_pct= value/sum(value))

alpha_plot <- ggplot(df_tmp,aes(x=sample,y=value,fill=type))+
    geom_bar(stat="identity",position = "stack",width = 1)+
    theme_classic2()+
    ggtitle(paste0("16s singletons: ",n_single_asv, " singleton ASVs"))+
    theme(plot.title = element_text(face='bold'))+
    scale_y_continuous(expand = c(0,0))+
    scale_x_continuous(expand = c(0,0))+
    xlab("samples")+
    ylab("Richness")+
    scale_fill_manual(values=c("lightseagreen","mediumvioletred"))

alpha_plot_pct <- ggplot(df_tmp,aes(x=sample,y=val_pct,fill=type))+
    geom_bar(stat="identity",position = "stack",width = 1)+
    theme_classic2()+
    theme(plot.title = element_text(face='bold'))+
    scale_y_continuous(expand = c(0,0))+
    scale_x_continuous(expand = c(0,0))+
    xlab("samples")+
    ylab("Richness")+
    scale_fill_manual(values=c("lightseagreen","mediumvioletred"))


meco_16s_singl <- clone(meco_16s)
meco_16s_singl$otu_table %<>% filter(rowSums(.)==1)
meco_16s_singl$tidy_dataset()
meco_16s_singl$sample_table %<>% mutate(dumb_group = "sample")
meco_16s_singl$cal_abund()
meco_16s_singl <- trans_abund$new(meco_16s_singl,taxrank = "Order_conf_rdp",ntaxa = 8,groupmean = "dumb_group")
    
plot_data <- meco_16s_singl$data_abund
use_taxanames <- c(meco_16s_singl$data_taxanames,"unidentified")
plot_data$Taxonomy[!plot_data$Taxonomy %in% use_taxanames] <- "Others"
plot_data %<>% 
    dplyr::group_by(!!!syms(c("Taxonomy","Sample"))) %>% 
    dplyr::summarise(Abundance = sum(Abundance)) %>% 
    as.data.frame(stringsAsFactors = FALSE)
plot_data$Taxonomy %<>% factor(., levels = c(use_taxanames[-9], "Others", "unidentified"))
plot_data$label <- paste0(round(plot_data$Abundance, 1),"%")
donut_comp <- ggdonutchart(plot_data,"Abundance",
             fill="Taxonomy",
             label = "label",
             color = "white",
             palette = c(colorRampPalette(brewer.pal(8, "Dark2"))(9),"lightgrey"))+
    theme(legend.position = "right")


singleton_plots <- alpha_plot + theme(legend.position = "n") + alpha_plot_pct + singletons + theme(legend.position = "n") + donut_comp  + plot_layout(widths = c(1, 1))

ggsave("Figures/diagnose_singletons.png",singleton_plots,width = 14,height = 14)
```

```{r}
rm(alpha_plot,alpha,alpha_plot_pct,data_temp,df_tmp,donut_comp,meco_16s_singl,plot_data,singleton_plots,singletons,n_non_single_asv,n_non_single_reads,n_single_asv,n_single_reads,non_single_asv,single_asv,use_taxanames,site_ecoregions)
```


re-compute for each samples the sequencing depth and richness
```{r}
meco_16s$sample_table %<>%
    dplyr::select(sample_id,nb_reads,nb_asvs,Sample,Y,X) %>%
    mutate(nb_reads=colSums(meco_16s$otu_table),
           nb_asvs=colSums(meco_16s$otu_table>0))
```


same without singletons
```{r}
meco_16s_ns <- clone(meco_16s)
meco_16s_ns$otu_table %<>% filter(rowSums(meco_16s_ns$otu_table>0)>1)
meco_16s_ns$tidy_dataset()
meco_16s_ns$sample_table %<>%
    mutate(nb_reads=colSums(meco_16s_ns$otu_table),
           nb_asvs=colSums(meco_16s_ns$otu_table>0))
```

## Filtering on relab

```{r}
meco_16s_relabfiltered <- clone(meco_16s_ns) # clone
tmp_com <- meco_16s_ns$otu_table%>%
  mutate(across(everything(),.fns=~./sum(.))) # create a relative abundance matrix


filt_05pct <- tmp_com%>%
  t()%>%
  as.data.frame() %>%
  select_if(~max(.)>0.005) # 0.5% threshold. ASVs need to represent more than 0.5% of the community reads in at least one sample.


meco_16s_relabfiltered$otu_table%<>%filter(rownames(meco_16s_relabfiltered$otu_table)%in%colnames(filt_05pct)) # get OTUs that match the threshold
meco_16s_relabfiltered$tidy_dataset() # filter datasets

meco_16s_relabfiltered$sample_table$nb_reads <- colSums(meco_16s_relabfiltered$otu_table) # count reads
meco_16s_relabfiltered$sample_table$nb_motus <- colSums(meco_16s_relabfiltered$otu_table>0) # count motus

save(meco_16s_relabfiltered,file = "outputs/meco_16s_filtered.RData")
```


```{r}
data_temp <- meco_16s_relabfiltered # get data

sum(rowSums(data_temp$otu_table>0)==1) # number of single asvs (those that are present exactly once across all sites)
```
No newly generated singletons

```{r}
rm(data_temp,filt_05pct,tmp_com)
```

## Procrustes our different datasets

```{r}
mds_filtered <- meco_16s_relabfiltered$otu_table%>%
    t()%>%
    labdsv::hellinger()%>%
    vegan::metaMDS(distance= "horn")

mds_16s <- meco_16s$otu_table%>%
    t()%>%
    labdsv::hellinger()%>%
    vegan::metaMDS(distance= "horn")

mds_ns <- meco_16s_ns$otu_table%>%
    t()%>%
    labdsv::hellinger()%>%
    vegan::metaMDS(distance= "horn") 

distrr::combn_char(c("mds_filtered","mds_16s","mds_ns"))[[2]]

procrustes_res1 <- vegan::procrustes(mds_16s,mds_filtered, symmetric = T)
procrustes_res2 <- vegan::procrustes(mds_16s,mds_ns, symmetric = T)
procrustes_res3 <- vegan::procrustes(mds_filtered,mds_ns, symmetric = T)

t1 <- paste0("Procrustes",dim(mds_16s$species)[1],"/",dim(mds_filtered$species)[1]," ASVs")
t2 <- paste0("Procrustes",dim(mds_16s$species)[1],"/",dim(mds_ns$species)[1]," ASVs")
t3 <- paste0("Procrustes",dim(mds_filtered$species)[1],"/",dim(mds_ns$species)[1]," ASVs")

list_procrustes_com <- c("procrustes_res1","procrustes_res2","procrustes_res3")
list_pro_title <- list(t1,t2,t3)

pro_plot_com <- NULL
for(i in list_procrustes_com){
  
  pro_tmp <- get(i)
  ctest <- data.frame(nmds1=pro_tmp$Yrot[,1],
                      nmds2=pro_tmp$Yrot[,2],
                      xnmds1=pro_tmp$X[,1],
                      xnmds2=pro_tmp$X[,2])
  pro.error <- data.frame(err=residuals(pro_tmp),Sample=meco_16s_ns$sample_table$Sample)
  quantiles <- quantile(pro.error$err,probs = c(0.25,0.50,0.75))
  
  p1 <- ggplot(ctest) +
    geom_point(aes(x=nmds1, y=nmds2)) +
    geom_point(aes(x=xnmds1, y=xnmds2),shape=17) +
    geom_segment(aes(x=nmds1,y=nmds2,xend=xnmds1,yend=xnmds2),arrow=arrow(length=unit(0.2,"cm")))+
    theme_classic2()+
    ggtitle(list_pro_title[[match(i,list_procrustes_com)]])+
    theme(legend.position = "n")
  
  
  
  p2 <- ggplot(pro.error,aes(x = Sample, y=err))+
    geom_bar(stat='identity',width = 1)+
    geom_hline(yintercept = quantiles[1],linetype="dashed")+
    geom_hline(yintercept = quantiles[2])+
    geom_hline(yintercept = quantiles[3],linetype="dashed")+
    theme_classic2()+
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank())+
    xlab("site row")+
    ylab("Residual fit")+ 
    plot_layout(widths = c(1.4,1.6))+
    scale_y_continuous(expand = c(0,0))
  
  p1.solution <- patchwork::wrap_elements(plot = p1 + coord_fixed())
  procr <- patchwork::wrap_plots(p1.solution, p2, ncol = 2)
  pro_plot_com[[i]] <- procr
  
  
ggsave(paste0("../paper_16s/Figures/procruste_",i,".png"),procr,height = 5, width = 14)

}
```

```{r}
rm(ctest,mds_16s,mds_filtered,mds_ns,p1,p2,p1.solution,list_pro_title,pro_plot_com,pro_tmp,pro.error,procr,procrustes_res1,procrustes_res2,procrustes_res3,list_procrustes_com,t1,t2,t3,quantiles)
```

## Alpha-div

```{r}
plot_alpha_divz_sgnsg <- NULL
for(i in c("meco_16s","meco_16s_ns","meco_16s_relabfiltered")){
    
    tmp <- get(i)
    plot_title <- ifelse(match(i,c("meco_16s","meco_16s_ns"))==1,
                         "With singletons",
                         ifelse(match(i,c("meco_16s","meco_16s_ns","meco_16s_ns_relabfiltered"))==2,
                                "Without singletons",
                                "Filtered 5% relative abundacne"))
    
    distrib_reads_and_asvs <- tmp$sample_table %>%
        ggplot(aes(x=nb_reads))+
        geom_histogram(bins=30,color='darkorange',fill='white')+
        scale_y_continuous(expand = c(0,0))+
        theme_classic2()+
        tmp$sample_table %>%
        ggplot(aes(x=nb_asvs))+
        geom_histogram(bins=30,color='deeppink4',fill='white')+
        scale_y_continuous(expand = c(0,0))+
        theme_classic2()
    
    cor_reads_asvs <- tmp$sample_table %>%
        ggplot(aes(x=nb_reads, y=nb_asvs))+
        geom_point(color='darkgrey')+
        scale_y_continuous(expand = expansion(mult = c(0,0.05), add= c(0,0)))+
        scale_x_continuous(expand = expansion(mult = c(0,0.05), add= c(0,0)) )+
        theme_classic2()+
        geom_smooth(method = 'lm',lty=2,color='darkorange')+
        ggpmisc::stat_poly_eq(ggpmisc::use_label(c("eq", "R2", "p")))
    
    tab16s <- t(otu_table(file2meco::meco2phyloseq(tmp))) # get the community
    class(tab16s) <- "matrix" # change class
    curve16s <- rarecurve(tab16s,step=100) # use vegan rarefaction curves
    names(curve16s) <- rownames(tab16s) # name curves after sample IDs
    
    # Coerce data into "long" form.
    protox <- mapply(FUN = function(x, y) {
        mydf <- as.data.frame(x)
        colnames(mydf) <- "value"
        mydf$samples <- y
        mydf$subsample <- attr(x, "Subsample")
        mydf
    }, x = curve16s, y = as.list(names(curve16s)), SIMPLIFY = FALSE)
    
    xy <- do.call(rbind, protox)
    rownames(xy) <- NULL  # pretty
    
    # Plot.
    rare16s <- ggplot(xy, aes(x = subsample, y = value, group = samples )) +
        theme_classic2() +
        scale_color_discrete(guide = "none") +  # turn legend on or off
        geom_line(color = "aquamarine4")+
        xlab("nb reads")+
        ylab("ASVs count")
    
    plot_alpha_divz_sgnsg[[i]] <- distrib_reads_and_asvs/(cor_reads_asvs+rare16s)+ plot_annotation(title = plot_title) & theme(plot.title = element_text(face='bold'))
    
}
plot_alpha_divz_sgnsg[[1]]|plot_alpha_divz_sgnsg[[2]]|plot_alpha_divz_sgnsg[[3]]
```

```{r}
ggsave("Figures/alpha_div_with_sing.png",plot_alpha_divz_sgnsg[[1]],width = 14,height = 14)
ggsave("Figures/alpha_div_no_sing.png",plot_alpha_divz_sgnsg[[2]],width = 14,height = 14)
ggsave("Figures/alpha_div_relab_filt.png",plot_alpha_divz_sgnsg[[3]],width = 14,height = 14)
```

```{r}
rm(tmp,plot_title,distrib_reads_and_asvs,cor_reads_asvs,tab16s,curve16s,protox,rare16s,plot_alpha_divz_sgnsg,xy)
```

## Composition

donuts plot without singletons fur 16s
```{r}
plots_comp <- NULL
for( i in c("Order_conf_rdp","Genus_conf_rdp")){
  for(j in c("meco_16s_ns","meco_16s_relabfiltered")){
    tmp16s <- clone(get(j))
    tmp16s$sample_table %<>% mutate(dumb_group = "sample")
    tmp16s$otu_table %<>% filter(rowSums(.)>1)
    tmp16s$tidy_dataset()
    
    tmp16s$cal_abund()
    tmp16s1 <- trans_abund$new(tmp16s,taxrank = i,ntaxa = 8,groupmean = "dumb_group")
    
    plot_data1 <- tmp16s1$data_abund
    use_taxanames <- tmp16s1$data_taxanames
    plot_data1$Taxonomy[!plot_data1$Taxonomy %in% c(use_taxanames,"unidentified")] <- "Others"
    plot_data1 %<>% 
      dplyr::group_by(!!!syms(c("Taxonomy","Sample"))) %>% 
      dplyr::summarise(Abundance = sum(Abundance)) %>% 
      as.data.frame(stringsAsFactors = FALSE)
    plot_data1$Taxonomy %<>% factor(., levels = c(use_taxanames[-9], "Others","unidentified"))
    plot_data1$label <- paste0(round(plot_data1$Abundance, 1),"%")
    donut_comp <- ggdonutchart(plot_data1,"Abundance",
                               fill="Taxonomy",
                               label = "label",
                               color = "white",
                               palette =  c(colorRampPalette(brewer.pal(8, "Dark2"))(9),"lightgrey"),
                               guide = guide_legend(reverse = TRUE) )+
      theme(legend.position = "right")
    
    tmp16s2 <- trans_abund$new(tmp16s,taxrank = i,ntaxa = 8)
    plot_data2 <- tmp16s2$data_abund
    plot_data2$Taxonomy[!plot_data2$Taxonomy %in% c(use_taxanames,"unidentified")] <- "Others"
    plot_data2$Taxonomy %<>% factor(., levels = rev(c(use_taxanames[-9], "Others","unidentified")))
    bar_comp <- plot_data2%>%
      ggplot(aes(x=Sample,y=Abundance,fill=Taxonomy),color=NA)+
      geom_bar(stat = "identity",width=1,position='fill')+
      scale_fill_manual(values =  rev(c(colorRampPalette(brewer.pal(8, "Dark2"))(9),"lightgrey")),
                        guide = guide_legend(reverse = TRUE) )+
      scale_y_continuous(expand = c(0,0))+
      theme(axis.text.x = element_blank(),
            axis.ticks.x = element_blank())
    
    plots_comp[[i]][[j]] <- donut_comp + bar_comp  +  plot_annotation(title = ifelse(j=="meco_16s_ns","No singletons","Filtered at 5% relative abundance")) & theme(plot.title = element_text(face='bold'))
  }
}
```

```{r}
ggsave("Figures/comp_order_ns.png",plots_comp$Order_conf_rdp$meco_16s_ns,width = 14)
ggsave("Figures/com_genus_ns.png",plots_comp$Genus_conf_rdp$meco_16s_ns,width = 14)
ggsave("Figures/comp_order_filt.png",plots_comp$Order_conf_rdp$meco_16s_relabfiltered,width = 14)
ggsave("Figures/com_genus_filt.png",plots_comp$Genus_conf_rdp$meco_16s_relabfiltered,width = 14)
```

```{r}
rm(tmp16s,plot_data1,use_taxanames,plots_comp,bar_comp,tmp16s2,donut_comp,tmp16s1)
```

Distribution and prev/relab

```{r}
for(j in c("meco_16s_ns","meco_16s_relabfiltered")){
  tmp <- get(j)
  tmp <- clone(tmp)
  prev <- rowSums(tmp$otu_table>0)
  a <- prev%>%
    as.data.frame()%>%
    ggplot(aes(x=prev))+
    geom_histogram(bins=30,color='darkcyan',fill='white')+
    scale_y_continuous(expand = c(0,0))+
    theme_classic2()+
    xlab("Cluster prevalence across samples")+
    coord_trans(y = "log1p")
  
  median_relab <- NULL
  mean_relab <- NULL
  for(i in 1:nrow(tmp$otu_table)){
    median_relab <- c(median_relab,median(as.numeric(tmp$otu_table[i,]/colSums(tmp$otu_table)))*100)
    mean_relab <- c(mean_relab,mean(as.numeric(tmp$otu_table[i,]/colSums(tmp$otu_table)))*100)
  }
  b <- median_relab%>%
    as.data.frame()%>%
    ggplot(aes(x=median_relab))+
    geom_histogram(bins=30,color='burlywood3',fill='white')+
    scale_y_continuous(expand = c(0,0))+
    theme_classic2()+
    xlab("Cluster median relative abundance within samples (%)")+
    coord_trans(y = "log1p")
  
  c <- mean_relab%>%
    as.data.frame()%>%
    ggplot(aes(x=mean_relab))+
    geom_histogram(bins=30,color='darkolivegreen4',fill='white')+
    scale_y_continuous(expand = c(0,0))+
    theme_classic2()+
    xlab("Cluster mean relative abundance within samples (%)")+
    coord_trans(y = "log1p")
  ggsave(filename = paste0("Figures/prev_otu_",j,".png"),plot=(a+b)/(c+plot_spacer()),width=8,height = 10)
  
}
```


```{r}
rm(a,b,c,median_relab,mean_relab,prev,tmp)
```

## Taxa summary

```{r}
pl <- NULL
for(i in c("meco_16s_ns","meco_16s_relabfiltered")){
  
  data_tmp <- get(i)
  data_tmp <- clone(data_tmp)
  d <- data_tmp$tax_table[,c(5,7,9)]
  tab <- data_tmp$otu_table 
  
  tax.lvl <- "Order_conf"
  order_tot <-agg.table.taxo(tab = tab, # aggregate my data at the targeted tax level
                             tax.lvl = tax.lvl,
                             tax.table = data_tmp$tax_table) %>%
    apply(1,sum) %>% # sum the number of reads
    sort %>% # sort in ascending order
    identity
  tax.lvl <- "Class_conf"
  class_tot <-agg.table.taxo(tab = tab, # aggregate my data at the targeted tax level
                             tax.lvl = tax.lvl,
                             tax.table = data_tmp$tax_table) %>%
    apply(1,sum) %>% # sum the number of reads
    sort %>% # sort in ascending order
    identity
  tax.lvl <- "Phylum_conf"
  phylum_tot <-agg.table.taxo(tab = tab, # aggregate my data at the targeted tax level
                              tax.lvl = tax.lvl,
                              tax.table = data_tmp$tax_table) %>%
    apply(1,sum) %>% # sum the number of reads
    sort %>% # sort in ascending order
    identity
  top10_order <- names(order_tot[(length(order_tot)-ifelse(length(order_tot)<10,length(order_tot),10)):length(order_tot)])
  top10_order <- top10_order[which(top10_order!="o__")]
  top10_class <- names(class_tot[(length(class_tot)-ifelse(length(class_tot)<10,length(class_tot),10)):length(class_tot)])
  top10_class <- top10_class[which(top10_class!="c__")]
  top10_phylum <- names(phylum_tot[(length(phylum_tot)-ifelse(length(phylum_tot)<10,length(phylum_tot),10)):length(phylum_tot)])
  top10_phylum <- top10_phylum[which(top10_phylum!="p__")]
  
  d <- d %>% mutate(Phylum=ifelse(!Phylum%in%c("p__",top10_phylum),"p__others",Phylum),
                    Class=ifelse(!Class%in%c("c__",top10_class),"c__others",Class),
                    Order=ifelse(!Order%in%c("o__",top10_order),"o__others",Order))
  d <- d %>%  mutate(Phylum=ifelse(Phylum=="p__","p__unknown",Phylum),
                     Class=ifelse(Class=="c__","c__unknown",Class),
                     Order=ifelse(Order=="o__","o__unknown",Order))
  
  d$reads <- data_tmp$taxa_sums()
  
  df <- d %>%
    ggsankey::make_long(1:3)
  
  TotalCount = nrow(d)
  # Step 2
  dagg <- df%>%
    dplyr::group_by(node)%>%
    tally()
  
  dagg <- dagg%>%
    dplyr::group_by(node)%>%
    dplyr::mutate(pct = n/TotalCount)%>%
    dplyr::mutate(tax_lvl=ifelse(grepl("c__",node),"class",
                                 ifelse(grepl("o__",node),"order","phylum")))
  
  
  # Step 3
  df2_16s <- merge(df, dagg, by.x = 'node', by.y = 'node', all.x = TRUE)
  
  pl[[i]] <- ggplot(df2_16s, aes(x = x, 
                            next_x = next_x, 
                            node = node, 
                            next_node = next_node, 
                            fill = factor(node),
                            label = paste0(node," n=", n, ' (',  round(pct* 100,1), '%)' ))) +
    ggsankey::geom_sankey(flow.alpha = 0.5,  color = "gray40", show.legend = TRUE) +
    ggsankey::geom_sankey_label(size = 3, color = "black", fill= "white", hjust = -0.1) + 
    theme_bw()+
    theme(legend.position = "none") +
    theme(axis.title = element_blank(), 
          axis.text.y = element_blank(), 
          axis.ticks = element_blank(),
          panel.grid = element_blank())+
    labs(title = "Sankey diagram - Bacteria") + 
    labs(fill = 'Nodes') + 
    scale_fill_viridis_d(option = "inferno")
  
  ggsave(paste0("Figures/sankey",i,".png"),pl[[i]], device="png", width=15,height = 10)
  
  # Table recap
  
  phylum <- filter(dagg,tax_lvl=="phylum")
  phylum %<>% mutate(node=gsub("p__","",node),
                     abun = paste0(n," (",round(pct*100, digits=2),"%)"))%>%
    dplyr::select(-c(2:4))
  
  class <- filter(dagg,tax_lvl=="class")
  class %<>% mutate(node=gsub("c__","",node),
                    abun = paste0(n," (",round(pct*100, digits=2),"%)"))%>%
    dplyr::select(-c(2:4))
  
  order <- filter(dagg,tax_lvl=="order")
  order %<>% mutate(node=gsub("o__","",node),
                    abun = paste0(n," (",round(pct*100, digits=2),"%)"))%>%
    dplyr::select(-c(2:4))
  
  if(nrow(phylum)<12){
    phylum <- rbind(phylum,data.frame(node=rep(NA,12-nrow(phylum)),abun=rep(NA,12-nrow(phylum))))
  }
  
  smry_tab <- cbind(phylum,class,order)
  smry_tab %<>% 
    add_row(.after = 10)%>%
    flextable::flextable()%>%
    flextable::set_header_labels(node...1="Name",abun...2="Count",node...3="Name",abun...4="Count",node...5="Name",abun...6="Count")%>%
    flextable::add_header_row(top = TRUE, values = c("Phylum", "Class","Order"), colwidths = c(2,2,2))%>%
    flextable::align(align = "center", part = "all") %>%
    flextable::autofit()%>%
    flextable::bold(part='header')
  
  
  flextable::save_as_docx(smry_tab,path=paste0("Figures/taxa_smry_",i,".docx"))
}
```

```{r}
rm(d,dagg,df,df2_16s,order,phylum,pl,smry_tab,tab,class,class_tot,order_tot,phylum_tot,tax.lvl,top10_class,top10_order,top10_phylum,TotalCount)
```


## Clust

```{r}
hmap_com <- NULL
hclust_com <- NULL
for(i in c("meco_16s","meco_16s_ns","meco_16s_relabfiltered")){
  
  data_tmp <- get(i)
  df <- data_tmp$otu_table
  df <- melt(as.matrix(df))
  colnames(df) <- c("ASVs","Samples","Reads")
  df%<>%
    mutate(Samples = as.factor(gsub("[A-Z]|-|(?=_).*","",Samples,perl = T)))
  clustsites <- hclust(vegan::vegdist(labdsv::hellinger(t(data_tmp$otu_table)),method = "horn"),method = "complete")
  ord <- clustsites$order
  
  ord2 <- rowSums(data_tmp$otu_table>0)%>%sort(decreasing = T)%>%names
  
  p <- df%>%
    ggplot(aes(x=ASVs,y=Samples,fill=log(Reads)))+
    geom_tile()+
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank())+
    scale_x_discrete(limits=levels(df$ASVs)[match(ord2,levels(df$ASVs))])+
        scale_y_discrete(limits=levels(df$Samples)[ord])

  
  hmap_com[[i]] <- p
  hclust_com[[i]] <- list(clustsites)
  
}
```

```{r}
hclust_com$meco_16s[[1]]$order
hclust_com$meco_16s_ns[[1]]$order
hclust_com$meco_16s_relabfiltered[[1]]$order
```

```{r}
part_full <- cutree(hclust_com$meco_16s[[1]],h=max(hclust_com$meco_16s[[1]]$height)*0.75)
part_ns <- cutree(hclust_com$meco_16s_ns[[1]],h=max(hclust_com$meco_16s_ns[[1]]$height)*0.75)
part_filt <- cutree(hclust_com$meco_16s_relabfiltered[[1]],h=max(hclust_com$meco_16s_relabfiltered[[1]]$height)*0.75)
df_part <- data.frame(part_full=part_full,part_ns=part_ns,part_filt=part_filt)
df_part %<>%
  mutate(site=gsub("[A-Z]|-|(?=_).*","",rownames(.),perl = T))
igraph::compare(part_filt,part_full)
igraph::compare(part_filt,part_ns)
igraph::compare(part_full,part_ns)

list_bestpart <- NULL
list_nc <- NULL
for(i in c("kl","ch","hartigan","cindex","db","silhouette","ratkowsky","ball","ptbiserial","gap","frey","mcclain","gamma","gplus","tau","dunn","hubert","sdindex","sdbw")){
  
  tmp_clust <- NbClust::NbClust(vegan::vegdist(labdsv::hellinger(t(data_tmp$otu_table)),method = "horn"),method = "ward.D2",index=i)
  list_nc[[i]] <- tmp_clust$Best.nc
  list_bestpart[[i]] <- tmp_clust$Best.partition
  
}


tibble::enframe(list_nc)%>%
  unnest(cols=value)%>%
  group_by(name)%>%
  mutate(nbc=ifelse(row_number()%%2,value,''),
         indxval=ifelse(!row_number()%%2,value,'')) %>% 
 summarise_all(funs(trimws(paste(., collapse = ''))))%>%
  dplyr::select(-c(2))%>%
  mutate(across(.cols=c(2,3),.fns=as.numeric))%>%
  ggplot(aes(x=name,y=nbc))+
  geom_point()+
  theme(axis.text.x = element_text(angle=45,vjust=.5))
```

```{r}
rm(ord,ord2,df,data_tmp,p,clustsites)
```

## Ordinate

```{r}
ordi_list <- NULL
ordi_plots_sp <- NULL
ordi_plots_sites <- NULL

for(i in c("meco_16s","meco_16s_ns","meco_16s_relabfiltered")){
  
  data_tmp <- get(i)
  data_tmp <- clone(data_tmp)
  orditmp <- ordinate(file2meco::meco2phyloseq(data_tmp), "NMDS", "horn")
  ordi_list[[i]] <- orditmp
  data_tmp$sample_table %<>% mutate(dumb_group = "sample")
  data_tmp$otu_table %<>% filter(rowSums(.)>1)
  data_tmp$tidy_dataset()
  
  data_tmp2 <- trans_abund$new(data_tmp,taxrank = "Genus",ntaxa = 8)
  
  df_ordi  <- merge(orditmp$species,data_tmp$tax_table,by = 'row.names')%>%
    mutate(Genus=ifelse(Genus%in%paste0("g__",data_tmp2$data_taxanames),Genus,"Other"))%>%
    mutate(Genus=gsub('g__','',Genus))%>%
    mutate(Genus=as.factor(Genus))%>%
    mutate(Genus=fct_relevel(Genus,c(data_tmp2$data_taxanames,"Other")))
  
  ordi_plots_sp[[i]] <- ggplot(df_ordi,aes(x=MDS1,y=MDS2,color=Genus,alpha=Genus))+
    geom_point(shape=16)+
    theme_classic()+
    ylab(paste0("NMDS 2"))+
    xlab(paste0("NMDS 1"))+
    geom_vline(xintercept=0,lty=2)+
    geom_hline(yintercept=0,lty=2)+
    scale_color_manual(values=colorRampPalette(brewer.pal(8, "Dark2"))(9))+
    scale_alpha_manual(values=c(rep(1,8),.5))
  
  df_ordi_sites <- orditmp$points
  df_ordi_sites %<>%
      as.data.frame()%>%
      mutate(site=gsub("[A-Z]|-|(?=_).*","",rownames(.),perl = T))%>%
      left_join(df_part)
  
  for(j in c("part_full","part_ns","part_filt")){  
    
    ordi_plots_sites[[i]][[j]] <-  ggplot(df_ordi_sites,aes(x=MDS1,y=MDS2,label = site,color=!!as.factor(df_part[,j])))+
      geom_point()+
      theme_dark()+
      # geom_text()+
      scale_color_manual(values=c('#e6194b', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4', '#46f0f0', '#f032e6', '#bcf60c', '#fabebe', '#008080'),
                         name=paste0("Partition based on ",gsub("part_","",j)," communities"))
  }
}
```


## Picrust2

### Prepare inputs

Create from R picrust2 inputs
Galaxy Picrust2 needs a .Biom and .Fasta file.

.Fasta -> sequences and Header
.Biom -> tougher to create, will create a .Tsv and convert to .Biom within Galaxy
```{r}
seqs <- as.list(gsub("s__","",meco_16s_ns$tax_table$sequence))
names_seqs <- rownames(meco_16s_ns$tax_table)
seqinr::write.fasta(seqs,names_seqs,"outputs/fasta4picrust2.fasta")
```

```{r}
data_temp <- read_delim(file = "frogs_input/Galaxy169-[FROGS_BIOM_to_TSV__abundance.tsv].tsv", # read the tsv file
                        delim = "\t", escape_double = FALSE, 
                        trim_ws = TRUE)
data_temp%<>%
    filter(observation_name%in%names_seqs)

data_temp <- data_temp[,c(1:12,which(colnames(data_temp)%in%meco_16s_ns$sample_table$sample_id))] 

write_delim(data_temp,
            file = "outputs/tsv4picrust.tsv",
            delim = "\t", )
```



```{r}
seqs <- as.list(gsub("s__","",meco_16s_relabfiltered$tax_table$sequence))
names_seqs <- rownames(meco_16s_relabfiltered$tax_table)
seqinr::write.fasta(seqs,names_seqs,"outputs/fasta4picrust2_filt.fasta")
```

```{r}
data_temp <- read_delim(file = "frogs_input/Galaxy169-[FROGS_BIOM_to_TSV__abundance.tsv].tsv", # read the tsv file
                        delim = "\t", escape_double = FALSE, 
                        trim_ws = TRUE)
data_temp%<>%
    filter(observation_name%in%names_seqs)

data_temp <- data_temp[,c(1:12,which(colnames(data_temp)%in%meco_16s_relabfiltered$sample_table$sample_id))] 

write_delim(data_temp,
            file = "outputs/tsv4picrust_filt.tsv",
            delim = "\t", )
```


### Alignment and stuff

```{r}
picrust_closestref <-  read_delim("picrust2/Galaxy228-[FROGSFUNC_1_placeseqs_and_copynumbers__frogsfunc_placeseqs_closests_ref_sequences.txt].tsv", # read the tsv file
                                  delim = "\t", escape_double = FALSE, 
                                  trim_ws = TRUE)
```

check ASVs discrepencies between Picrust2 and my cleaned dataset
```{r}
nrow(meco_16s_ns$tax_table) #12792 ASVs in my cleaned dataset
nrow(picrust_closestref) # 12792 ASVs in picrust

all(rownames(meco_16s_ns$tax_table) %in% picrust_closestref$`#ASV`)
```

```{r}
picrust_closestref %>%
    ggplot()+
    geom_point(aes(x=NSTI,y=`%cov`,color="darkorange"))+
    geom_point(aes(x=NSTI,y=`%id`,color="darkorchid4"))+
    theme_classic2()+
    ylab("Metric %") +
     scale_color_identity(name = "Blast metrics",
                          breaks = c("darkorange", "darkorchid4"),
                          labels = c("Coverage", "Identity"),guide = "legend")+ 
    scale_x_continuous(breaks = scales::breaks_width(2),expand = c(0, 0))+
    ggplot(picrust_closestref)+
    geom_point(aes(x=NSTI,y=score), color="aquamarine4")+
    theme_classic2()+
    ylab("Blast score")
```

Clusters with NSTI > 2 are considered poorly represented in the Picrust2 reference database.
Additionally, a coverage < 80% is pretty low 

```{r}
(picrust_closestref %>%
    ggplot(aes(x=score,y=`%id`))+
    geom_point()+
    picrust_closestref %>%
    ggplot(aes(x=`%id`,y=`%cov`))+
    geom_point()+
    picrust_closestref %>%
    ggplot(aes(x=score,y=`%cov`))+
    geom_point())/
    (picrust_closestref %>%
         filter(`%cov`>80&`%id`>80&NSTI<2)%>%
    ggplot(aes(x=score,y=`%id`))+
    geom_point()+
    picrust_closestref %>%
         filter(`%cov`>80&`%id`>80&NSTI<2)%>%
    ggplot(aes(x=`%id`,y=`%cov`))+
    geom_point()+
    picrust_closestref %>%
         filter(`%cov`>80&`%id`>80&NSTI<2)%>%
    ggplot(aes(x=score,y=`%cov`))+
    geom_point())
```

```{r}
picrust_closestref %>%
    filter(NSTI<2)%>%
    filter(`%cov`>80&`%id`>80)%>%
    nrow()/nrow(picrust_closestref) # 97% of OTUs

picrust_closestref %>%
    filter(NSTI<2)%>%
    filter(`%cov`>80&`%id`>80)%>%
    summarise(sum_seq=sum(`Nb sequences`))/sum(picrust_closestref$`Nb sequences`) # Keep 99% of sequences
```

I don't have much confidence in these ASVs associated predictions cuz poorly mapped in Picrust2 reference db so filter them out. 

```{r}
asvs_picrust <- picrust_closestref %>%
    filter(NSTI<2&`%cov`>80&`%id`>80)%>%
    select(`#ASV`)
discarded_picrust <- picrust_closestref %>%
         filter(!`#ASV`%in%asvs_picrust$`#ASV`)%>%select(`#ASV`)

asvs_picrust <- asvs_picrust$`#ASV` #12486 asvs
discarded_picrust <- discarded_picrust$`#ASV` # 306 asvs
```

Set cov and Id to 0.8 in galaxy FrogsFunc 2.

Investigate Excluded ASVs and their repartition across my samples.
306 ASVs should be excluded with this filtering

```{r}
meco_picrust_16s <- clone(meco_16s_ns)
meco_picrust_16s$tax_table%<>%
    mutate(is_picrust=ifelse(rownames(.)%in%asvs_picrust,"Yes","No"))%>%
    mutate(cluster=rownames(.))
meco_picrust_16s$otu_table%>%
    mutate(cluster=rownames(.))%>%
    reshape2::melt()%>%
    left_join(meco_picrust_16s$tax_table)%>%
    ggplot(aes(x=variable,y=value,fill=is_picrust))+
    geom_bar(stat="identity",width = 1)+
    theme(axis.text.x = element_blank())+
    ggtitle("Reads of picrust or not OTUs")+
    scale_y_continuous(expand = c(0,0))+
    meco_picrust_16s$otu_table%>%
   mutate(across(everything(), ~ .x/sum(.)))%>%
    mutate(cluster=rownames(.))%>%
    reshape2::melt()%>%
    left_join(meco_picrust_16s$tax_table)%>%
    ggplot(aes(x=variable,y=value,fill=is_picrust))+
    geom_bar(stat="identity",width = 1)+
    theme(axis.text.x = element_blank())+
    ggtitle("Reads proportion of picrust or not OTUs")+
    scale_y_continuous(expand = c(0,0))
```

```{r}
rownames(meco_16s_ns$sample_table) <- meco_16s_ns$sample_table$sample_id
meco_16s_picrust2 <- clone(meco_16s_ns)

meco_16s_picrust2$otu_table %<>% filter(rownames(.)%in%asvs_picrust)

meco_16s_picrust2$tidy_dataset()
```

```{r}
ab_trans_meco_16s_picrust2 <- trans_abund$new(meco_16s_picrust2,taxrank = "Order",ntaxa = 8)
order_relab_16s_picrust2 <- ab_trans_meco_16s_picrust2$plot_bar(others_color = "grey70", xtext_keep = FALSE, legend_text_italic = FALSE)+
    geom_col(width = 1)+
    ggtitle("MAPP 16s")+
    theme(plot.title = element_text(face='bold'))
order_relab_16s_picrust2
```

###Functions and pathways

We investigate functions and pathways using two distinct databases (Kegg and MetaCyc).
#### Load and ID xcluded ASVs

```{r}
pathways_db <- c("Kegg","MetaCyc")
```


```{r}
kegg_files <- NULL
metacyc_files <- NULL
for(i in pathways_db){
    
    # get file from good database
    shrtct <- ifelse(i=="Kegg","KO","EC")
    
    # load function copy number predictions
    if(shrtct == "KO"){
      kegg_files[["picrust_fct_pred_copynb"]] <- read_delim("picrust2/Galaxy267-[FROGSFUNC_2_functions__KO_copynumbers_predicted.tsv].tsv",
                                              delim = "\t", escape_double = F, trim_ws = T)
      
      kegg_files[["picrust_fct_unstrat"]] <- read_delim("picrust2/Galaxy269-[FROGSFUNC_2_functions___frogsfunc_functions_unstrat_KO.tsv].tsv",
                                              delim = "\t", escape_double = F, trim_ws = T)
    }
    else{
       metacyc_files[["picrust_fct_pred_copynb"]] <- read_delim("picrust2/Galaxy266-[FROGSFUNC_2_functions__EC_copynumbers_predicted.tsv].tsv",
                                              delim = "\t", escape_double = F, trim_ws = T)
      
      metacyc_files[["picrust_fct_unstrat"]] <- read_delim("picrust2/Galaxy268-[FROGSFUNC_2_functions___frogsfunc_functions_unstrat_EC.tsv].tsv",
                                              delim = "\t", escape_double = F, trim_ws = T)
    }
    

}
    # Load asv excluded by galaxy FROGs
    galaxy_Xcluded <- read_delim("picrust2/Galaxy265-[FROGSFUNC_2_functions__frogsfunc_functions_asv_excluded.tsv].tsv",
                                              delim = "\t", escape_double = F, trim_ws = T)
    # load normalize marker abundance
    picrust_norm_marker <- read_delim("picrust2/Galaxy263-[FROGSFUNC_2_functions__frogsfunc_functions_marker_norm.tsv].tsv",
                                              delim = "\t", escape_double = F, trim_ws = T)
```


```{r}
length(discarded_picrust)
nrow(galaxy_Xcluded)
galaxy_Xcluded$`#Cluster` %in% discarded_picrust

setdiff(discarded_picrust,galaxy_Xcluded$`#Cluster`) 
```

```{r}
picrust_closestref%>%
  filter(`#ASV`%in%setdiff(discarded_picrust,galaxy_Xcluded$`#Cluster`)) #difference due to 80% ID. Frogs on Galaxy is likely conservative while I specified "Strictly Inferior to .8"
```

```{r}
asvs_picrust <- picrust_closestref %>%
    filter(NSTI<2&`%cov`>80&`%id`>=80)%>%
    select(`#ASV`)
discarded_picrust <- picrust_closestref %>%
         filter(!`#ASV`%in%asvs_picrust$`#ASV`)%>%select(`#ASV`)

asvs_picrust <- asvs_picrust$`#ASV` #12499 asvs
discarded_picrust <- discarded_picrust$`#ASV` #293 ASVs Now we match Galaxy's Xclusion
```


#### Xplore functions

```{r}
amino_color <- c("#4e8937",
                 "#733cc9",
                 "#6dc140",
                 "#cf4cc3",
                 "#63b889",
                 "#d24172",
                 "#4ca3ae",
                 "#d74c33",
                 "#656ad1",
                 "#cf9133",
                 "#6d2f7d",
                 "#a6a34d",
                 "#bb86cb",
                 "#4a5c2f",
                 "#6f97d0",
                 "#814025",
                 "#434a7b",
                 "#cf8c70",
                 "#78334b",
                 "#d0849f")
```


```{r}
plot_fct <- NULL
plot_fct_tgt <- NULL
ordiplot_fct <- NULL
donutplot_fct <- NULL
for(i in pathways_db){
  if(i == "Kegg"){
    d_tmp <- kegg_files
  }else{
    d_tmp <- metacyc_files
  }
  names(d_tmp$picrust_fct_unstrat)[grepl("L001",names(d_tmp$picrust_fct_unstrat))] <- gsub("[A-Z]|-|(?=_).*","",names(d_tmp$picrust_fct_unstrat)[grepl("L001",names(d_tmp$picrust_fct_unstrat))] ,perl = T)
  
  print("% of NA")
  a <- d_tmp$picrust_fct_unstrat%>%
    select(c(1:4,which(names(.)%in%combined$Sample)))%>%
    mutate(across(5:ncol(.),~(.x/sum(.))*100))%>%
    pivot_longer(cols =c(5:ncol(.)))%>%
    separate(col=classification,into = paste0("c",1:4),sep = ";")%>%
    summarise(total = sum(value))
  b <- d_tmp$picrust_fct_unstrat%>%
    select(c(1:4,which(names(.)%in%combined$Sample)))%>%
    mutate(across(5:ncol(.),~(.x/sum(.))*100))%>%
    pivot_longer(cols =c(5:ncol(.)))%>%
    separate(col=classification,into = paste0("c",1:4),sep = ";")%>%
    group_by(c1,c2,c3,c4)%>%
    summarise(total = sum(value))%>%
    filter(is.na(c1))
  
  print((b$total/a$total)*100)
    
    
  plot_fct[[i]] <- d_tmp$picrust_fct_unstrat%>%
    select(c(1:4,which(names(.)%in%combined$Sample)))%>%
    mutate(across(5:ncol(.),~(.x/sum(.))*100))%>%
    pivot_longer(cols =c(5:ncol(.)))%>%
    separate(col=classification,into = paste0("c",1:4),sep = ";")%>%
    ggplot(aes(x=name,y=value,fill=c1))+
    geom_bar(stat = "identity",position = "stack",width=1)+
    scale_fill_manual(values =RColorBrewer::brewer.pal(11,'Set3'))+
    ylab("Function %")+
    xlab("Samples")+
    theme_classic2()+
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank())+
    scale_y_continuous(expand = c(0, 0))+
    d_tmp$picrust_fct_unstrat%>%
    select(c(1:4,which(names(.)%in%combined$Sample)))%>%
    pivot_longer(cols =c(5:ncol(.)))%>%
    separate(col=classification,into = paste0("c",1:4),sep = ";")%>%
    ggplot(aes(x=name,y=value,fill=c1))+
    geom_bar(stat = "identity",position = "stack",width=1)+
    scale_fill_manual(values =RColorBrewer::brewer.pal(11,'Set3'))+
    ylab("Function %")+
    xlab("Samples")+
    theme_classic2()+
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank())+
    scale_y_continuous(expand = c(0, 0))
  
  plot_fct_tgt[[i]] <- (d_tmp$picrust_fct_unstrat%>%
    select(c(1:4,which(names(.)%in%combined$Sample)))%>%
    filter(grepl("glucosidase",classification))%>%
    mutate(across(5:ncol(.),~(.x/sum(.))*100))%>%
    pivot_longer(cols =c(5:ncol(.)))%>%
    separate(col=classification,into = paste0("c",1:4),sep = ";")%>%
    ggplot(aes(x=name,y=value,fill=c4))+
    geom_bar(stat = "identity",position = "stack",width=1)+
    scale_fill_manual(values =RColorBrewer::brewer.pal(11,'Set3'))+
    ylab("Function %")+
    xlab("Samples")+
    theme_classic2()+
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank())+
    scale_y_continuous(expand = c(0, 0))+
    d_tmp$picrust_fct_unstrat%>%
    select(c(1:4,which(names(.)%in%combined$Sample)))%>%
    filter(grepl("aminopep",classification))%>%
    mutate(across(5:ncol(.),~(.x/sum(.))*100))%>%
    pivot_longer(cols =c(5:ncol(.)))%>%
    separate(col=classification,into = paste0("c",1:4),sep = ";")%>%
    ggplot(aes(x=name,y=value,fill=c4))+
    geom_bar(stat = "identity",position = "stack",width=1)+
    scale_fill_manual(values = amino_color)+
    ylab("Enzymes")+
    xlab("Samples")+
    theme_classic2()+
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank())+
    scale_y_continuous(expand = c(0, 0))+
    plot_annotation(title = paste0(i,' Functions')))/
    (d_tmp$picrust_fct_unstrat%>%
    select(c(1:4,which(names(.)%in%combined$Sample)))%>%
    filter(grepl("glucosidase",classification))%>%
    pivot_longer(cols =c(5:ncol(.)))%>%
    separate(col=classification,into = paste0("c",1:4),sep = ";")%>%
    ggplot(aes(x=name,y=value,fill=c4))+
    geom_bar(stat = "identity",position = "stack",width=1)+
    scale_fill_manual(values =RColorBrewer::brewer.pal(11,'Set3'))+
    ylab("Function %")+
    xlab("Samples")+
    theme_classic2()+
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank())+
    scale_y_continuous(expand = c(0, 0))+
    d_tmp$picrust_fct_unstrat%>%
    select(c(1:4,which(names(.)%in%combined$Sample)))%>%
    filter(grepl("aminopep",classification))%>%
    pivot_longer(cols =c(5:ncol(.)))%>%
    separate(col=classification,into = paste0("c",1:4),sep = ";")%>%
    ggplot(aes(x=name,y=value,fill=c4))+
    geom_bar(stat = "identity",position = "stack",width=1)+
    scale_fill_manual(values =amino_color)+
    ylab("Enzymes")+
    xlab("Samples")+
    theme_classic2()+
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank())+
    scale_y_continuous(expand = c(0, 0))+
    plot_annotation(title = paste0(i,' Functions')))
  
  
  ordi_fct <- d_tmp$picrust_fct_unstrat%>%
    select(c(which(names(.)%in%combined$Sample)))%>%
    t()%>%
    metaMDS()

  df_ordi_fct_sites <- ordi_fct$points
  df_ordi_fct_sites %<>%
    as.data.frame()%>%
    mutate(Sample=rownames(.))%>%
    left_join(combined)
  
  ordiplot_fct[[i]] <- ggplot(df_ordi_fct_sites,aes(x=MDS1,y=MDS2,label = Sample,color=Country))+
    geom_point()+
    theme_dark()+
    # geom_text()+
    scale_color_manual(values=country_color)

  df_donut <- d_tmp$picrust_fct_unstrat%>%
    select(c(1:4,which(names(.)%in%combined$Sample)))%>%
    pivot_longer(cols =c(5:ncol(.)))%>%
    separate(col=classification,into = paste0("c",1:4),sep = ";")%>%
    drop_na()%>%
    group_by(c1,c2,c3,c4)%>%
    summarise(abund = sum(value))%>%
    mutate(high_lvl=c1)%>%
    reshape2::melt(measure.vars = c("c1","c2","c3","c4"))%>%
    group_by(variable)%>%
    mutate(relab = (abund/sum(abund))*100)%>%
    group_by(high_lvl,variable,value)%>%
    summarise(relab_smr = sum(relab))
  
  
  donutplot_fct[[i]] <- df_donut %>%
    ggplot(aes(x=variable,y=relab_smr,fill=high_lvl))+
    geom_bar(stat = "identity",position = "stack",color='white',width=1)+
    scale_fill_manual(values =RColorBrewer::brewer.pal(11,'Set3'))+
    ylab("Function %")+
    xlab("Samples")+
    theme_void()+
    coord_polar(theta = 'y')+
    ggtitle("Overall functional diversity without NAs")
  
  
}
```

```{r}
kegg_plots <- (plot_fct$Kegg)/(donutplot_fct$Kegg+ordiplot_fct$Kegg)
metacyc_plots <- (plot_fct$MetaCyc)/(donutplot_fct$MetaCyc+ordiplot_fct$MetaCyc)

kegg_plots_tgt <- plot_fct_tgt$Kegg
metacyc_plots_tgt <- plot_fct_tgt$MetaCyc

ggsave("Figures/keggplot.png",kegg_plots,width = 10,height = 10)
ggsave("Figures/metacycplot.png",metacyc_plots,width = 10,height = 10)

ggsave("Figures/keggplottgt.png",kegg_plots_tgt,width = 10,height = 10)
ggsave("Figures/metacycplottgt.png",metacyc_plots_tgt,width = 10,height = 10)
```

#### Xplore pathways

```{r}
kegg_files[["picrust_pathway_unstrat"]] <- read_delim("picrust2/Galaxy271-[FROGSFUNC_3_pathways__frogsfunc_pathways_unstrat.tsv].tsv",
                                                      delim = "\t", escape_double = F, trim_ws = T)

metacyc_files[["picrust_pathway_unstrat"]] <- read_delim("picrust2/Galaxy273-[FROGSFUNC_3_pathways__frogsfunc_pathways_unstrat.tsv].tsv",
                                                         delim = "\t", escape_double = F, trim_ws = T)
```

```{r}
names(kegg_files$picrust_pathway_unstrat)[grepl("L001",names(kegg_files$picrust_pathway_unstrat))] <- gsub("[A-Z]|-|(?=_).*","",names(kegg_files$picrust_pathway_unstrat)[grepl("L001",names(kegg_files$picrust_pathway_unstrat))] ,perl = T)

getPalette <- colorRampPalette(RColorBrewer::brewer.pal(12,'Set3'))

kegg_files$picrust_pathway_unstrat%>%
  select(c(1:4,which(names(.)%in%combined$Sample)))%>%
    mutate(across(5:ncol(.),~(.x/sum(.))*100))%>%
    pivot_longer(cols =c(5:ncol(.)))%>%
    separate(col=classification,into = paste0("c",1:4),sep = ";")%>%
    ggplot(aes(x=name,y=value,fill=c2))+
    geom_bar(stat = "identity",position = "stack",width=1)+
    scale_fill_manual(values = getPalette(35))+
    ylab("Function %")+
    xlab("Samples")+
    theme_classic2()+
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank())+
    scale_y_continuous(expand = c(0, 0))


names(metacyc_files$picrust_pathway_unstrat)[grepl("L001",names(metacyc_files$picrust_pathway_unstrat))] <- gsub("[A-Z]|-|(?=_).*","",names(metacyc_files$picrust_pathway_unstrat)[grepl("L001",names(metacyc_files$picrust_pathway_unstrat))] ,perl = T)

metacyc_files$picrust_pathway_unstrat%>%
  select(c(1:4,which(names(.)%in%combined$Sample)))%>%
    mutate(across(5:ncol(.),~(.x/sum(.))*100))%>%
    pivot_longer(cols =c(5:ncol(.)))%>%
    separate(col=classification,into = paste0("c",1:4),sep = ";")%>%
    ggplot(aes(x=name,y=value,fill=c2))+
    geom_bar(stat = "identity",position = "stack",width=1)+
    scale_fill_manual(values = getPalette(37))+
    ylab("Function %")+
    xlab("Samples")+
    theme_classic2()+
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank())+
    scale_y_continuous(expand = c(0, 0))

```

```{r}
metacyc_files$picrust_pathway_unstrat%>%
  select(c(1:4,which(names(.)%in%combined$Sample)))%>%
    mutate(across(5:ncol(.),~(.x/sum(.))*100))%>%
    pivot_longer(cols =c(5:ncol(.)))%>%
    separate(col=classification,into = paste0("c",1:4),sep = ";")%>%
    ggplot(aes(x=name,y=value,fill=c4))+
    geom_bar(stat = "identity",position = "stack",width=1)+
    scale_fill_manual(values = getPalette(414))+
    ylab("Function %")+
    xlab("Samples")+
    theme_classic2()+
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank())+
    scale_y_continuous(expand = c(0, 0))+
  theme(legend.position = "none")

```

```{r}
plot_pth <- NULL
ordiplot_pth <- NULL
for(i in pathways_db){
  if(i == "Kegg"){
    d_tmp <- kegg_files
  }else{
    d_tmp <- metacyc_files
  }
  names(d_tmp$picrust_pathway_unstrat)[grepl("L001",names(d_tmp$picrust_pathway_unstrat))] <- gsub("[A-Z]|-|(?=_).*","",names(d_tmp$picrust_pathway_unstrat)[grepl("L001",names(d_tmp$picrust_pathway_unstrat))] ,perl = T)
  
  print("% of NA")
  a <- d_tmp$picrust_pathway_unstrat%>%
    select(c(1:4,which(names(.)%in%combined$Sample)))%>%
    mutate(across(5:ncol(.),~(.x/sum(.))*100))%>%
    pivot_longer(cols =c(5:ncol(.)))%>%
    separate(col=classification,into = paste0("c",1:4),sep = ";")%>%
    summarise(total = sum(value))
  b <- d_tmp$picrust_pathway_unstrat%>%
    select(c(1:4,which(names(.)%in%combined$Sample)))%>%
    mutate(across(5:ncol(.),~(.x/sum(.))*100))%>%
    pivot_longer(cols =c(5:ncol(.)))%>%
    separate(col=classification,into = paste0("c",1:4),sep = ";")%>%
    group_by(c1,c2,c3,c4)%>%
    summarise(total = sum(value))%>%
    filter(is.na(c1))
  
  print((b$total/a$total)*100)
    
    
  plot_pth[[i]] <- d_tmp$picrust_pathway_unstrat%>%
    select(c(1:4,which(names(.)%in%combined$Sample)))%>%
    mutate(across(5:ncol(.),~(.x/sum(.))*100))%>%
    pivot_longer(cols =c(5:ncol(.)))%>%
    separate(col=classification,into = paste0("c",1:4),sep = ";")%>%
    ggplot(aes(x=name,y=value,fill=c2))+
    geom_bar(stat = "identity",position = "stack",width=1)+
    scale_fill_manual(values = getPalette(37))+
    ylab("Function %")+
    xlab("Samples")+
    theme_classic2()+
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank())+
    scale_y_continuous(expand = c(0, 0))+
    theme(legend.position = "n")+
    d_tmp$picrust_pathway_unstrat%>%
    select(c(1:4,which(names(.)%in%combined$Sample)))%>%
    pivot_longer(cols =c(5:ncol(.)))%>%
    separate(col=classification,into = paste0("c",1:4),sep = ";")%>%
    ggplot(aes(x=name,y=value,fill=c2))+
    geom_bar(stat = "identity",position = "stack",width=1)+
    scale_fill_manual(values = getPalette(37))+
    ylab("Function %")+
    xlab("Samples")+
    theme_classic2()+
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank())+
    scale_y_continuous(expand = c(0, 0))
  
  ordi_pth <- d_tmp$picrust_pathway_unstrat%>%
    select(c(which(names(.)%in%combined$Sample)))%>%
    t()%>%
    metaMDS()

  df_ordi_pth_sites <- ordi_pth$points
  df_ordi_pth_sites %<>%
    as.data.frame()%>%
    mutate(Sample=rownames(.))%>%
    left_join(combined)
  
  ordiplot_pth[[i]] <- ggplot(df_ordi_pth_sites,aes(x=MDS1,y=MDS2,label = Sample,color=Country))+
    geom_point()+
    theme_dark()+
    scale_color_manual(values=country_color)
}
```


#### Xplore diversity within picrust2

```{r}
abfct_plots <- NULL
cntfct_plots <- NULL
mapfct_plots <- NULL
for(i in pathways_db){
  if(i == "Kegg"){
    d_tmp <- kegg_files
  }else{
    d_tmp <- metacyc_files
  }
  names(d_tmp$picrust_fct_unstrat)[grepl("L001",names(d_tmp$picrust_fct_unstrat))] <- gsub("[A-Z]|-|(?=_).*","",names(d_tmp$picrust_fct_unstrat)[grepl("L001",names(d_tmp$picrust_fct_unstrat))] ,perl = T)
  
  abfct_plots[[i]] <- d_tmp$picrust_fct_unstrat%>%
    select(5:ncol(.))%>%
    summarise(across(.cols=1:ncol(.),.fns=sum))%>%
    reshape2::melt()%>%
    rename(Sample=variable)%>%
    left_join(combined)%>%
    ggplot(aes(x=Country,y=value,color=Country))+
    geom_jitter()+
    scale_color_manual(values=country_color)+
    theme_classic2()+
    theme(axis.text.x = element_text(angle=90))
  
  cntfct_plots[[i]] <- d_tmp$picrust_fct_unstrat%>%
    select(5:ncol(.))%>%
    summarise(across(.cols=1:ncol(.),.fns=~sum(.x>0)))%>%
    reshape2::melt()%>%
    rename(Sample=variable)%>%
    left_join(combined)%>%
    ggplot(aes(x=Country,y=value,color=Country))+
    geom_jitter()+
    scale_color_manual(values=country_color)+
    theme_classic2()+
    theme(axis.text.x = element_text(angle=90))  
  
  (sites <- st_as_sf(d_tmp$picrust_fct_unstrat%>%
                       select(5:ncol(.))%>%
                       summarise(across(.cols=1:ncol(.),.fns=~sum(.x>0)))%>%
                       reshape2::melt()%>%
                       rename(Sample=variable)%>%
                       left_join(combined)%>%filter(X!="NA"), coords = c("X", "Y"), 
                     crs = 4326, agr = "constant"))
  
  # Plot the map
  mapfct_plots[[i]] <- ggplot() +
    geom_sf(data = world_lambert, fill = "grey", color = "darkgrey", size = 0.1)+
    geom_sf(data = sites, size = 3, shape = 23, aes(fill = value),alpha=.7) +
    ggtitle("MAPP 16s sites") +
    theme(plot.title = element_text(hjust = 0.5, size = 16))+
    theme_minimal()+
    theme(panel.background = element_rect(fill = "azure"))+
    scale_fill_viridis_c()
}
```

## Ubiquist ASVs

```{r}
ubiquist_asvs <- meco_16s_relabfiltered$otu_table%>%
  mutate(name=rownames(.))%>%
  reshape2::melt()%>%
  group_by(name)%>%
  summarise(prev=sum(value>0))%>%
  filter(prev>175)

meco_16s_relabfiltered$tax_table%>%
  filter(rownames(.)%in%ubiquist_asvs$name)%>%
  dplyr::select(Kingdom_conf_rdp,Phylum_conf_rdp,Order_conf_rdp,Family_conf_rdp,Genus_conf_rdp)%>%
  mutate(name=rownames(.))%>%
  reshape2::melt(id.vars = "name")%>%
  mutate(known=ifelse(nchar(value)<4,"no","yes"))%>%
  ggplot(aes(x=variable,y=name,fill=known))+
  geom_tile()
```


# D - Sites

We collated data from Google Earth Engine (GEE) using sample coordinate provided by our collaborators.
These data are from different datasets and satellite sources available on  [GEE website](https://developers.google.com/earth-engine/datasets).

Temporal data (Terra Climate, SMAP soil, Vegetation, Productivity) are average over years  and tagged "_lt" for "long-term".
In addition to these long term data we retrieved monthly data from march (_03) to october (_10) of the sampling year (2021).
These will be used to produce "short-term" (_st) data with the hypothesis that microbial communities are strongly affected by recent meteorology.

For each variable is given: name - unit - scale - resolution.


## Map Sites

```{r}
world <- ne_countries(scale = "medium", returnclass = "sf")

# Subset the world data to include only the specified latitude range
cropping <- as(raster::extent(-180, 180, 20, 90), "SpatialPolygons")


world_subset <- raster::crop(as_Spatial(world),cropping)
# Create a Lambert azimuthal equal-area projection centered on the North Pole
lambert_proj <- st_crs("+proj=laea +lat_0=90 +lon_0=0 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs")
world_lambert <- st_transform(st_as_sf(world_subset), crs = lambert_proj)


(sites <- st_as_sf(meco_16s_ns$sample_table, coords = c("X", "Y"), 
                   crs = 4326, agr = "constant"))

# Plot the map
ggplot() +
    geom_sf(data = world_lambert, fill = "grey", color = "darkgrey", size = 0.1)+
    geom_sf(data = sites, size = 3, shape = 23, fill = "coral",alpha=.7) +
    ggtitle("MAPP 16s sites") +
    theme(plot.title = element_text(hjust = 0.5, size = 16))+
    theme_minimal()+
    theme(panel.background = element_rect(fill = "azure"))
```


## Available Data

### Terra Climate

These are monthly weather data.
Long term : 2016/01/01 to 2021/01/01

With scale being a scaling factor by which to multiply the variable to get the right values.

**aet**: actual evapotranspiration - mm - 0.1 - 4638.3m
**def**: Climate water deficit - mm - 0.1 - 4638.3m
**pdsi**: Palmer drought severity index (temperature and precipitation -10 to +10 : dry to wet) - no unit - 0.01 - 4638.3m  
**pet**: Reference evapotranspiration - mm - 0.1 - 4638.3m  
**pr**: Precipitation accumulation (@ the end of the month) - mm - no scale - 4638.3m  
**srad**: Downward surface shortwave radiation - W/m^2 - 0.1 - 4638.3m  
**swe**: Snow water equivalent - mm - no scale - 4638.3m  
**tmmn**: Minimum Temperature - Â°C - 0.1 - 4638.3m  
**tmmx**: Maximum Temperature - Â°C - 0.1 - 4638.3m  
**vap**: Vapor pressure - KPa - 0.001 - 4638.3m  
**vpd**: Vapor pressure deficit - kPa - 0.01 - 4638.3m  
**moist**: Soil moisture - mm - 0.1 - 4638.3m  

### SMAP soil

NASA/SMAP/SPL3SMP_E/005

These are monthly soil data.
Long term : 2016/01/01 to 2021/01/01

**soil_moisture**: Top layer soil moisture (0 - 5) - volume fraction - no scale - 9000 m


### Topography

USGS/GMTED2010_FULL

**elevation**: Min elevation - m - no scale - 231.92m

### Vegetation

MODIS/006/MOD13Q1
MODIS/006/MCD15A3H

Long term : 2016/01/01 to 2021/01/01

**ndvi**: Normalized difference vegetation index over 16days - no unit - 0.0001 - 250m
**evi**: Enhanced vegetation index over 16days - no unit - 0.0001 - 250m
**lai**: Leaf area index over 4days - no unit - 0.1 - 500m
**fpar**: Fraction of absorbed photosynthecatilly active radiation (400-700nm) absorbed by the green elements of a vegetation canopy over 4days - no unit - 0.001 - 500m

### Productivity

MODIS/006/MOD17A2H

Long term : 2016/01/01 to 2021/01/01

**gpp**: Gross primary production 8days - kg*C/m^2 - 0.0001 - 500m
**npp**: Net primary production 8days - kg*C/m^2 - 0.0001 - 500m

### Open Land Map Soil

OpenLandMap/SOL/SOL_BULKDENS-FINEEARTH_USDA-4A1H_M/v02
OpenLandMap/SOL/SOL_CLAY-WFRACTION_USDA-3A1A1A_M/v02
OpenLandMap/SOL/SOL_ORGANIC-CARBON_USDA-6A1C_M/v02
OpenLandMap/SOL/SOL_PH-H2O_USDA-4C1A2A_M/v02
OpenLandMap/SOL/SOL_WATERCONTENT-33KPA_USDA-4B1C_M/v01

**bulk**: Bulk density @ 0 cm depth - kg/m^3 - 10 - 250m
**clay**: Clay content @ 0 cm depth - % (kg / kg) - no scale - 250m
**soc**: Organic carbon content @0 cm depth - g/kg - 5 - 250m
**ph**: pH in H20 @ 0 cm depth - pH - 10 - 250m
**water**: Water content @ field capacity (33kPa) @ 0 cm depth - % - no scale - 250m

### Human variables: Global Human Modification

CSP/HM/GlobalHumanModification

**ghm**: Global human modification index - fraction of a km^2 - no scale - 1000m



## Select sites & deal with NAs

```{r}
site_data_raw <- read.csv("../../ressource/Site_edaphic_data/MappPtsSampled.csv")
site_data_raw %<>%
    mutate(Sample=ifelse(nchar(Sample)<3,paste0("0",Sample),Sample))%>%
    mutate(Sample=ifelse(nchar(Sample)<3,paste0("0",Sample),Sample))%>%
    mutate(Sample=ifelse(grepl("^8",Sample),paste0("0",Sample),Sample))%>% # fix 87a and 87b sample ids
    arrange(Sample)# fix sample ID to match the format of other MAPP datasets

site_data <- site_data_raw %>% filter(Sample%in%meco_16s_ns$sample_table$Sample)%>% # replace the NA placeholder -9999 with NAs
    mutate(across(.cols= colnames(site_data_raw),.fns = ~replace(., . ==  -9999 , NA)))%>%
  left_join(site_coordinates)
```


### Count NAs and Imputations


```{r}
site_data %<>% # remove short term variable of wrong months from site data
    dplyr::select(names(site_data)[!grepl('06|07|08|09|10', names(site_data))])%>%
    rename(soil_moisture_04=soil_moisture_03_1)

var_missing_val <- as.data.frame(colSums(is.na(site_data)))%>% # plot NAs counts and %of variables
    rename(nb_na=`colSums(is.na(site_data))`)%>%
    mutate(var=rownames(.))%>%
    filter(nb_na!=0)%>%
    ggplot(aes(x=var,y=nb_na))+
    geom_bar(stat='identity',color='midnightblue',fill="white",width=1)+
    theme_classic2()+
    theme(axis.text.x = element_text(angle=45,hjust=1),
          plot.title = element_text(face="bold"))+
    scale_y_continuous(expand = c(0,0))+
    ggtitle("Number of missing values")+
    as.data.frame(colSums(is.na(site_data)))%>%
    rename(nb_na=`colSums(is.na(site_data))`)%>%
    mutate(var=rownames(.),
           na_pct=(nb_na/202)*100)%>%
    filter(nb_na!=0)%>%
    mutate(non_na_pct=100-na_pct)%>%
    reshape2::melt(id.variables=c(var,nb_na))%>%
    filter(variable!="nb_na")%>%
    mutate(variable=fct_relevel(variable,"non_na_pct","na_pct"))%>%
    ggplot(aes(x=var,y=value,fill=variable))+
    geom_bar(stat='identity',width=1,position="fill")+
    scale_fill_manual(values=c("lightgrey","mediumvioletred"))+
    theme_classic2()+
    theme(axis.text.x = element_text(angle=45,hjust=1),
          plot.title = element_text(face="bold"))+
    ggtitle("Percentage of missing values")+
    scale_y_continuous(expand = c(0,0))

ggsave("Figures/var_mssing_val.png",var_missing_val,width=16)
```

```{r}
as.data.frame(rowSums(is.na(site_data)))%>%
    ggplot(aes(x=1:nrow(.),y=`rowSums(is.na(site_data))`))+
    geom_bar(stat='identity',width=1)

site_data[which.max((rowSums(is.na(site_data)))),]
```

```{r}
rm(var_missing_val)
```

### Create short term

```{r}
var_lt <- colnames(site_data)[grep('_lt', names(site_data))] # extract long term variables (as they also exist on monthly basis)
months_we_want <- c("03","04","05") # march/april/may  (1 to 4 months before sampling)
var_st <- colnames(site_data)[grep('03|04|05', names(site_data))] # get columns of monthly variables

site_data_lt <- site_data%>% # subset long term variables
    dplyr::select(all_of(c("X","Y",var_lt,"bulk","gHM","height","ph","soc","water")))
site_data_st <- site_data%>% # subset chort term variables
    dplyr::select(all_of(c("X","Y",var_st,"bulk","gHM","height","ph","soc","water")))
```

### Impute missing data

We perform missing data imputation using missMDA package.

```{r} 
# Get the number of PCs we need to infer our missing values
ncp_data_lt <- site_data %>%  
    dplyr::select(all_of(c("X","Y",var_lt,"bulk","gHM","height","ph","soc","water"))) %>%
    missMDA::estim_ncpPCA(scale=T)

ncp_data_st <- site_data %>% 
    dplyr::select(all_of(c("X","Y",var_st,var_lt,"bulk","gHM","height","ph","soc","water"))) %>%
    mutate(across(everything(),as.numeric))%>%
    missMDA::estim_ncpPCA(scale=T)

# Impute our missing values and store them in a new 'imputed' data frame
imputed_data_lt <- site_data %>% 
    dplyr::select(all_of(c("X","Y",var_lt,"bulk","gHM","height","ph","soc","water")))%>%
    missMDA::imputePCA(ncp=5,scale=T)
imputed_data_lt <- imputed_data_lt$completeObs %>% as.data.frame()

imputed_data_st <- site_data %>% 
    dplyr::select(all_of(c("X","Y",var_st,var_lt,"bulk","gHM","height","ph","soc","water")))%>%
    missMDA::imputePCA(ncp=5,scale=T)
imputed_data_st <- imputed_data_st$completeObs %>% as.data.frame()
```

Our short term data are averaged over three months (march to may).
We need to test if imputed before or on mean changes a lot to imputed values.

```{r}
# Test by averaging short term variables before imputation
site_data_st_before_imputation <- site_data %>% 
    dplyr::select(all_of(c("X","Y",var_lt,var_st,"bulk","gHM","height","ph","soc","water")))%>%
    mutate(across(.cols=all_of(var_lt),
                  ~get(paste0(gsub("_lt","_",cur_column()), months_we_want[1]))+
                       get(paste0(gsub("_lt","_",cur_column()), months_we_want[2]))+
                       get(paste0(gsub("_lt","_",cur_column()), months_we_want[3]))/3,
                  .names = "{col}__st"
    ))

var_to_remove <- colnames(site_data_st_before_imputation)[grep('_[0-9]{2}', names(site_data_st_before_imputation))]
site_data_st_before_imputation %<>%
    dplyr::select(-one_of(var_to_remove))%>% 
    rename_with(~ stringr::str_remove(., "_lt_"), everything())

st <- names(site_data_st_before_imputation)[grep('_st', names(site_data_st_before_imputation))]
ncp_data_before_st <- site_data_st_before_imputation %>% 
    dplyr::select(all_of(c("X","Y",st,"bulk","gHM","height","ph","soc","water"))) %>%
    mutate(across(everything(),as.numeric))%>%
    missMDA::estim_ncpPCA(scale=T)


site_data_st_before_imputation_imputed <- site_data_st_before_imputation %>% 
    dplyr::select(all_of(c("X","Y",st,"bulk","gHM","height","ph","soc","water")))%>%
    missMDA::imputePCA(ncp=3,scale=T)
site_data_st_before_imputation_imputed <- site_data_st_before_imputation_imputed$completeObs %>% as.data.frame()

# Here we average on imputed variables
site_data_st_after_imputation <- imputed_data_st %>%
    mutate(across(.cols=all_of(var_lt),
                  ~get(paste0(gsub("_lt","_",cur_column()), months_we_want[1]))+
                       get(paste0(gsub("_lt","_",cur_column()), months_we_want[2]))+
                       get(paste0(gsub("_lt","_",cur_column()), months_we_want[3]))/3,
                  .names = "{col}__st"
    ))

var_to_remove <- colnames(site_data_st_after_imputation)[grep('_[0-9]{2}', names(site_data_st_after_imputation))]
site_data_st_after_imputation %<>%
    dplyr::select(-one_of(var_to_remove))%>% 
    rename_with(~ stringr::str_remove(., "_lt_"), everything())%>%
    dplyr::select(all_of(c("X","Y",st,"bulk","gHM","height","ph","soc","water")))
```

## Select variables

### Histogram of variables


```{r}
data_sets <- c("site_data_lt",
               "site_data_st",
               'imputed_data_lt',
               'imputed_data_st',
               "site_data_st_after_imputation",
               "site_data_st_before_imputation_imputed")

for(j in data_sets){
    message(j)
    tmp <- get(j)
    plot_list <- NULL
    for(i in 1:ncol(tmp)){
        plot_list[[names(tmp[i])]] <- local({
            i <- i
            ggplot(tmp,aes(x=tmp[,i]))+
            geom_histogram(fill="darkolivegreen3")+
            theme_classic2()+
            xlab(names(tmp[i]))})
        
    }
    ggsave(plot=ggarrange(plotlist =  plot_list,
                          ncol = ceiling(sqrt(i)),
                          nrow = ceiling(sqrt(i))),
                          filename=paste0("Figures/histograms/",j,".png"),
                          height =25,
                          width = 25)
}
```

### Var correlation

```{r}
cor_fun <- function(data, mapping, method="pearson", use="pairwise", sz=5, ...){
    
    # grab data
    x <- eval_data_col(data, mapping$x)
    y <- eval_data_col(data, mapping$y)
    
    # calculate correlation: for significance stars
    corr <- cor.test(x, y, method=method)
    est <- corr$estimate
    
    # get significance stars

        stars <- c("***", "**", "*", "")[findInterval(corr$p.value, c(0, 0.001, 0.01, 0.05, 1))]
        lbl <- stars

    # calculate correlation: for colored tiles
    corr <- cor(x, y, method=method, use=use)
    
    # calculate color based on correlation value
    # corr = -1 => blue, 
    # corr =  0 => white, 
    # corr = +1 => red, 
    colFn <- colorRampPalette(c("blue", "white", "red"), interpolate ='spline')
    fill <- colFn(100)[findInterval(corr, seq(-1, 1, length=100))]
    fill[which(stars=="")] <- "grey"
    ggplot(data = data, mapping = mapping, ...) + 
        theme_void() +
        annotate("text",
                 x=mean(x, na.rm=TRUE),
                 y=mean(y, na.rm=TRUE),
                 label=lbl,
                 ...) +
        theme(panel.background = element_rect(fill=fill,  # to fill background of panel with color
                                              colour=NA), # to remove border of panel
              panel.grid.major = element_blank())
}
```


```{r}
data_sets <- c("site_data_lt",
               'imputed_data_lt',
               "site_data_st_after_imputation",
               "site_data_st_before_imputation_imputed")

for(j in data_sets){
    message(j)
    tmp <- get(j)
    names(tmp) <- gsub("_.t$","",names(tmp))
    pairs <- ggpairs(tmp,
                     columns=3:ncol(tmp),
                     progress = F,
                     axisLabels = "none",
                     # LOWER TRIANGLE ELEMENTS: add line with smoothing; make points transparent and smaller
                     lower = list(continuous = function(...) 
                         ggally_smooth(..., colour="darkolivegreen3", alpha = 0.3, size=0.8)), 
                     # DIAGONAL ELEMENTS: histograms
                     diag = list(continuous = function(...) 
                         ggally_barDiag(..., fill="grey")),
                     
                     # UPPER TRIANGLE ELEMENTS: use fct. creating corr heatmap with sign stars
                     upper = list(continuous = cor_fun)) + 
        theme(strip.background = element_blank(), # remove color
              strip.text = element_text(size=6,angle=45), # change font and font size
              axis.line = element_line(colour = "grey"),
              # remove grid
              panel.grid.minor = element_blank(), )+  # remove smaller gridlines
        # panel.grid.major = element_blank()    # remove larger gridlines)
        ggtitle(j)+
        theme(plot.title = element_text(face="bold"))
    
    
    ggsave(plot=pairs,
           filename=paste0("Figures/pairs_",j,".png"),
           height =29.7/2.54,
           width = 21/2.54)
}
```

Soil moisture imputation strategies changes its relations with other variables: REMOVE IT.


### Xplore Eco-Regions

```{r}
length(unique(site_data$ECO_NAME))
unique(site_data$ECO_NAME)
length(unique(site_data$BIOME_NAME))
unique(site_data$BIOME_NAME)
```


```{r}
site_data%>%
  filter(Country%in%c("Russia","Norway"))%>%
  dplyr::select(Sample,Country,BIOME_NAME,ECO_NAME,X,Y,COLOR)

# 20/21 and 22 are samples from Primorskii in Russia which is in a Boreal Forest/ TaÃ¯ga - Scandinavian and Russian TaÃ¯ga

# 92/93 and 94 are from Sultindvik in Norway and are Scandinavian Montane Birch forest and grasslands / Tundra

site_data[which(site_data$Sample%in%c("020","021","022")),"BIOME_NAME"] <- "Boreal Forests/Taiga"
site_data[which(site_data$Sample%in%c("020","021","022")),"ECO_NAME"] <- "Scandinavian and Russian taiga"


site_data[which(site_data$Sample%in%c("092","093","094")),"BIOME_NAME"] <- "Tundra"
site_data[which(site_data$Sample%in%c("092","093","094")),"ECO_NAME"] <- "Scandinavian Montane Birch forest and grasslands"
```



### PCA sites

```{r}
arrowMul <- function(arrows, data, at = c(0, 0), fill = 0.75) {
  u <- c(range(data[,1], range(data[,2])))
  u <- u - rep(at, each = 2)
  r <- c(range(arrows[, 1], na.rm = TRUE), range(arrows[, 2], na.rm = TRUE))
  rev <- sign(diff(u))[-2]
  if (rev[1] < 0)
    u[1:2] <- u[2:1]
  if (rev[2] < 0)
    u[3:4] <- u[4:3]
  u <- u/r
  u <- u[is.finite(u) & u > 0]
  fill * min(u)
}
```

```{r}
pca_sites_lt <- imputed_data_lt %>% 
    dplyr::select(!grep('_st', names(imputed_data_lt)))%>%
    dplyr::select(!grep('soil_moisture',colnames(.)))%>%
    dplyr::select(-c(X,Y))%>%
    FactoMineR::PCA(scale.unit = T,
                    graph = F)

pca_sites_before_st <- site_data_st_before_imputation_imputed %>% 
    dplyr::select(grep('_st', names(site_data_st_before_imputation_imputed)))%>%
    dplyr::select(!grep('soil_moisture',colnames(.)))%>%
    FactoMineR::PCA(scale.unit = T,
                    graph = F) # NAs

pca_sites_after_st <- site_data_st_after_imputation %>% 
    dplyr::select(grep('_st', names(site_data_st_after_imputation)))%>%
    dplyr::select(!grep('soil_moisture',colnames(.)))%>%
    FactoMineR::PCA(scale.unit = T,
                    graph = F)
```

```{r}
data_sets <- c("pca_sites_lt","pca_sites_before_st","pca_sites_after_st")
col <- c("darkorange","cornflowerblue","darkorchid4")
pca_site_biplot <- NULL
scree_plot_list <- NULL
pca_site_biplot_eco <- NULL
biomes_color <- c("#F6D55C","#ED553B","#173F5F","#3CAEA3","#20639B")
for(i in data_sets){
    pca_tmp <- get(i)
    
    eig <- pca_tmp$eig
    coord_pca <- as.data.frame(pca_tmp$ind$coord)
    coord_pca$site <- site_data$Sample
    coord_pca$biome_name <- site_data$BIOME_NAME
    coord_pca$eco_name <- site_data$ECO_NAME

    mul <- arrowMul(as.data.frame(pca_tmp$var$coord),
                    pca_tmp$ind$coord)
    
    pca_site_biplot[[i]] <- ggplot()+
        geom_point(coord_pca,mapping=aes(x=Dim.1,y=Dim.2,color=biome_name))+
        theme_classic2()+
        geom_vline(xintercept = 0,lty=2)+
        geom_hline(yintercept = 0,lty=2)+
        # ggrepel::geom_label_repel(data=filter(coord_pca,Dim.2< -3),aes(x=Dim.1,y=Dim.2,label=site))+
        xlab(paste0("PC1 (",round(eig[1,2],2),"%)"))+
        ylab(paste0("PC2 (",round(eig[2,2],2),"%)"))+
        geom_segment(data= as.data.frame(pca_tmp$var$coord),aes(x = 0, y = 0, xend=mul*Dim.1, yend=mul*Dim.2),
                     lineend = "round", 
                     linejoin = "round",
                     linewidth = .75, 
                     arrow = arrow(length = unit(0.2, "inches")),
                     colour = "black" 
        )+
        ggrepel::geom_text_repel(data = data.frame(var=rownames(pca_tmp$var$coord),pca_tmp$var$coord*mul), # add variable names at the end of arrows
                                 aes(x = Dim.1*1.1, # nudge a bit the coordinates so that they're not on the arrows
                                     y = Dim.2*1.1,
                                     label = var),
                                 max.overlaps = getOption("ggrepel.max.overlaps", default = 15))+
        ggtitle(paste0("Biplot sites ",i))+
        theme(plot.title = element_text(face="bold"))+
      scale_color_manual(values=biomes_color)
    
    scree_plot_list[[i]] <- factoextra::fviz_screeplot(pca_tmp,barfill = col[match(i,data_sets)], barcolor=col[match(i,data_sets)])
    
    
    
    pca_site_biplot_eco[[i]] <- ggplot()+
        geom_point(coord_pca,mapping=aes(x=Dim.1,y=Dim.2,color=eco_name))+
        theme_classic2()+
        geom_vline(xintercept = 0,lty=2)+
        geom_hline(yintercept = 0,lty=2)+
        # ggrepel::geom_label_repel(data=filter(coord_pca,Dim.2< -3),aes(x=Dim.1,y=Dim.2,label=site))+
        xlab(paste0("PC1 (",round(eig[1,2],2),"%)"))+
        ylab(paste0("PC2 (",round(eig[2,2],2),"%)"))+
        geom_segment(data= as.data.frame(pca_tmp$var$coord),aes(x = 0, y = 0, xend=mul*Dim.1, yend=mul*Dim.2),
                     lineend = "round", 
                     linejoin = "round",
                     linewidth = .75, 
                     arrow = arrow(length = unit(0.2, "inches")),
                     colour = "black" 
        )+
        ggrepel::geom_text_repel(data = data.frame(var=rownames(pca_tmp$var$coord),pca_tmp$var$coord*mul), # add variable names at the end of arrows
                                 aes(x = Dim.1*1.1, # nudge a bit the coordinates so that they're not on the arrows
                                     y = Dim.2*1.1,
                                     label = var),
                                 max.overlaps = getOption("ggrepel.max.overlaps", default = 15))+
        ggtitle(paste0("Biplot sites ",i))+
        theme(plot.title = element_text(face="bold"))+
      scale_fill_manual(values = c("#800000","#9a6324","#808000","#469990","#000075","#000000","#e6194b","#f58231","#ffe119","#bfef45","#3cb44b","#42d4f4","#4363d8","#911eb4","#f032e6","#a9a9a9","#fabed4","#ffd8b1","#fffac8","#aaffc3","#dcbeff","darkorchid4","darkolivegreen3"))+
  stat_ellipse(coord_pca,mapping=aes(x=Dim.1,y=Dim.2,color=eco_name))  
}
```

```{r}
pca_sites <- (pca_site_biplot$pca_sites_lt+scree_plot_list$pca_sites_lt)/
    (pca_site_biplot$pca_sites_before_st+scree_plot_list$pca_sites_before_st)/
    (pca_site_biplot$pca_sites_after_st+scree_plot_list$pca_sites_after_st)
```

```{r}
ggsave("Figures/pca_sites.png",pca_sites,width = 21/2.54 ,height= 29.7/2.54)
```


### PCA sites on env interests

```{r}
site_data_st_before_imputation_imputed$Sample <- site_data$Sample
imputed_data_lt$Sample <- site_data$Sample
combined <- site_data_st_before_imputation_imputed%>%
    left_join(imputed_data_lt, by="Sample", suffix=c("",".y"))%>%
    dplyr::select(-ends_with(".y"))%>%
    left_join(site_data[,1:4])%>%
    relocate(Sample)

combined%<>%
    mutate(ph=ph/100)
combined$BIOME_NAME <- site_data$BIOME_NAME
combined$ECO_NAME <- site_data$ECO_NAME
combined$X2 <- site_data$X2
combined$Y2 <- site_data$Y2

var_lt <- colnames(combined)[which(grepl("lt",colnames(combined)))]
var_st <- colnames(combined)[which(grepl("st",colnames(combined)))]

var_interest <- c("aet","pr","swe","tmmn","tmmx","vpd","elevation","evi","fpar","gpp","ph","soc")

var_lt <- var_lt[which(gsub("_lt","",var_lt)%in%var_interest)]
var_st <- var_st[which(gsub("_st","",var_st)%in%var_interest)]

pca_site_var <- NULL
scree_plot_var_list <- NULL
for(i in c("st","lt")){
  
  var2use <- get(paste0("var_",i))
  pca_tmp <- combined %>% 
    dplyr::select(all_of(c("ph",var2use)))%>%
    FactoMineR::PCA(scale.unit = T,
                    graph = F)
  
  eig <- pca_tmp$eig
  coord_pca <- as.data.frame(pca_tmp$ind$coord)
  coord_pca$site <- combined$Sample
  coord_pca$biome_name <- combined$BIOME_NAME
  
  mul <- arrowMul(as.data.frame(pca_tmp$var$coord),
                  pca_tmp$ind$coord)
  
  pca_site_var[[i]] <- ggplot()+
    geom_point(coord_pca,mapping=aes(x=Dim.1,y=Dim.2,color=biome_name))+
    theme_classic2()+
    geom_vline(xintercept = 0,lty=2)+
    geom_hline(yintercept = 0,lty=2)+
    xlab(paste0("PC1 (",round(eig[1,2],2),"%)"))+
    ylab(paste0("PC2 (",round(eig[2,2],2),"%)"))+
    geom_segment(data= as.data.frame(pca_tmp$var$coord),aes(x = 0, y = 0, xend=mul*Dim.1, yend=mul*Dim.2),
                 lineend = "round", 
                 linejoin = "round",
                 linewidth = .75, 
                 arrow = arrow(length = unit(0.2, "inches")),
                 colour = "black" 
    )+
    ggrepel::geom_text_repel(data = data.frame(var=rownames(pca_tmp$var$coord),pca_tmp$var$coord*mul), # add variable names at the end of arrows
                             aes(x = Dim.1*1.1, # nudge a bit the coordinates so that they're not on the arrows
                                 y = Dim.2*1.1,
                                 label = var),
                             max.overlaps = getOption("ggrepel.max.overlaps", default = 15))+
    ggtitle(paste0("Biplot sites ",i))+
    theme(plot.title = element_text(face="bold"))+
    scale_color_manual(values=biomes_color)
  
  scree_plot_var_list[[i]] <- factoextra::fviz_screeplot(pca_tmp,barfill = "darkorchid4", barcolor="darkorchid4")
  ggsave(paste0("Figures/pca_",i,".png"),pca_site_var[[i]]+scree_plot_var_list[[i]],width = 12)
}
```
## Cluster site

```{r}
results_nbclust_lt <- NbClust::NbClust(scale(combined[c("ph",var_lt)]), distance = 'euclidean',method = "ward.D2")
results_nbclust_st <- NbClust::NbClust(scale(combined[c("ph",var_st)]), distance = 'euclidean',method = "ward.D2")

site_bp <- combined
site_bp %<>% mutate(bp_lt = as.factor(results_nbclust_lt$Best.partition),
                    bp_st = as.factor(results_nbclust_st$Best.partition))

(sites <- st_as_sf(site_bp, coords = c("X", "Y"), 
                   crs = 4326, agr = "constant"))

map_com_best_part_lt <- (ggplot() +
                          geom_sf(data = world_lambert, fill = "grey", color = "darkgrey", size = 0.1)+
                          geom_sf(data = sites, size = 3, shape = 23,aes(fill = bp_lt),alpha=.7) +
                          ggtitle("Site clustering satellite data LT") +
                          theme_minimal()+
                          theme(plot.title = element_text(hjust = 0.5, size = 16,face="bold"))+
                          theme(panel.background = element_rect(fill = "azure"))+
                          scale_fill_manual(values = c("darkgreen","darkorange3"),name="Cluster - best partition"))

map_com_best_part_st <- (ggplot() +
                          geom_sf(data = world_lambert, fill = "grey", color = "darkgrey", size = 0.1)+
                          geom_sf(data = sites, size = 3, shape = 23,aes(fill = bp_st),alpha=.7) +
                          ggtitle("Site clustering satellite data ST") +
                          theme_minimal()+
                          theme(plot.title = element_text(hjust = 0.5, size = 16,face="bold"))+
                          theme(panel.background = element_rect(fill = "azure"))+
                          scale_fill_manual(values = c("darkgreen","darkorange3","darkorchid4"),name="Cluster - best partition"))

map_com_best_part_lt+map_com_best_part_st
```


```{r}
pca_site_var <- NULL
scree_plot_var_list <- NULL
for(i in c("st","lt")){
  
  var2use <- get(paste0("var_",i))
  pca_tmp <- combined %>% 
    dplyr::select(all_of(c("ph",var2use)))%>%
    FactoMineR::PCA(scale.unit = T,
                    graph = F)
  
  eig <- pca_tmp$eig
  coord_pca <- as.data.frame(pca_tmp$ind$coord)
  coord_pca$site <- combined$Sample
  coord_pca$cluster <- site_bp[,paste0("bp_",i)]
  
  mul <- arrowMul(as.data.frame(pca_tmp$var$coord),
                  pca_tmp$ind$coord)
  
  pca_site_var[[i]] <- ggplot()+
    geom_point(coord_pca,mapping=aes(x=Dim.1,y=Dim.2,color=as.factor(cluster)))+
    theme_classic2()+
    geom_vline(xintercept = 0,lty=2)+
    geom_hline(yintercept = 0,lty=2)+
    xlab(paste0("PC1 (",round(eig[1,2],2),"%)"))+
    ylab(paste0("PC2 (",round(eig[2,2],2),"%)"))+
    geom_segment(data= as.data.frame(pca_tmp$var$coord),aes(x = 0, y = 0, xend=mul*Dim.1, yend=mul*Dim.2),
                 lineend = "round", 
                 linejoin = "round",
                 linewidth = .75, 
                 arrow = arrow(length = unit(0.2, "inches")),
                 colour = "black" 
    )+
    ggrepel::geom_text_repel(data = data.frame(var=rownames(pca_tmp$var$coord),pca_tmp$var$coord*mul), # add variable names at the end of arrows
                             aes(x = Dim.1*1.1, # nudge a bit the coordinates so that they're not on the arrows
                                 y = Dim.2*1.1,
                                 label = var),
                             max.overlaps = getOption("ggrepel.max.overlaps", default = 15))+
    ggtitle(paste0("Biplot sites ",i))+
    theme(plot.title = element_text(face="bold"))
  
  ggsave(paste0("Figures/pca_clust_",i,".png"),pca_site_var[[i]],width = 12)
}
```



```{r}
clust_heatmap <- site_bp%>%
    select(grep("Sample|bp_",colnames(.)))%>%
    melt("Sample")%>%
    mutate(variable=fct_relevel(variable,"bp_lt","bp_st"))%>%
    ggplot(aes(x=variable,y=Sample,fill=value))+
    geom_tile()+
    scale_fill_manual(values = c("darkgreen","darkorange3","darkorchid4"),name="Cluster - best partition")+
    scale_y_discrete(limits=rev)+
    theme_minimal()+
    combined%>%
    select(c(BIOME_NAME,Sample))%>%
    ggplot(aes(x="Biomes",y=Sample,fill=BIOME_NAME))+
    geom_tile()+
    theme_void()+
    scale_fill_manual(values=biomes_color,
                      name="Biomes")+
    plot_layout(guides="collect",widths = c(5,1))


ggsave("Figures/cluster_heatmaps.png",clust_heatmap,height = 28.7/2.54)
```

```{r}
list_maps_var <- NULL
for(i in c("st","lt")){
  
  varofinterest <- c("ph",get(paste0("var_",i)))
  for(j in varofinterest){
    
    list_maps_var[[i]][[j]] <- (ggplot() +
                                  geom_sf(data = world_lambert, fill = "grey", color = "darkgrey", size = 0.1)+
                                  geom_sf(data = sites, size = 3, shape = 23,aes_string(fill = j),alpha=.7) +
                                  ggtitle(paste0("Maps ",j," (",i,")")) +
                                  theme_minimal()+
                                  theme(plot.title = element_text(hjust = 0.5, size = 16,face="bold"))+
                                  theme(panel.background = element_rect(fill = "azure")))+
      scale_fill_viridis_c( oob = scales::squish)
    
    ggsave(paste0("Figures/map_var/map_",i,"_",j,".png"),list_maps_var[[i]][[j]])
    
  }
}
```

## Traits pct range

```{r}
for(i in c("st","lt")){
  
  varofinterest <- c("ph",get(paste0("var_",i)))
  for(j in varofinterest){
    
    (sd(combined[,j])/mean(combined[,j]))*100
    
    ggsave(paste0("Figures/map_var/map_",i,"_",j,".png"),list_maps_var[[i]][[j]])

  }
}
p1 <- combined%>%
  select(all_of(c("ph",var_lt,var_st)))%>%
  summarise_all(.funs=~(sd(abs(.x))/mean(abs(.x)))*100)%>%
  reshape2::melt()%>%
  mutate(datatype=ifelse(grepl("lt",variable),"Long term",ifelse(variable=="ph","ph","Short term")))%>%
  ggplot(aes(x=variable,y=value))+
  geom_bar(stat = "identity")+
  facet_grid(~datatype,scales = "free",space="free")+
  theme(axis.text.x = element_text(angle = 45,hjust=1))

ggsave("Figures/CV_var.png",p1)
```


## Site temp/prec

```{r}
combined%>%
  ggplot(aes(x=tmmx_lt,y= pr_lt, color = BIOME_NAME))+
  geom_point()+
  scale_color_manual(values = biomes_color)+
  theme_classic2()+
  ylab("Monthly precipitation (mm)")+
  xlab("Monthly max temperature (CÂ°)")

  combined%>%
  ggplot(aes(x=tmmx_lt,y= pr_lt, color = ECO_NAME))+
  geom_point()+
  scale_color_manual(values = c("#800000","#9a6324","#808000","#469990","#000075","#000000","#e6194b","#f58231","#ffe119","#bfef45","#3cb44b","#42d4f4","#4363d8","#911eb4","#f032e6","#a9a9a9","#fabed4","#ffd8b1","#fffac8","#aaffc3","#dcbeff","darkorchid4","darkolivegreen3"))+
  theme_classic2()+
  ylab("Monthly precipitation (mm)")+
  xlab("Monthly max temperature (CÂ°)")
  
  
  combined%>%
  ggplot(aes(x=tmmx_lt,y= pr_lt, color = Country))+
  geom_point()+
  scale_color_manual(values = c("#800000","#9a6324","#808000","#469990","#000075","#000000","#e6194b","#f58231","#ffe119","#bfef45","#3cb44b","#42d4f4","#4363d8","#911eb4","#f032e6","#a9a9a9","#fabed4","#ffd8b1","#fffac8","#aaffc3","#dcbeff","darkorchid4","darkolivegreen3"))+
  theme_classic2()+
  ylab("Monthly precipitation (mm)")+
  xlab("Monthly max temperature (CÂ°)")
```




# E -  Save cleaned datasets

I need meco_16s_ns which is our communities with no singletons.
I need site data that are imputed.
I'll go with data imputed after short term averaging to reduce noise.
Selected variables!!

```{r}
# save.image(file='outputs/preproc_myenv.RData')
save(meco_16s_ns,file = "outputs/meco_16s.RData")
save(meco_16s_relabfiltered,file = "outputs/meco_16s_relabfiltered.RData")
save(combined,file = "outputs/site_data_imputed.RDS")
save(non_targ_asvs, file = "non_targ_asvs.rds")
write.csv(combined,file = "outputs/combined.csv")
rm(list=ls())
gc()
```

```{r}
load("outputs/meco_16s.RData")
load("outputs/meco_16s_relabfiltered.RData")
load("outputs/site_data_imputed.RDS")
```

```{r}
biomes_color <- c("#F6D55C","#ED553B","#173F5F","#3CAEA3","#20639B")
```

# -----------------------------------
# -----------------------------------
# -----------------------------------

# A - 16s and sites relations

```{r}
names_df_clean <-data.frame(fullname= c("Geographic","pH","Evapo-transpiration","Precipitation","Snow water equivalent", "TÂ° min","TÂ° max","Vapor pressure deficit", "Enhanced vegetation index", "Fraction of absorbed photosynthetically active radiation","Growth primary production"),
                            Var2= c("Geographic","ph","aet","pr","swe", "tmmn","tmmx","vpd", "evi", "fpar","gpp"),
                            midname= c("Geographic","pH","AET","Precipitation","Snow water eq","TÂ° min","TÂ° max","VPD","eVI","FPAR","GPP"))

```


```{r}
world <- ne_countries(scale = "medium", returnclass = "sf")

# Subset the world data to include only the specified latitude range
cropping <- as(raster::extent(-180, 180, 20, 90), "SpatialPolygons")


world_subset <- raster::crop(as_Spatial(world),cropping)
# Create a Lambert azimuthal equal-area projection centered on the North Pole
lambert_proj <- st_crs("+proj=laea +lat_0=90 +lon_0=0 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs")
world_lambert <- st_transform(st_as_sf(world_subset), crs = lambert_proj)
```

## Formula

```{r}
var_lt <- colnames(combined)[which(grepl("lt",colnames(combined)))]
var_st <- colnames(combined)[which(grepl("st",colnames(combined)))]
var_interest <- c("aet","pr","swe","tmmn","tmmx","vpd","elevation","evi","fpar","gpp","ph","soc")
var_lt <- var_lt[which(gsub("_lt","",var_lt)%in%var_interest)]
var_st <- var_st[which(gsub("_st","",var_st)%in%var_interest)]

XFormula_lt <- paste(var_lt,sep="", collapse = "+")
XFormula_st <- paste(var_st,sep="", collapse = "+")

XFormula_lt <- paste0("nb_asvs ~ ph + height + water + gHM + soc +", XFormula_lt ,"+ log(nb_reads)")
XFormula_st <- paste0("nb_asvs ~ ph + height + water + gHM + soc +", XFormula_st ,"+ log(nb_reads)")
```

## Different variable

```{r}
p_var_biomes <- NULL
for(i in c("_st","_lt")){
  var_tmp <- get(paste0("var",i))
  combined_tmp <- combined[,c("ph",var_tmp,"BIOME_NAME")]
  combined_tmp_melted <- reshape2::melt(combined_tmp)
  combined_tmp_melted$variable <- gsub(i,"",combined_tmp_melted$variable)
  combined_tmp_melted%<>%
    left_join(rename(names_df_clean,variable=Var2))
  
   p_var_biomes[[i]] <- combined_tmp_melted%>%
     filter(!is.na(fullname))%>%
     ggplot(aes(x=BIOME_NAME,y=value,color=BIOME_NAME))+
      geom_boxplot(outlier.shape = NA)+
      geom_jitter(width=.25)+
      scale_color_manual(values = biomes_color, name="Biomes")+
      theme_classic2()+
      xlab("")+
      theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))+
     facet_wrap("fullname",scales = "free_y")

}
```

```{r}
p_rich_var_biomes <- NULL
nb_asvs_ns <- colSums(meco_16s_ns$otu_table>0)
df_nb_asvs <- data.frame(nb_asvs_ns = nb_asvs_ns,Sample = gsub("[A-Z]|-|(?=_).*","",names(nb_asvs_ns),perl=T))
df_nb_asvs%<>%
  left_join(data.frame(nb_asvs_relabfilt = colSums(meco_16s_relabfiltered$otu_table>0),Sample = gsub("[A-Z]|-|(?=_).*","",names(colSums(meco_16s_relabfiltered$otu_table>0)),perl=T)))

combined%<>%
  left_join(df_nb_asvs)

for(i in c("_st","_lt")){
  var_tmp <- get(paste0("var",i))
  combined_tmp <- combined[,c("ph",var_tmp,"BIOME_NAME","nb_asvs_relabfilt","nb_asvs_ns")]
  combined_tmp_melted <- reshape2::melt(combined_tmp,id.vars=c("BIOME_NAME","nb_asvs_relabfilt","nb_asvs_ns"))
  combined_tmp_melted$variable <- gsub(i,"",combined_tmp_melted$variable)
  combined_tmp_melted%<>%
    left_join(rename(names_df_clean,variable=Var2))
  
  p_rich_var_biomes[[i]][["filtered"]] <- combined_tmp_melted%>%
    filter(!is.na(fullname))%>%
    ggplot(aes(x=value,y=nb_asvs_relabfilt))+
    geom_point(aes(color=BIOME_NAME))+
    geom_smooth(method = 'lm')+
    scale_color_manual(values = biomes_color, name="Biomes")+
    theme_classic2()+
    xlab("")+
    ylab("ASV richness")+
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))+
    facet_wrap("fullname",scales = "free_x")+
    ggpmisc::stat_poly_eq(ggpmisc::use_label(c("adj.R2", "f", "p")))
  
  p_rich_var_biomes[[i]][["non_filtered"]] <- combined_tmp_melted%>%
    filter(!is.na(fullname))%>%
    ggplot(aes(x=value,y=nb_asvs_ns))+
    geom_point(aes(color=BIOME_NAME))+
    geom_smooth(method = 'lm')+
    scale_color_manual(values = biomes_color, name="Biomes")+
    theme_classic2()+
    xlab("")+
    ylab("ASV richness")+
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))+
    facet_wrap("fullname",scales = "free_x")+
    ggpmisc::stat_poly_eq(ggpmisc::use_label(c("adj.R2", "f", "p")))
}
```


## Moran's eigenvector with Adespatial

```{r}
library(adespatial)

mat_dist <- codep::geodesics(combined[,c("X2","Y2")])
mat_geo <- geodist::geodist(combined[,c("X2","Y2")],measure = 'geodesic')
```


```{r}
# class(mat_geo) <- c("matrix","dist")
mems <- dbmem(as.dist(mat_geo),MEM.autocor = "positive")
mems2 <- dbmem(mat_dist,MEM.autocor = "positive")
```

```{r}
df_mems <- mems
class(df_mems) <- "data.frame"
df_mems%<>%  
  mutate(across(all_of(c(1:19)),.fns=~ifelse(.>0,"Pos","Neg"),.names = "{.col}_fill"))
  
df_mems$long <- combined$X2
df_mems$lat <- combined$Y2
df_mems%<>%
  reshape2:: melt(id.vars = c('long','lat'))

df_mems <- cbind(filter(df_mems,grepl("fill",variable)),filter(df_mems[,c(3,4)],!grepl("fill",variable)))
names(df_mems) <- c("long","lat","var1","fillval","var2","value")
df_mems$value <- as.numeric(df_mems$value)


(df_mems <- st_as_sf(df_mems, coords = c("long", "lat"), 
                   crs = 4326, agr = "constant"))
ggplot() +
  geom_sf(data = world_lambert, fill = "grey", color = "darkgrey", size = 0.1)+
  geom_sf(data=df_mems, aes(fill=fillval,size=abs(value)),shape=22)+
  facet_wrap(~var2)+
  ggtitle("MEMs across sites") +
  theme(plot.title = element_text(hjust = 0.5))+
  theme_minimal()+
  theme(panel.background = element_rect(fill = "azure"))+
  scale_fill_manual(values=c("black","white"))+
  labs(size="MEM value", fill="MEM sign")
```


```{r}
df_mems2 <- mems2
class(df_mems2) <- "data.frame"
df_mems2%<>%  
  mutate(across(all_of(c(1:12)),.fns=~ifelse(.>0,"Pos","Neg"),.names = "{.col}_fill"))
  
df_mems2$long <- combined$X2
df_mems2$lat <- combined$Y2
df_mems2%<>%
  reshape2:: melt(id.vars = c('long','lat'))

df_mems2 <- cbind(filter(df_mems2,grepl("fill",variable)),filter(df_mems2[,c(3,4)],!grepl("fill",variable)))
names(df_mems2) <- c("long","lat","var1","fillval","var2","value")
df_mems2$value <- as.numeric(df_mems2$value)


(df_mems2 <- st_as_sf(df_mems2, coords = c("long", "lat"), 
                   crs = 4326, agr = "constant"))

ggplot() +
  geom_sf(data = world_lambert, fill = "grey", color = "darkgrey", size = 0.1)+
  geom_sf(data=df_mems2, aes(fill=fillval,size=abs(value)),shape=22)+
  facet_wrap(~var2)+
  ggtitle("MEMs across sites") +
  theme(plot.title = element_text(hjust = 0.5))+
  theme_minimal()+
  theme(panel.background = element_rect(fill = "azure"))+
  scale_fill_manual(values=c("black","white"))+
  labs(size="MEM value", fill="MEM sign")

```



```{r}
test <- moran.randtest(mems, nrepet = 999, p.adjust.method = "holm") # 4 first are significant (positive eigenvalues)

p1 <- data.frame(test$names,test$adj.pvalue,test$obs)%>%
ggplot(aes(x=reorder(test.names,-test.obs),y=test.adj.pvalue))+
  geom_point()+
  xlab("")+
  ylab("P values")+
  theme(axis.text.x = element_blank())+
  geom_hline(yintercept = 0.05,color="darkorange2")
p2 <-   data.frame(test$names,test$obs)%>%
ggplot(aes(x=reorder(test.names,-test.obs),y=test.obs))+
  geom_point()+
  xlab("")+
  ylab("Moran's I")+
  theme(axis.text.x = element_text(angle = 45,vjust=1,hjust=1))

p1/p2


p <- FactoMineR::PCA(mems[,1:12],graph=F)%>%
  factoextra::fviz_pca_biplot()/(
    FactoMineR::PCA(mems[,1:12],graph=F)%>%
      factoextra::fviz_contrib("var",axes = 1)+
      FactoMineR::PCA(mems[,1:12],graph=F)%>%
      factoextra::fviz_contrib("var",axes = 2))
ggsave("Figures/MEMs_PCA.png",p)

mem_long <- gather(mems, MEM, Value, MEM1:(ncol(mems)-2))

p <- FactoMineR::PCA(mems2[,1:12],graph=F)%>%
  factoextra::fviz_pca_biplot()/(
    FactoMineR::PCA(mems2[,1:12],graph=F)%>%
      factoextra::fviz_contrib("var",axes = 1)+
      FactoMineR::PCA(mems2[,1:12],graph=F)%>%
      factoextra::fviz_contrib("var",axes = 2))
ggsave("Figures/mems2_PCA.png",p)
```


## Alpha div patterns

```{r}
paldiv <- meco_16s_ns$sample_table%>%
  left_join(combined)%>%
  ggplot(aes(x=X,y=nb_asvs))+
  geom_point(aes(color=BIOME_NAME))+
  theme_classic2()+
  labs(x="Latitude",y="Richness")+
  geom_smooth(method='lm')+
  ggpmisc::stat_poly_eq(ggpmisc::use_label(c("adj.R2", "f", "p"))) +
  scale_color_manual(values = biomes_color)+
meco_16s_ns$sample_table%>%
  left_join(combined)%>%
  ggplot(aes(x=Y,y=nb_asvs))+
  geom_point(aes(color=BIOME_NAME))+
  theme_classic2()+
  labs(x="Longitude",y="Richness")+
  geom_smooth(method='lm')+
  ggpmisc::stat_poly_eq(ggpmisc::use_label(c("adj.R2", "f", "p")))+
  scale_color_manual(values = biomes_color)

paldiv+plot_layout(guides = "collect")
```

```{r}
# Plot the map
(sitesfil <- st_as_sf(meco_16s_relabfiltered$sample_table, coords = c("X", "Y"), 
                   crs = 4326, agr = "constant"))

sitesfil$nb_asvs <- colSums(meco_16s_relabfiltered$otu_table>0)

mappfil <- ggplot() +
  geom_sf(data = world_lambert, fill = "grey", color = "darkgrey", size = 0.1)+
  geom_sf(data = sitesfil, size = 3, shape = 23, aes(fill = nb_asvs),alpha=.7) +
  ggtitle("MAPP 16s sites") +
  theme(plot.title = element_text(hjust = 0.5, size = 16))+
  theme_minimal()+
  theme(panel.background = element_rect(fill = "azure"))+
  scale_fill_viridis_c( oob = scales::squish)

ggsave("Figures/map_fil.png",mappfil)
```

```{r}
combined$nb_asvs <- colSums(meco_16s_ns$otu_table>0)
combined$nb_reads <- colSums(meco_16s_ns$otu_table)
```



```{r}
ggplot(combined,aes(x=BIOME_NAME,y=nb_asvs,color=BIOME_NAME))+
  geom_boxplot(outlier.shape = NA)+
  scale_color_manual(values=biomes_color, name="Biome")+
  geom_jitter()+
  theme_classic2()+
  ylab("ASVs richness")+
  xlab("")+
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))+
ggplot(combined,aes(x=BIOME_NAME,y=nb_reads,color=BIOME_NAME))+
  geom_boxplot(outlier.shape = NA)+
  scale_color_manual(values=biomes_color, name="Biome")+
  geom_jitter()+
  theme_classic2()+
  ylab("Sequencing depth")+
  xlab("")+
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))+
  plot_layout(guides = "collect")
```

```{r}
ggplot(combined,aes(x=ECO_NAME,y=nb_asvs,color=ECO_NAME))+
  geom_boxplot(outlier.shape = NA)+
  scale_color_manual(values=c("#800000","#9a6324","#808000","#469990","#000075","#000000","#e6194b","#f58231","#ffe119","#bfef45","#3cb44b","#42d4f4","#4363d8","#911eb4","#f032e6","#a9a9a9","#fabed4","#ffd8b1","#fffac8","#aaffc3","#dcbeff","darkorchid4","darkolivegreen3"), name="Biome")+
  geom_jitter()+
  theme_classic2()+
  ylab("ASVs richness")+
  xlab("")+
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))+
  facet_wrap(~BIOME_NAME,scales = "free_x")+
ggplot(combined,aes(x=ECO_NAME,y=nb_reads,color=ECO_NAME))+
  geom_boxplot(outlier.shape = NA)+
  scale_color_manual(values=c("#800000","#9a6324","#808000","#469990","#000075","#000000","#e6194b","#f58231","#ffe119","#bfef45","#3cb44b","#42d4f4","#4363d8","#911eb4","#f032e6","#a9a9a9","#fabed4","#ffd8b1","#fffac8","#aaffc3","#dcbeff","darkorchid4","darkolivegreen3"), name="Biome")+
  geom_jitter()+
  theme_classic2()+
  ylab("Sequencing depth")+
  xlab("")+
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))+
  plot_layout(guides = "collect")+
  facet_wrap(~BIOME_NAME,scales = "free_x")
```


## Cyto pattern

```{r}
cyto_data <- read.csv2("../../ressource/cytometry/bacteria_algae_abundances_2022.csv")

cyto_data%<>%
    mutate(ID=stringr::str_replace(ID,"\\.1","a"))%>%
    mutate(ID=stringr::str_replace(ID,"\\.2","b"))%>%
    mutate(ID=stringr::str_replace(ID,"\\.3","c"))%>%
    mutate(ID=ifelse(nchar(ID)<3,paste0("0",ID),ID))%>%
    mutate(ID=ifelse(nchar(ID)<3,paste0("0",ID),ID))

combined$Sample%in%cyto_data$ID
setdiff(combined$Sample,cyto_data$ID)

cyto_data$Sample <- cyto_data$ID
tmp <- left_join(combined,cyto_data)
tmp <- tmp[-109,]
tmp$nb_asvs <- colSums(meco_16s_relabfiltered$otu_table>0)

tmp%>%
  ggplot(aes(x=nb_asvs,y=Bacteria_AB_mL))+
  geom_point(aes(color=BIOME_NAME))+
  geom_smooth(method='lm')+
  ggpmisc::stat_poly_eq(ggpmisc::use_label(c("adj.R2", "f", "p")))+
  scale_color_manual(values=biomes_color)
```


```{r}
(sitescyto <- st_as_sf(tmp, coords = c("X", "Y"), 
                   crs = 4326, agr = "constant"))

mappcyto <- ggplot() +
  geom_sf(data = world_lambert, fill = "grey", color = "darkgrey", size = 0.1)+
  geom_sf(data = sitescyto, size = 3, shape = 23, aes(fill = nb_asvs),alpha=.7) +
  ggtitle("MAPP 16s sites") +
  theme(plot.title = element_text(hjust = 0.5, size = 16))+
  theme_minimal()+
  theme(panel.background = element_rect(fill = "azure"))+
  scale_fill_viridis_c( oob = scales::squish)
mappcyto
ggsave("Figures/map_cyto.png",mappcyto)
```

## Assignation quality

donuts plot without singletons fur 16s
```{r}
plots_comp <- NULL
for( i in c("Order_conf_rdp","Genus_conf_rdp")){
    tmp16s <- clone(meco_16s_relabfiltered)
    tmp16s$sample_table %<>% mutate(dumb_group = "sample")
    tmp16s$otu_table %<>% filter(rowSums(.)>1)
    tmp16s$tidy_dataset()
    
    tmp16s$cal_abund()
    tmp16s1 <- trans_abund$new(tmp16s,taxrank = i,ntaxa = 8,groupmean = "dumb_group")
    
    plot_data1 <- tmp16s1$data_abund
    use_taxanames <- tmp16s1$data_taxanames
    plot_data1$Taxonomy[!plot_data1$Taxonomy %in% c(use_taxanames,"unidentified")] <- "Others"
    plot_data1 %<>% 
        dplyr::group_by(!!!syms(c("Taxonomy","Sample"))) %>% 
        dplyr::summarise(Abundance = sum(Abundance)) %>% 
        as.data.frame(stringsAsFactors = FALSE)
    plot_data1$Taxonomy %<>% factor(., levels = c(use_taxanames[-9], "Others","unidentified"))
    plot_data1$label <- paste0(round(plot_data1$Abundance, 1),"%")
    donut_comp <- ggdonutchart(plot_data1,"Abundance",
                               fill="Taxonomy",
                               label = "label",
                               color = "white",
                               palette =  c(colorRampPalette(brewer.pal(8, "Dark2"))(9),"lightgrey"),
                               guide = guide_legend(reverse = TRUE) )+
        theme(legend.position = "right")

    tmp16s2 <- trans_abund$new(tmp16s,taxrank = i,ntaxa = 8)
    plot_data2 <- tmp16s2$data_abund
    plot_data2$Taxonomy[!plot_data2$Taxonomy %in% c(use_taxanames,"unidentified")] <- "Others"
    plot_data2$Taxonomy %<>% factor(., levels = rev(c(use_taxanames[-9], "Others","unidentified")))
   bar_comp <- plot_data2%>%
        ggplot(aes(x=Sample,y=Abundance,fill=Taxonomy),color=NA)+
        geom_bar(stat = "identity",width=1,position='fill')+
        scale_fill_manual(values =  rev(c(colorRampPalette(brewer.pal(8, "Dark2"))(9),"lightgrey")),
                          guide = guide_legend(reverse = TRUE) )+
        scale_y_continuous(expand = c(0,0))+
        theme(axis.text.x = element_blank(),
              axis.ticks.x = element_blank())
    
    plots_comp[[i]] <- donut_comp + bar_comp  +  plot_annotation(title = 'No singletons') & theme(plot.title = element_text(face='bold'))
}
plots_comp$Order_conf_rdp
```

```{r}
ggsave("Figures/comp_order_relfil.png",plots_comp$Order_conf_rdp,width = 14)
ggsave("Figures/com_genus_relfil.png",plots_comp$Genus_conf_rdp,width = 14)
```

## Prevalence

```{r}
for( i in c("meco_16s_ns","meco_16s_relabfiltered")){
    
    d_tmp <- get(i)
    d_tmp <- clone(d_tmp)
    
    p <- rowSums(d_tmp$otu_table>0)%>%
        gghistogram(fill="darkorange",binwidth = 1)+
        scale_x_continuous(expand = c(0,0))+
        scale_y_continuous(expand = c(0,0))+
        xlab("Prevalence")+
        ylab("ASVs count")+
        ggtitle(paste0(nrow(d_tmp$otu_table)," ASVs"))+
        coord_trans(y = "log1p")
    ggsave(paste0("Figures/prev_",i,".png"),p)
}
```


## Heatmaps

```{r}
for( i in c("meco_16s_ns","meco_16s_relabfiltered")){
    
    d_tmp <- get(i)
    d_tmp <- clone(d_tmp)
    
    hmap <- d_tmp$otu_table%>%
        mutate(otus=rownames(.))%>%
        reshape2::melt()%>%
        mutate(variable=gsub("[A-Z]|-|(?=_).*","",variable,perl = T),
               value=ifelse(value==0,NA,value))%>%
        ggplot(aes(x=variable,y=otus,fill=log(1+value)))+
        geom_tile()+
        scale_fill_viridis_c()+
        theme_void()+
        guides(fill=guide_legend("Logged number of reads"))
    
    ggsave(paste0("Figures/hmap_",i,'.png'),hmap)
}
```


```{r}
meco_16s_ns$otu_table%>%
    mutate(prevalence=rowSums(.>0))%>%
    ggplot(aes(x=prevalence))+
    geom_bar()

otus_more_than_50_samples <- meco_16s_ns$otu_table%>%
    mutate(prevalence=rowSums(.>0))%>%
    filter(prevalence>49)
otus_more50 <- rownames(otus_more_than_50_samples)

quoi <- meco_16s_ns$otu_table%>%
    mutate(prevalence=rowSums(.>0))
min(quoi$prevalence)
```


```{r}
meco_16s_ns$sample_table%<>%
  left_join(combined,by = "Sample")

(meco_16s_ns$otu_table%>%
   mutate(otus=rownames(.))%>%
   mutate(high_prev=ifelse(otus%in%otus_more50,"yes","nope"))%>%
   group_by(high_prev)%>%
   summarise(across(1:(ncol(.)-2),sum))%>%
   mutate(across(where(is.numeric),~(./sum(.))*100))%>%
   reshape2::melt(id.vars=c("high_prev"))%>%
   ggplot(aes(x=variable,y=value,fill=high_prev))+
   geom_bar(stat = "identity", position = "stack",width=1)+
   scale_fill_manual(values=c("darkorange","darkorchid4"))+
   theme_classic2()+
   theme(axis.text.x = element_blank(),
         axis.ticks.x = element_blank(),
         axis.title.x = element_blank())+
   scale_y_continuous(expand=c(0,0))+
   ylab("Relative abundance within samples (%)"))/(
     meco_16s_ns$sample_table%>%
       ggplot(aes(x=1,y=gsub("[A-Z]|-|(?=_).*","",Sample,perl = T),fill=BIOME_NAME))+
       geom_tile()+
       coord_flip()+
       scale_fill_manual(values=biomes_color)+
       theme_void())+        
  guides(fill=guide_legend(ncol=3))+
  plot_layout(heights = c(9,1),guides="collect")
```
```{r}
(meco_16s_ns$otu_table%>%
   mutate(otus=rownames(.))%>%
   mutate(high_prev=ifelse(otus%in%otus_more50,"yes","nope"))%>%
   group_by(high_prev)%>%
   summarise(across(1:(ncol(.)-2),sum))%>%
   mutate(across(where(is.numeric),~(./sum(.))*100))%>%
   reshape2::melt(id.vars=c("high_prev"))%>%
   ggplot(aes(x=variable,y=value,fill=high_prev))+
   geom_bar(stat = "identity", position = "stack",width=1)+
   scale_fill_manual(values=c("darkorange","darkorchid4"))+
   theme_classic2()+
   theme(axis.text.x = element_blank(),
         axis.ticks.x = element_blank(),
         axis.title.x = element_blank())+
   scale_y_continuous(expand=c(0,0))+
   ylab("Relative abundance within samples (%)"))/(
     meco_16s_ns$sample_table%>%
       ggplot(aes(x=1,y=gsub("[A-Z]|-|(?=_).*","",Sample,perl = T),fill=ECO_NAME))+
       geom_tile()+
       coord_flip()+
       scale_fill_manual(values=c("#800000","#9a6324","#808000","#469990","#000075","#000000","#e6194b","#f58231","#ffe119","#bfef45","#3cb44b","#42d4f4","#4363d8","#911eb4","#f032e6","#a9a9a9","#fabed4","#ffd8b1","#fffac8","#aaffc3","#dcbeff","darkorchid4","darkolivegreen3"))+
       theme_void())+        
  guides(fill=guide_legend(ncol=3))+
  plot_layout(heights = c(9,1),guides="collect")
```


## LMM

```{r}
combined %<>% left_join(meco_16s_ns$sample_table)

test <- lm(formula = XFormula_st,
                    data = combined)
anova(test)

test <- lm(formula = XFormula_lt,
                    data = combined)
anova(test)
plot(test)
predict(test)

df_test_pred <- data.frame(pred_asvs = predict(test),
                           actual_asvs = combined$nb_asvs)
df_test_pred %>%
    ggplot(aes(x=actual_asvs,
               y=pred_asvs))+
    geom_point()+
    geom_smooth(method = "lm")+
    stat_regline_equation(label.y = max(df_test_pred$pred_asvs), aes(label = ..rr.label..))

```

## envfit NMDS

```{r}
store_env_fit <- NULL
for(i in c("_lt","_st")){
  
  var_tmp <- colnames(combined)[which(grepl(i,colnames(combined)))]
  var_interest <- c("aet","pr","swe","tmmn","tmmx","vpd","elevation","evi","fpar","gpp","ph","soc")
  var_tmp <- var_tmp[which(gsub(i,"",var_tmp)%in%var_interest)]
  
  env <- combined[,var_tmp]
  
  for(j in c("filt","nonfilt")){
    
    if(j=="filt"){
      com_tmp <- get("meco_16s_relabfiltered")
    }else{
      com_tmp <- get("meco_16s_ns")
    }
    p_title <- paste0("NMDS envfit ",ifelse(i=="_lt","long term ","short term "), ifelse(j=="filt", "filtered","non filtered"))
    
    com <- t(com_tmp$otu_table)
    nmds <- metaMDS(com, distance="horn")
    en <- envfit(nmds, env, permutations = 999, na.rm = TRUE)
    
    data.scores <- as.data.frame(scores(nmds)$sites)
    data.scores%<>%mutate(Sample=gsub("[A-Z]|-|(?=_).*","",rownames(.),perl = T))
    data.scores%<>%left_join(combined)
    
    en_coord_cont  <-  as.data.frame(scores(en, "vectors")) * ordiArrowMul(en)
    en_coord_cont$pvals <- en$vectors$pvals 
    en_coord_cont$r2 <- en$vectors$r 
    en_coord_cont %<>% mutate(signif=ifelse(pvals<=0.05,"sig","ns"))%>%
      mutate(label=gsub(i,"",row.names(.)))%>%
      left_join(rename(names_df_clean,label=Var2))
    
    store_env_fit[[i]][[j]] <- ggplot(data = data.scores, aes(x = NMDS1, y = NMDS2)) + 
      geom_point(data = data.scores, aes(colour = BIOME_NAME), size = 3, alpha = 0.8) + 
      scale_colour_manual(values = biomes_color)  + 
      geom_segment(aes(x = 0, y = 0, xend = NMDS1, yend = NMDS2, lty = signif), 
                   data = en_coord_cont, size =1, alpha = 0.5, colour = "grey30") +
      scale_linetype_manual(values=c(2,1),name="Significance")+
      geom_text(data = en_coord_cont, aes(
        x = NMDS1*1.2,
        y = NMDS2*1.2, 
        label = midname), colour = "grey30", 
                fontface = "bold") + 
      theme(axis.title = element_text(size = 10, face = "bold", colour = "grey30"), 
            panel.background = element_blank(), panel.border = element_rect(fill = NA, colour = "grey30"), 
            axis.ticks = element_blank(), axis.text = element_blank(), legend.key = element_blank(), 
            legend.title = element_text(size = 10, face = "bold", colour = "grey30"), 
            legend.text = element_text(size = 9, colour = "grey30")) + 
      labs(colour = "Country")+
      ggtitle(p_title)
    
    ggsave(paste0("Figures/envfit",i,"_",j,".png"),store_env_fit[[i]][[j]],width = 8,height = 8)
  }
}
```




## dbRDA

```{r}
arrowMul <- function(arrows, data, at = c(0, 0), fill = 0.75) {
  u <- c(range(data[,1], range(data[,2])))
  u <- u - rep(at, each = 2)
  r <- c(range(arrows[, 1], na.rm = TRUE), range(arrows[, 2], na.rm = TRUE))
  rev <- sign(diff(u))[-2]
  if (rev[1] < 0)
    u[1:2] <- u[2:1]
  if (rev[2] < 0)
    u[3:4] <- u[4:3]
  u <- u/r
  u <- u[is.finite(u) & u > 0]
  fill * min(u)
}
```


```{r}
formulaZ <- c(XFormula_lt,XFormula_st)
dbrda_site_biplot <- NULL
for(i in c("_lt","_st")){
  
  var_tmp <- colnames(combined)[which(grepl(i,colnames(combined)))]
  var_interest <- c("aet","pr","swe","tmmn","tmmx","vpd","elevation","evi","fpar","gpp","ph","soc")
  var_tmp <- var_tmp[which(gsub(i,"",var_tmp)%in%var_interest)]
  
  for(j in c("filt","nonfilt")){
    
    if(j=="filt"){
      com_tmp <- get("meco_16s_relabfiltered")
    }else{
      com_tmp <- get("meco_16s_ns")
    }
    p_title <- paste0("dbRDA ",ifelse(i=="_lt","long term ","short term "), ifelse(j=="filt", "filtered","non filtered"))
    
    formula_tmp <- paste0("labdsv::hellinger(t(com_tmp$otu_table))~Condition(nb_reads)+ph+",paste0(var_tmp, collapse = "+"))
    dbrda_tmp <- dbrda(formula=formula(formula_tmp),data=combined, distance="horn") # full model with morisita horn distance based on hellinger transformed data
    
    #get eigen values of axes
    eig <- c(dbrda_tmp$CCA$eig)
    eig1 <- round((eig[1]/sum(eig))*100,digits = 2) # % of explained inertia of the first axis
    eig2 <- round((eig[2]/sum(eig))*100,digits = 2) # % of explained inertia of the second axis
    
    fort_rda_tmp <- fortify(dbrda_tmp) # transform dbrda results in a ggplot2 usable format
    vars <- c("dbRDA1","dbRDA2") # we will plot in the first two dimensions
    want <- fort_rda_tmp[["score"]] == "biplot" # get variables scores (arrows)
    mul <- arrowMul(fort_rda_tmp[want, vars, drop = FALSE],
                    fort_rda_tmp[!want, vars, drop = FALSE]) # get the scaling factor to scale these scores for plotting as in ggvegan
    fort_rda_tmp[want, vars] <- mul * fort_rda_tmp[want, vars] # scale the scores 
    
    fort_rda_tmp%<>%
      mutate(label=gsub(i,"",label))%>%
      mutate(label=gsub("[A-Z]|-|(?=_).*","",label,perl=T))%>%
      left_join(rename(names_df_clean,label=Var2))%>%
      left_join(rename(combined,label=Sample))
    
    dbrda_site_biplot[[i]][[j]] <- ggplot(fort_rda_tmp, aes(x = dbRDA1, y = dbRDA2)) +
      geom_point(data = subset(fort_rda_tmp, score == "sites"), 
                 aes(color = BIOME_NAME), 
                 size = 3) +
      scale_color_manual(values = biomes_color)+
      geom_segment(data = subset(fort_rda_tmp, score == "biplot"), # add arrows for variables
                   aes(x = 0, y = 0, xend=dbRDA1, yend=dbRDA2),
                   lineend = "round", 
                   linejoin = "round",
                   linewidth = .75, 
                   arrow = arrow(length = unit(0.2, "inches")),
                   colour = "black" ) +
      coord_fixed()+ # fix proportion between axis units
      geom_text(data = fort_rda_tmp[want, , drop = FALSE ], # add variable names at the end of arrows
                aes(x = dbRDA1*1.2, # nudge a bit the coordinates so that they're not on the arrows
                    y = dbRDA2*1.2,
                    label = midname))+
      theme_classic()+
      xlab(paste0("dbRDA1 (",eig1,"%)"))+
      ylab(paste0("dbRDA2 (",eig2,"%)"))+
      guides(fill="none")  +
      geom_hline(yintercept=0,linetype = "dashed")+
      geom_vline(xintercept=0,linetype = "dashed")+
      ggtitle(formula_tmp)+
      theme(plot.title = element_text(face="bold"))+
      coord_fixed()+
      ggtitle(paste0(p_title," | contsrained: ", round(dbrda_tmp$CCA$tot.chi/dbrda_tmp$tot.chi,digits = 2)))
    
        ggsave(paste0("Figures/dbrda",i,"_",j,".png"),dbrda_site_biplot[[i]][[j]],width = 8,height = 8)

  }
}
```

```{r}
formulaZ <- c(XFormula_lt,XFormula_st)
dbrda_site_biplot <- NULL
for(i in c("_lt","_st")){
  
  var_tmp <- colnames(combined)[which(grepl(i,colnames(combined)))]
  var_interest <- c("aet","pr","swe","tmmn","tmmx","vpd","elevation","evi","fpar","gpp","ph","soc")
  var_tmp <- var_tmp[which(gsub(i,"",var_tmp)%in%var_interest)]
  
  for(j in c("filt","nonfilt")){
    
    if(j=="filt"){
      com_tmp <- get("meco_16s_relabfiltered")
    }else{
      com_tmp <- get("meco_16s_ns")
    }
    p_title <- paste0("dbRDA ",ifelse(i=="_lt","long term ","short term "), ifelse(j=="filt", "filtered","non filtered"))
    
    formula_tmp <- paste0("labdsv::hellinger(t(com_tmp$otu_table))~Condition(nb_reads)+ph+",paste0(var_tmp, collapse = "+"))
    dbrda_tmp <- dbrda(formula=formula(formula_tmp),data=combined, distance="horn") # full model with morisita horn distance based on hellinger transformed data
    
    #get eigen values of axes
    eig <- c(dbrda_tmp$CCA$eig)
    eig1 <- round((eig[1]/sum(eig))*100,digits = 2) # % of explained inertia of the first axis
    eig2 <- round((eig[2]/sum(eig))*100,digits = 2) # % of explained inertia of the second axis
    
    fort_rda_tmp <- fortify(dbrda_tmp) # transform dbrda results in a ggplot2 usable format
    vars <- c("dbRDA1","dbRDA2") # we will plot in the first two dimensions
    want <- fort_rda_tmp[["score"]] == "biplot" # get variables scores (arrows)
    mul <- arrowMul(fort_rda_tmp[want, vars, drop = FALSE],
                    fort_rda_tmp[!want, vars, drop = FALSE]) # get the scaling factor to scale these scores for plotting as in ggvegan
    fort_rda_tmp[want, vars] <- mul * fort_rda_tmp[want, vars] # scale the scores 
    
    fort_rda_tmp%<>%
      mutate(label=gsub(i,"",label))%>%
      mutate(label=gsub("[A-Z]|-|(?=_).*","",label,perl=T))%>%
      left_join(rename(names_df_clean,label=Var2))%>%
      left_join(rename(combined,label=Sample))
    
    dbrda_site_biplot[[i]][[j]] <- ggplot(fort_rda_tmp, aes(x = dbRDA1, y = dbRDA2)) +
      geom_point(data = subset(fort_rda_tmp, score == "sites"), 
                 aes(color = ECO_NAME), 
                 size = 3) +
      scale_color_manual(values = c("#800000","#9a6324","#808000","#469990","#000075","#000000","#e6194b","#f58231","#ffe119","#bfef45","#3cb44b","#42d4f4","#4363d8","#911eb4","#f032e6","#a9a9a9","#fabed4","#ffd8b1","#fffac8","#aaffc3","#dcbeff","darkorchid4","darkolivegreen3"))+
      geom_segment(data = subset(fort_rda_tmp, score == "biplot"), # add arrows for variables
                   aes(x = 0, y = 0, xend=dbRDA1, yend=dbRDA2),
                   lineend = "round", 
                   linejoin = "round",
                   linewidth = .75, 
                   arrow = arrow(length = unit(0.2, "inches")),
                   colour = "black" ) +
      coord_fixed()+ # fix proportion between axis units
      geom_text(data = fort_rda_tmp[want, , drop = FALSE ], # add variable names at the end of arrows
                aes(x = dbRDA1*1.2, # nudge a bit the coordinates so that they're not on the arrows
                    y = dbRDA2*1.2,
                    label = midname))+
      theme_classic()+
      xlab(paste0("dbRDA1 (",eig1,"%)"))+
      ylab(paste0("dbRDA2 (",eig2,"%)"))+
      guides(fill="none")  +
      geom_hline(yintercept=0,linetype = "dashed")+
      geom_vline(xintercept=0,linetype = "dashed")+
      ggtitle(formula_tmp)+
      theme(plot.title = element_text(face="bold"))+
      coord_fixed()+
      ggtitle(paste0(p_title," | contsrained: ", round(dbrda_tmp$CCA$tot.chi/dbrda_tmp$tot.chi,digits = 2)))
    
        ggsave(paste0("Figures/dbrda_eco",i,"_",j,".png"),dbrda_site_biplot[[i]][[j]],width = 13,height = 10)

  }
}
```


## test new db

```{r}
kegg_fct <- read_delim(file = "picrust2/Kegg_function_all_pathway_id_fullname_20231128.tsv", # read the tsv file
                        delim = "\t", escape_double = FALSE, 
                        trim_ws = TRUE)

kegg_fct2 <- read_delim(file = "picrust2/Kegg_pathway_id_fullname_20231128.tsv", # read the tsv file
                        delim = "\t", escape_double = FALSE, 
                        trim_ws = TRUE)
```

```{r}
all(kegg_files$picrust_fct_unstrat$observation_name%in%kegg_fct$Function_id)
not_in_their_db <- kegg_files$picrust_fct_unstrat$observation_name[!kegg_files$picrust_fct_unstrat$observation_name%in%kegg_fct$Function_id]

setdiff(kegg_fct$Function_id,kegg_files$picrust_fct_unstrat$observation_name)
setdiff(kegg_files$picrust_fct_unstrat$observation_name,kegg_fct$Function_id)
```


```{r}
tset <- kegg_fct
tset %<>% rename(observation_name=Function_id)
tset2 <- kegg_files$picrust_fct_unstrat
tset2%<>%left_join(tset)
```



## Procrustes

```{r}
ordi_16s <- meco_16s_ns$otu_table%>%
  t()%>%
  labdsv::hellinger()%>%
  metaMDS(distance = "horn") # MDS on 16s communities

ordi_metacyc <- metacyc_files$picrust_fct_unstrat%>%
    select(c(which(gsub("[A-Z]|-|(?=_).*","",names(.),perl = T)%in%combined$Sample)))%>%
    t()%>%
    metaMDS(distance = "horn")

ordi_kegg <- kegg_files$picrust_fct_unstrat%>%
    select(c(which(gsub("[A-Z]|-|(?=_).*","",names(.),perl = T)%in%combined$Sample)))%>%
    t()%>%
    metaMDS(distance = "horn")

procrustes_res_16kegg <- vegan::procrustes(ordi_16s,ordi_kegg,symmetric = T)
procrustes_res_16meta <- vegan::procrustes(ordi_16s,ordi_metacyc,symmetric = T)
procrustes_res_metakegg <- vegan::procrustes(ordi_metacyc,ordi_kegg,symmetric = T)
procrustes_list <- c("procrustes_res_16kegg","procrustes_res_16meta","procrustes_res_metakegg")

procrustes_plots <- NULL
for(i in procrustes_list){
 procrustes_tmp <- get(i)
 
 
 ctest <- data.frame(nmds1=procrustes_tmp$Yrot[,1],
                     nmds2=procrustes_tmp$Yrot[,2],
                     xnmds1=procrustes_tmp$X[,1],
                     xnmds2=procrustes_tmp$X[,2])
 
 pro.error <- data.frame(err=residuals(procrustes_tmp),sam_id=meco_16s_ns$sample_table$Sample)
 quantiles <- quantile(pro.error$err,probs = c(0.25,0.50,0.75))
 
 procrustes_plots[[i]] <- ggplot(ctest) +
   geom_point(aes(x=nmds1, y=nmds2)) +
   geom_point(aes(x=xnmds1, y=xnmds2)) +
   geom_segment(aes(x=nmds1,y=nmds2,xend=xnmds1,yend=xnmds2),arrow=arrow(length=unit(0.2,"cm")))+
   coord_fixed()+
   theme_classic2()+
   ggplot(pro.error,aes(x = sam_id, y=err))+
   ggtitle(i)+
   geom_bar(stat='identity',width = 1)+
   geom_hline(yintercept = quantiles[1],linetype="dashed")+
   geom_hline(yintercept = quantiles[2])+
   geom_hline(yintercept = quantiles[3],linetype="dashed")+
   theme_classic2()+
   theme(axis.text.x = element_text(angle=90))+
   xlab("site row")+
   ylab("Residual fit")+ 
   plot_layout(widths = c(1.4,1.6))
}
```


```{r}
rowSums(meco_16s_relabfiltered$otu_table>0)%>%
    as.data.frame()%>%
    rename(prev=1)%>%
    ggplot(aes(x=prev))+
    geom_histogram(binwidth = 1)


rowSums(meco_16s_relabfiltered$otu_table>0)%>%
    as.data.frame()%>%
    rename(prev=1)%>%
    count(prev>2)
```


```{r}
ordi_metacyc_hell <- metacyc_files$picrust_fct_unstrat%>%
    dplyr::select(c(which(gsub("[A-Z]|-|(?=_).*","",names(.),perl = T)%in%combined$Sample)))%>%
    t()%>%
    labdsv::hellinger()%>%
    metaMDS(distance = "horn")

ordi_kegg_hell <- kegg_files$picrust_fct_unstrat%>%
    dplyr::select(c(which(gsub("[A-Z]|-|(?=_).*","",names(.),perl = T)%in%combined$Sample)))%>%
    t()%>%
    labdsv::hellinger()%>%
    metaMDS(distance = "horn")



procrustes_cor <- c(protest(X = mds_filtered, Y = ordi_16s, scores = "sites", permutations = 999)$t0,
                       protest(X = ordi_16s, Y = ordi_kegg, scores = "sites", permutations = 999)$t0,
                       protest(X = ordi_16s, Y = ordi_metacyc, scores = "sites", permutations = 999)$t0,
                       protest(X = ordi_metacyc, Y = ordi_kegg, scores = "sites", permutations = 999)$t0,
                       protest(X = ordi_metacyc_hell, Y = ordi_metacyc, scores = "sites", permutations = 999)$t0,
                       protest(X = ordi_kegg_hell, Y = ordi_kegg, scores = "sites", permutations = 999)$t0,
                       protest(X = ordi_metacyc_hell, Y = ordi_kegg_hell, scores = "sites", permutations = 999)$t0,
                       protest(X = ordi_16s, Y = ordi_kegg_hell, scores = "sites", permutations = 999)$t0,
                       protest(X = ordi_16s, Y = ordi_metacyc_hell, scores = "sites", permutations = 999)$t0)

names(procrustes_cor) <- c("full_vs_filtered",
                           "16s_kegg",
                           "16s_metacyc",
                           "metacyc_kegg",
                           "metacyc_hell_nohell",
                           "kegg_hell_nohell",
                           "metacyc_kegg_hell",
                           "16s_kegghell",
                           "16s_metacychell")

cor_procrustes_df <- data.frame(procrustes_cor=procrustes_cor,
                                type_procor=names(procrustes_cor))




cor_procrustes_df%>%
  ggplot(aes(x=type_procor,y=procrustes_cor,fill=type_procor))+
  geom_bar(stat="identity")+
  theme_classic2()+
  theme(axis.text.x = element_text(angle=45,hjust = 1))+
  scale_fill_manual(values=RColorBrewer::brewer.pal(9,"Set3"))+
  scale_y_continuous(expand=c(0,0),limits = c(0,1))
```

```{r}
d_full <- meco_16s_ns$otu_table%>%
    select(c(which(gsub("[A-Z]|-|(?=_).*","",names(.),perl = T)%in%combined$Sample)))%>%
    t()%>%
    labdsv::hellinger()%>%
    vegan::vegdist(method = "horn")


d_filt <- meco_16s_relabfiltered$otu_table%>%
    select(c(which(gsub("[A-Z]|-|(?=_).*","",names(.),perl = T)%in%combined$Sample)))%>%
    t()%>%
    labdsv::hellinger()%>%
    vegan::vegdist(method = "horn")

d_metacyc <- metacyc_files$picrust_fct_unstrat%>%
    select(c(which(gsub("[A-Z]|-|(?=_).*","",names(.),perl = T)%in%combined$Sample)))%>%
    t()%>%
    labdsv::hellinger()%>%
    vegan::vegdist(method = "horn")


d_kegg <- kegg_files$picrust_fct_unstrat%>%
    select(c(which(gsub("[A-Z]|-|(?=_).*","",names(.),perl = T)%in%combined$Sample)))%>%
    t()%>%
    labdsv::hellinger()%>%
    vegan::vegdist(method = "horn")


mantel(xdis = d_full,
       ydis = d_filt)

mantel(xdis = d_metacyc,
       ydis = d_kegg)
```





## Network

```{r}
# # Required packages
# install.packages("devtools")
# install.packages("BiocManager")
# 
# # Install NetCoMi
# devtools::install_github("zdk123/SpiecEasi", 
#                          dependencies = c("Depends", "Imports", "LinkingTo"),
#                          repos = c("https://cloud.r-project.org/",
#                                    BiocManager::repositories()))
devtools::install_github("valentinitnelav/plotbiomes")
library(plotbiomes)

whittaker_base_plot()

install.packages("WGCNA", repos = BiocManager::repositories())

rm(net1,d1)
d1 <-clone(meco_16s_relabfiltered)
d1 <- d1
net1 <- trans_network$new(dataset = d1, cor_method = "pearson",use_WGCNA_pearson_spearman=T)

net1$cal_network(COR_p_thres = 0.01, COR_optimization = TRUE)

net1$cal_module(method = "cluster_fast_greedy")

net1$res_network

net1$save_network(filepath = "network.gexf")

net1$get_node_table(node_roles = TRUE)

net1$cal_network_attr()
```


```{r}
rm(net2,d2)
d2 <- clone(meco_16s_relabfiltered)
d2 <- d2
net2 <- trans_network$new(dataset = d2)

net2$cal_network(network_method = "SpiecEasi", SpiecEasi_method = "mb")

net2$cal_module(method = "cluster_leading_eigen")

net2$save_network(filepath = "networkspieceasi.gexf")

net2$get_node_table(node_roles = TRUE)

net2$cal_network_attr()
net2$res_network_attr
net2$res_node_table 



rm(net3,d3)
d3 <- clone(meco_16s_relabfiltered)
d3 <- d3
net3 <- trans_network$new(dataset = d3)

net3$cal_network(network_method = "SpiecEasi", SpiecEasi_method = "glasso")

net3$cal_module(method = "cluster_leading_eigen")

net3$save_network(filepath = "networkspieceasiglasso.gexf")

net3$get_node_table(node_roles = TRUE)
```

```{r}
module_col <- c("#FF326D","#00B7DA","#14B200","#7083ED","#FF6000","#A18B00","#00A66F","#007D90","#F657E4","#AA5C2D","#A25886","#4B7D34","#00A3F9","#404040ff")
nb_module <- 13

mod_ab_plot_list <- NULL
hmap_network_list <- NULL
plots_comp_module <- NULL
net_list <- list(net1=net1,net2=net2,net3=net3)
for(i in names(net_list)){
  net_tmp <- net_list[[i]]
  net_tmp <- net_tmp # get network
  tmp_data <- clone(meco_16s_relabfiltered)
  tmp_data <- tmp_data # get communities
  
  tmp_data$tax_table$name <- rownames(tmp_data$tax_table)
  tmp_data$tax_table %<>% left_join(net1$res_node_table) # merge network output and taxa information
  
  distfrom01 <- geodist::geodist(combined[1,c("X2","Y2")],combined[2:199,c("X2","Y2")],measure = 'geodesic') #compute geographic distance from the first sample to order samples
  
  
  df_tmp_plot <- tmp_data$otu_table%>%
    mutate(name=rownames(.))%>%
    reshape2::melt()%>%
    left_join(tmp_data$tax_table)%>%
    filter(!is.na(module))%>% # remove ASVs without modules (i.e. not kept in the network)
    filter(value!=0)%>% # remove rows with no abundances (ASVs is not found in that sample)
    group_by(variable)%>%
    mutate(relab=value/sum(value),
           variable=gsub("[A-Z]|-|(?=_).*","",variable,perl=T))%>% # compute relative abundance
    ungroup()%>%  
    left_join(rename(cbind(distfrom01=c(0,distfrom01),combined[,!names(combined)==("variable")]),variable=Sample)) # add distance
  
  
  # get most abundant (reads count) and biggest (number of asvs) modules
  top13_mod_reads <- df_tmp_plot%>%
    group_by(module)%>%
    summarise(totreads=sum(value))%>%
    arrange(desc(totreads))%>%
    slice(1:13)%>%
    dplyr::select(module)%>%
    pull()%>%
    as.character()
  
  top13_mod_size <- paste0("M",1:13)
  
  df_tmp_plot %<>%
    left_join(rename(combined,variable=Sample))%>%
    mutate(mod2keep_reads=ifelse(as.character(module)%in%top13_mod_reads,as.character(module),"MNA"),
           mod2keep_size=ifelse(as.character(module)%in%top13_mod_size,as.character(module),"MNA"))%>%
    mutate(mod2keep_reads=fct_relevel(mod2keep_reads, paste0("M",sort(unique(as.numeric(gsub("M","",as.character(mod2keep_reads)))),na.last = T))),
           mod2keep_size=fct_relevel(mod2keep_size, paste0("M",sort(unique(as.numeric(gsub("M","",as.character(mod2keep_size)))),na.last = T))))%>%
    mutate(mod2keep_reads=fct_recode(mod2keep_reads, "Others" = "MNA"),
           mod2keep_size=fct_recode(mod2keep_size, "Others" = "MNA"))%>%
    arrange(BIOME_NAME)%>%
    mutate(variable=as.factor(variable))%>%
    mutate(variable=fct_relevel(variable,as.character(unique(variable))))
  
  # Plot Module RELAB across samples
  p_relab_module <- df_tmp_plot%>%
    ggplot(aes(x=variable,y=relab,fill=mod2keep_reads))+
    geom_bar(stat="identity",position = "stack",width=1)+
    scale_fill_manual(values = module_col)+
    theme_classic2()+
    scale_y_continuous(expand = c(0,0))+
    theme(axis.text.x = element_blank(),
          axis.title.x = element_blank())+
    df_tmp_plot%>%
    ggplot(aes(x=variable,y=1,fill=BIOME_NAME))+
    geom_tile()+
    scale_fill_manual(values=biomes_color)+
    theme_void()+
    plot_layout(heights = c(9,1),guides = "collect")+ 
    theme(axis.text.x = element_text(angle = 90, vjust=.5,hjust=1,size=3))
  
  
  # Plot module total reads and size
  module_ab <- data_tmp$otu_table%>%
    mutate(name=rownames(.))%>%
    left_join(net1$res_node_table[,c("name","module")])%>%
    filter(!is.na(module))%>%
    reshape2::melt()%>%
    mutate(value=ifelse(value==0,NA,value))%>%
    group_by(module)%>%
    summarise(modab=sum(value,na.rm = T),
              modasvs=length(unique(name)))
  
  reads_modules <- module_ab %>%
    arrange(desc(modab))%>%
    mutate(module=as.factor(module))%>%
    ggplot(aes(x=reorder(module,-modab),y=modab))+
    geom_bar(stat='identity',width=1,color="grey40")+
    scale_y_continuous(expand=c(0,0))+
    theme(axis.text.x = element_text(angle=45,vjust=1,hjust=1))+
    xlab("")+
    ylab("Cumulative number of reads")
  
  asvs_modules <- module_ab %>%
    arrange(desc(modab))%>%
    mutate(module=as.factor(module))%>%
    ggplot(aes(x=reorder(module,-modab),y=modasvs))+
    geom_bar(stat='identity',width=1,color="grey40")+
    scale_y_continuous(expand=c(0,0))+
    theme(axis.text.x = element_text(angle=45,vjust=1,hjust=1))+
    xlab("")+
    ylab("Number of ASVs within modules")
  
  prev_cluster <- df_tmp_plot%>%group_by(name)%>%summarise(prev=sum(value>0))%>%filter(prev<100)
  
  # Plot hmap modules
  
  for(j in c("reads","size")){
    
    if(j=="reads"){
      col2use <- "mod2keep_reads"
    }else{
      col2use <- "mod2keep_size"
    }
    
    pheatmap_net <- df_tmp_plot%>%
      ggplot(aes(x=1,y=variable,fill=BIOME_NAME))+
      geom_tile()+
      scale_fill_manual(values = biomes_color)+
      theme(axis.title = element_blank(),
            axis.text.x = element_blank(),
            axis.ticks.x = element_blank())+
      theme(plot.margin = unit(c(0,0,0,0), "cm"))+
      df_tmp_plot%>%
      arrange(.data[[col2use]])%>%
      mutate(name=fct_relevel(name,unique(name)))%>%
      ggplot(aes(name,variable,fill=log(value)))+
      geom_tile()+
      scale_fill_viridis_b()+
      theme_void()+
      theme(plot.margin = unit(c(0,0,0,0), "cm"),
            panel.background = element_rect(fill="darkgrey"))+
      plot_spacer()+
      df_tmp_plot%>%
      arrange(.data[[col2use]])%>%
      mutate(name=fct_relevel(name,unique(name)))%>%
      ggplot(aes(name,1,fill=.data[[col2use]]))+
      geom_tile()+
      theme(axis.text.x = element_text(angle=90,size=3,vjust=.5,hjust=.5),
            axis.title.y = element_blank(),
            axis.ticks.y = element_blank(),
            axis.text.y = element_blank(),
            axis.title.x = element_blank())+
      scale_fill_manual(values = module_col)+
      theme(plot.margin = unit(c(0,0,0,0), "cm"))+
      plot_layout(guides="collect",widths = c(0.1,9),heights = c(9,.1),ncol = 2,nrow = 2)
    ggsave(paste0("Figures/pheatmap_network_",i,"_",j,".png"),pheatmap_net,width = 20,height = 13)
    
    
    pheatmap_net_lowprev <- df_tmp_plot%>%
      filter(name%in%prev_cluster$name)%>%
      ggplot(aes(x=1,y=distfrom01,fill=BIOME_NAME))+
      geom_tile()+
      scale_fill_manual(values = biomes_color)+
      theme(axis.title = element_blank(),
            axis.text.x = element_blank(),
            axis.ticks.x = element_blank())+
      theme(plot.margin = unit(c(0,0,0,0), "cm"))+
      df_tmp_plot%>%
      filter(name%in%prev_cluster$name)%>%
      arrange(.data[[col2use]])%>%
      mutate(name=fct_relevel(name,unique(name)))%>%
      ggplot(aes(name,distfrom01,fill=log(value)))+
      geom_tile()+
      scale_fill_viridis_b()+
      theme_void()+
      theme(plot.margin = unit(c(0,0,0,0), "cm"),
            panel.background = element_rect(fill="darkgrey"))+
      plot_spacer()+
      df_tmp_plot%>%
      arrange(.data[[col2use]])%>%
      filter(name%in%prev_cluster$name)%>%
      mutate(name=fct_relevel(name,unique(name)))%>%
      ggplot(aes(name,1,fill=.data[[col2use]]))+
      geom_tile()+
      theme(axis.text.x = element_text(angle=90,size=3,vjust=.5,hjust=.5),
            axis.title.y = element_blank(),
            axis.ticks.y = element_blank(),
            axis.text.y = element_blank(),
            axis.title.x = element_blank())+
      scale_fill_manual(values = module_col)+
      theme(plot.margin = unit(c(0,0,0,0), "cm"))+
      plot_layout(guides="collect",widths = c(0.1,9),heights = c(9,.1),ncol = 2,nrow = 2)
    ggsave(paste0("Figures/pheatmap_network_lowprev_",i,"_",j,".png"),pheatmap_net,width = 20,height = 13)
    
    
  }
  
  ggsave(paste0("Figures/module_info_",i,".png"),reads_modules/asvs_modules,width = 9, height = 8)
  ggsave(paste0("Figures/module_relab_",i,".png"),p_relab_module,width = 20, height = 10)
  
}
```



## Boruta 

```{r}
library(Boruta)
set.seed(973)
boruta_train_st <- Boruta(meco_16s_ns$otu_table~., data = combined[,c("ph",var_st)], doTrace = 2)
print(boruta_train_st)

boruta_train_lt <- Boruta(meco_16s_ns$otu_table~., data = combined[,c("ph",var_lt)], doTrace = 2)
print(boruta_train_lt)
```



## Random Forest

```{r}
rf_rez <- NULL
plot_var_xplain <- NULL
store_var <- NULL
var_unlist <- NULL
for(i in c("_lt","_st")){
  
  var_tmp <- colnames(combined)[which(grepl(i,colnames(combined)))]
  
  var_interest <- c("aet","pr","swe","tmmn","tmmx","vpd","elevation","evi","fpar","gpp","ph","soc")
  
  var_tmp <- var_tmp[which(gsub(i,"",var_tmp)%in%var_interest)]
  
  XFormula_tmp <- paste("train$",var_tmp,sep="", collapse = "+")
  XFormula_tmp <- paste0("~train$ph+",XFormula_tmp)
  
  formu <- XFormula_tmp
  var <- var_tmp
  
  for(j in c("filt","nonfilt")){
    

    if(j=="filt"){
      com_tmp <- get("meco_16s_relabfiltered")
    }else{
      com_tmp <- get("meco_16s_ns")
    }
    
    clust2keep <- rowSums(com_tmp$otu_table>0)%>%
      as.data.frame()%>%
      rename(prev=1)%>%
      mutate(cluster_id=rownames(.),
             respect_prev=ifelse(prev>3,"yup","nope"))%>%
      filter(respect_prev=="yup")
    
    tmp <- com_tmp$otu_table
    # tmp <- tmp[rownames(tmp)%in%clust2keep$cluster_id,]
    tmp%<>%
      t()%>%
      as.data.frame()%>%
      mutate(Sample= gsub("[A-Z]|-|(?=_).*","",rownames(.),perl = T))
    
    tmp$richness <- rowSums(dplyr::select(tmp,-Sample)>0)
    
    ind <- sample(2, nrow(tmp), replace = TRUE, prob = c(0.7, 0.3))
    
    for(k in 1:500){
      
      ind <- sample(2, nrow(tmp), replace = TRUE, prob = c(0.7, 0.3))
      
      train <- combined[ind==1,c("Sample","ph",var)]
      test <- combined[ind==2,c("Sample","ph",var)]
      train%<>%
        left_join(tmp)
      
      var_rf <- NULL  
      formula_tmp <- paste0("richness",formu)
      rf <- randomForest::randomForest(as.formula(formula_tmp), data=train, proximity=TRUE, type = "regression") 
      rf_rez[[j]][[i]][[k]] <- rf
      var_rf <- c(round(100 * rf$rsq[length(rf$rsq)], digits = 2),var_rf)
      store_var[[j]][[i]][[k]] <- var_rf
    }
    
  }
}
```

```{r}
tseteudessuh <- data.frame(used_df = c(rep("filt",1000),rep("nonfilt",1000)),
                           type = rep(c(rep("lt",500),rep("st",500)),2),
                           var = c(c(unlist(store_var$filt$`_lt`)),c(unlist(store_var$filt$`_st`)),
                                   c(unlist(store_var$nonfilt$`_lt`)),c(unlist(store_var$nonfilt$`_st`))))

p_RF <- tseteudessuh%>%
  ggplot(aes(x=type,y=var,fill=type))+
  geom_violin()+
  facet_wrap(~used_df)+
  ylab("Explained variance (%)")+
  theme_classic2()+
  scale_fill_manual(values=c("darkcyan","burlywood"),labels=c("Long term","Short term"),name="Variable type")+
  theme(axis.title.x = element_blank(),
        axis.text.x = element_blank())

ggsave("Figures/RF_var.png",p_RF)
```

## GDM

```{r}
gdm_formated <- NULL
gdm_fitted <- NULL
for(i in c("lt","st")){
    
  for(j in c("filt","nonfilt")){
    
    meco_tmp <- get(ifelse(j=="filt","meco_16s_relabfiltered","meco_16s_ns")) # get com datasets
    data_sat_tmp <- combined
    bioclim_predictors <- get(paste0("var_",i))
    bioclim_predictors <- c("ph",bioclim_predictors)
    
    
    comunity_df_hellingered <- as.data.frame(labdsv::hellinger(t(meco_tmp$otu_table))) # extract community matrices and transform to hellinger
    
    comunity_df_hellingered$siteCol <-  gsub("[A-Z]|-|(?=_).*","",rownames(comunity_df_hellingered),perl = T)  # get site name (i.e., sample)
    comunity_df_hellingered %<>%  
        mutate(siteCol=ifelse(nchar(siteCol)<3,paste0("0",siteCol),siteCol))%>% # reformat 1 into 001 and 64 to 064 etc...
        mutate(siteCol=ifelse(nchar(siteCol)<3,paste0("0",siteCol),siteCol))
    data_sat_tmp %<>% rename(siteCol=Sample) # rename 
    
    gdm_biodata <- left_join(comunity_df_hellingered,data_sat_tmp[,c("siteCol","X","Y")]) %>% # create gdm_biodata with site X and Y (long and lat)
        relocate(siteCol,X,Y)
    gdm_preddata <- data_sat_tmp %>%
        filter(siteCol%in%gdm_biodata$siteCol) %>% #remove sites not in biodata
        dplyr::select(all_of(c(bioclim_predictors,"siteCol"))) # get only variables we are interested in
    
    gdm_formated_tmp <- gdm::formatsitepair(bioData = gdm_biodata, # create data in the gdm format
                                            bioFormat = 1,
                                            dist="horn",
                                            abundance = T,
                                            siteColumn = "siteCol",
                                            sppColumn = NULL,
                                            abundColumn = NULL,
                                            XColumn = "X",
                                            YColumn = "Y",
                                            predData = gdm_preddata)
    gdm_formated[[i]][[j]] <- gdm_formated_tmp # store formated data
    gdm_fitted[[i]][[j]] <- gdm::gdm(gdm_formated_tmp, # fit gdm
                                geo = T)
    }
}
```

```{r}
gdm_plot_var <- NULL
gdm_plot_pred <- NULL
gdm_var_contrib <- NULL
for(i in c("lt","st")){
  
  for(j in c("filt","nonfilt")){
    
    # VAR
    gdm_spline_data <- gdm::isplineExtract(gdm_fitted[[i]][[j]])
    
    p_var <- gdm_spline_data$x%>%
      reshape2::melt()%>%
      rename(valuex=value)%>%
      left_join(reshape2::melt(gdm_spline_data$y[,which(colSums(gdm_spline_data$y)!=0)]))%>%
      mutate(Var2=gsub("_[a-z]{2}","",Var2))%>%
      rename(valuey=value)%>%
      left_join(names_df_clean)%>%  
      mutate(midname=fct_relevel(midname,unique(names_df_clean$midname)))%>%
      filter(Var2%in%gsub("_[a-z]{2}","",names(which(colSums(gdm_spline_data$y)!=0))))
    
    gdm_plot_var[[i]][[j]] <- p_var %>%
      ggplot(aes(x=valuex, y=valuey))+
      geom_line()+
      facet_wrap(~midname, scales="free")+
      theme_bw()+
      theme(axis.title = element_blank())
    
    gdm_var_contrib[[i]][[j]] <- p_var %>%
      group_by(midname)%>%
      summarise(maxy=max(valuey))%>%
      ggplot(aes(x=reorder(midname,-maxy),y=maxy,fill=midname))+
      geom_bar(stat = "identity")+
      scale_fill_manual(values = brewer.pal(8,"Dark2"),name="Variables")+
      xlab("")+
      ylab("Max effect")+
      theme_bw()+
      theme(axis.text.x = element_text(angle=45,hjust=1,vjust=1))
      
    # PRED
    
    gdm_pred_data <- predict(object=gdm_fitted[[i]][[j]],
                             data=gdm_formated[[i]][[j]])
    
    prd_df <- data.frame(pred=gdm_fitted[[i]][[j]]$predicted,
                         obs=gdm_fitted[[i]][[j]]$observed,
                         eco=gdm_fitted[[i]][[j]]$ecological)
    
    prd_df$density_ecoobs <- get_density(prd_df$obs, prd_df$eco, n = 100)
    prd_df$density_obspred <- get_density(prd_df$obs, prd_df$pred, n = 100)
    
    overlayX <- seq(from = min(prd_df$eco), to = max(prd_df$eco), 
                    length = 199)
    overlayY <- 1 - exp(-overlayX)
    df_over <- data.frame(x=overlayX,y=overlayY)
    
    
    gdm_plot_pred[[i]][[j]] <- ggplot()+
      geom_point(prd_df,mapping=aes(x=eco,
                                    y=obs,
                                    color=density_ecoobs))+
      geom_line(data=df_over,mapping=aes(x=x,y=y),color="darkblue",lwd=1.5)+
      ylim(c(0,1))+ 
      viridis::scale_color_viridis()+
      xlab("Ecological distance")+
      ylab("Observed dissimilarity")+
      ggplot(prd_df,
             aes(x=obs,
                 y=pred,
                 color=density_obspred))+
      geom_point()+
      geom_abline (slope=1, color="darkblue",lwd=1.5)+
      viridis::scale_color_viridis()+
      xlab("Observed dissimilarity")+
      ylab("Predicted dissimilarity")
    
  }
}
```

```{r}
for(i in c("lt","st")){
  
  for(j in c("filt","nonfilt")){
    ptmp <- (gdm_plot_pred[[i]][[j]])/(gdm_plot_var[[i]][[j]])
    ggsave(paste0("Figures/gdm_",j,"_",i,".png"),ptmp,width=12,height = 10)
    ptmp2 <- (gdm_var_contrib[[i]][[j]])
    ggsave(paste0("Figures/gdm_maxvar_",j,"_",i,".png"),ptmp2,width=4,height = 5)

  }
}
```

## pca mems
```{r}
PCA_withmems <- NULL
scree_plot_mems_list <- NULL
for(i in c("st","lt")){
  
  mems_df <- mems[,test$names[which(test$adj.pvalue<0.05)]]
  var2use <- get(paste0("var_",i))
  var2use <- c(names(mems_df),"ph",var2use)
  mems_df$Sample <- combined$Sample
  
  pca_tmp <- combined %>% 
    left_join(mems_df)%>%
    dplyr::select(all_of(var2use))%>%
    FactoMineR::PCA(scale.unit = T,
                    graph = F)
  
    eig <- pca_tmp$eig
    coord_pca <- as.data.frame(pca_tmp$ind$coord)
    coord_pca$site <- combined$Sample
    coord_pca$biome <- combined$BIOME_NAME

    mul <- arrowMul(as.data.frame(pca_tmp$var$coord),
                    pca_tmp$ind$coord)
    
    PCA_withmems[[i]] <- ggplot()+
        geom_point(coord_pca,mapping=aes(x=Dim.1,y=Dim.2,color=biome))+
        theme_classic2()+
        geom_vline(xintercept = 0,lty=2)+
        geom_hline(yintercept = 0,lty=2)+
        xlab(paste0("PC1 (",round(eig[1,2],2),"%)"))+
        ylab(paste0("PC2 (",round(eig[2,2],2),"%)"))+
        geom_segment(data= as.data.frame(pca_tmp$var$coord),aes(x = 0, y = 0, xend=mul*Dim.1, yend=mul*Dim.2),
                     lineend = "round", 
                     linejoin = "round",
                     linewidth = .75, 
                     arrow = arrow(length = unit(0.2, "inches")),
                     colour = "black" 
        )+
        geom_text(data = data.frame(var=rownames(pca_tmp$var$coord),pca_tmp$var$coord*mul), # add variable names at the end of arrows
                                 aes(x = Dim.1*1.1, # nudge a bit the coordinates so that they're not on the arrows
                                     y = Dim.2*1.1,
                                     label = var),
                                 max.overlaps = getOption("ggrepel.max.overlaps", default = 15))+
        ggtitle(paste0("Biplot sites ",i))+
        theme(plot.title = element_text(face="bold"))+
      scale_color_manual(values=biomes_color)
    
    scree_plot_mems_list[[i]] <- factoextra::fviz_screeplot(pca_tmp,barfill = "darkorchid4", barcolor="darkorchid4")
    ggsave(paste0("Figures/pca_mems_",i,".png"),PCA_withmems[[i]]+scree_plot_mems_list[[i]],width = 12)
}
```

## dbRDA mems

```{r}
dbrda_site_biplot_mems <- NULL
for(i in c("_lt","_st")){
  
  var_tmp <- colnames(combined)[which(grepl(i,colnames(combined)))]
  var_interest <- c("aet","pr","swe","tmmn","tmmx","vpd","elevation","evi","fpar","gpp","ph","soc")
  var_tmp <- var_tmp[which(gsub(i,"",var_tmp)%in%var_interest)]
  
  mems_df <- mems[,test$names[which(test$adj.pvalue<0.05)]]
  var_tmp <- c(names(mems_df),"ph",var_tmp)
  mems_df$Sample <- combined$Sample
  
  combined_tmp <- combined %>% 
    left_join(mems_df)
  
  for(j in c("filt","nonfilt")){
    
    if(j=="filt"){
      com_tmp <- get("meco_16s_relabfiltered")
    }else{
      com_tmp <- get("meco_16s_ns")
    }
    p_title <- paste0("dbRDA ",ifelse(i=="_lt","long term ","short term "), ifelse(j=="filt", "filtered","non filtered"))
    
    formula_tmp <- paste0("labdsv::hellinger(t(com_tmp$otu_table))~Condition(nb_reads)+",paste0(var_tmp, collapse = "+"))
    dbrda_tmp <- dbrda(formula=formula(formula_tmp),data=combined_tmp, distance="horn") # full model with morisita horn distance based on hellinger transformed data
    
    #get eigen values of axes
    eig <- c(dbrda_tmp$CCA$eig)
    eig1 <- round((eig[1]/sum(eig))*100,digits = 2) # % of explained inertia of the first axis
    eig2 <- round((eig[2]/sum(eig))*100,digits = 2) # % of explained inertia of the second axis
    
    fort_rda_tmp <- fortify(dbrda_tmp) # transform dbrda results in a ggplot2 usable format
    vars <- c("dbRDA1","dbRDA2") # we will plot in the first two dimensions
    want <- fort_rda_tmp[["score"]] == "biplot" # get variables scores (arrows)
    mul <- arrowMul(fort_rda_tmp[want, vars, drop = FALSE],
                    fort_rda_tmp[!want, vars, drop = FALSE]) # get the scaling factor to scale these scores for plotting as in ggvegan
    fort_rda_tmp[want, vars] <- mul * fort_rda_tmp[want, vars] # scale the scores 
    
    fort_rda_tmp%<>%
      mutate(label=gsub(i,"",label))%>%
      left_join(rename(names_df_clean,label=Var2))%>%
      mutate(midname=ifelse(is.na(midname),label,midname))
    
    dbrda_site_biplot_mems[[i]][[j]] <- ggplot(fort_rda_tmp, aes(x = dbRDA1, y = dbRDA2)) +
      geom_point(data = cbind(subset(fort_rda_tmp, score == "sites"), # add points (sites) corresponding to samples
                              country=combined$Country), 
                 aes(color = country), 
                 size = 3) +
      scale_color_manual(values = country_color)+
      geom_segment(data = subset(fort_rda_tmp, score == "biplot"), # add arrows for variables
                   aes(x = 0, y = 0, xend=dbRDA1, yend=dbRDA2),
                   lineend = "round", 
                   linejoin = "round",
                   linewidth = .75, 
                   arrow = arrow(length = unit(0.2, "inches")),
                   colour = "black" ) +
      coord_fixed()+ # fix proportion between axis units
      geom_text(data = fort_rda_tmp[want, , drop = FALSE ], # add variable names at the end of arrows
                aes(x = dbRDA1*1.2, # nudge a bit the coordinates so that they're not on the arrows
                    y = dbRDA2*1.2,
                    label = midname))+
      theme_classic()+
      xlab(paste0("dbRDA1 (",eig1,"%)"))+
      ylab(paste0("dbRDA2 (",eig2,"%)"))+
      guides(fill="none")  +
      geom_hline(yintercept=0,linetype = "dashed")+
      geom_vline(xintercept=0,linetype = "dashed")+
      ggtitle(formula_tmp)+
      theme(plot.title = element_text(face="bold"))+
      coord_fixed()+
      ggtitle(paste0(p_title," | contsrained: ", round(dbrda_tmp$CCA$tot.chi/dbrda_tmp$tot.chi,digits = 2)))
    
        ggsave(paste0("Figures/dbrda_mems_",i,"_",j,".png"),dbrda_site_biplot_mems[[i]][[j]],width = 8,height = 8)

  }
}
```

Enhance the proportion of constrained Variance of the model to add MEMs 

## Dist matrices

```{r}
mat_geo <- mat_geo
mat_bio <- vegdist(labdsv::hellinger(t(meco_16s_ns$otu_table)),"horn")
mat_eco <- vegdist(scale(combined[,c("ph",var_lt)]),"euclidean")
mat_ecost <- vegdist(scale(combined[,c("ph",var_st)]),"euclidean")

mt1 <- mantel(mat_geo,mat_bio)
mt2 <- mantel(mat_eco,mat_bio)
mt3 <- mantel(mat_ecost,mat_bio)

mantel_geo <- gghistogram(mt1$perm,fill = "darkgrey",color=NA)
df<- data.frame(x1=mt1$statistic,x2=mt1$statistic,y1=0,y2=layer_scales(mantel_geo)$y$range$range[2]*.25)

mantel_geo <- mantel_geo+
  geom_segment(df,mapping=aes(x = x1,xend = x2,y=y1,yend=y2))+
  geom_point(df,mapping=aes(x = x1,y=y2),shape=23,fill="darkorange2",size=4)+
  scale_y_continuous(expand = c(0,0))+
  xlab("Mantel simulation value (out of 999)")+
  geom_label(df,mapping=aes(x = x1,y=y2*1.5,label="Observed statistic"),color="darkorange2",size=4)+
  scale_x_continuous(expand = expansion(add=c(0,.15*mt1$statistic)))+
  ggtitle(paste0("Mantel test geo-bio | pval: ",mt1$signif))

mantel_eco <- gghistogram(mt2$perm,fill = "darkgrey",color=NA)
df2 <- data.frame(x1=mt2$statistic,x2=mt2$statistic,y1=0,y2=layer_scales(mantel_eco)$y$range$range[2]*.25)

mantel_eco <- mantel_eco+
  geom_segment(df2,mapping=aes(x = x1,xend = x2,y=y1,yend=y2))+
  geom_point(df2,mapping=aes(x = x1,y=y2),shape=23,fill="darkorange2",size=4)+
  scale_y_continuous(expand = c(0,0))+
  xlab("Mantel simulation value (out of 999)")+
  geom_label(df2,mapping=aes(x = x1,y=y2*1.5,label="Observed statistic"),color="darkorange2",size=4)+
  scale_x_continuous(expand = expansion(add=c(0,.15*mt2$statistic)))+  
  ggtitle(paste0("Mantel test eco-bio | pval: ",mt2$signif))


mantel_ecost <- gghistogram(mt3$perm,fill = "darkgrey",color=NA)
df3 <- data.frame(x1=mt3$statistic,x2=mt3$statistic,y1=0,y2=layer_scales(mantel_ecost)$y$range$range[2]*.25)

mantel_ecost <- mantel_ecost+
  geom_segment(df3,mapping=aes(x = x1,xend = x2,y=y1,yend=y2))+
  geom_point(df3,mapping=aes(x = x1,y=y2),shape=23,fill="darkorange2",size=4)+
  scale_y_continuous(expand = c(0,0))+
  xlab("Mantel simulation value (out of 999)")+
  geom_label(df3,mapping=aes(x = x1,y=y2*1.5,label="Observed statistic"),color="darkorange2",size=4)+
  scale_x_continuous(expand = expansion(add=c(0,.15*mt3$statistic)))+
  ggtitle(paste0("Mantel test ecost-bio | pval: ",mt3$signif))



ggsave("Figures/mantel.png",mantel_eco+mantel_geo+mantel_ecost+plot_spacer(),width=15,height =8)
```

Geography over env

## var part

```{r}
vlt <- varpart(labdsv::hellinger(t(meco_16s_ns$otu_table)),mems,combined[,c("ph",var_lt)])
plot(vlt)

vlt2 <- varpart(combined$nb_asvs,mems,combined[,c("ph",var_lt)])
plot(vlt2)

vlt3 <- varpart(mat_bio,mems,combined[,c("ph",var_lt)])
plot(vlt3)

pcnmtest <- pcnm(mat_geo)
vlt4 <- varpart(mat_bio,pcnmtest$vectors,combined[,c("ph",var_lt)])
plot(vlt4)
```

PCNM better than MEMs?


```{r}
vegan::cca(labdsv::hellinger(t(meco_16s_ns$otu_table)),mems,combined[,c("ph",var_lt)]);vegan::cca(labdsv::hellinger(t(meco_16s_ns$otu_table)),pcnmtest$vectors,combined[,c("ph",var_lt)])
```


## Spls Mixomics

```{r}
data_tmp <- meco_16s_relabfiltered
data_tmp <- clone(data_tmp)
mixomics_com <- t(data_tmp$otu_table)
library(mixOmics)
mixomics_plotlists <- NULL
for(i in c("lt","st")){
  
  mixomics_com <- mixomics_com[,which(colSums(mixomics_com!=0)!=1)] # remove samplewise singletons
  var <- get(paste0("var_",i))
  mydata <- list(df1 = cbind(combined[c("ph",var,"nb_reads")],pcnmtest$vectors),
                 df2 = mixomics_com) #Here you build your two datasets that should be integrated
  
  X <- mydata$df1 # use the gene expression data as the X matrix
  Y <- mydata$df2 # use the clinical data as the Y matrix
  
  dim(X) # check the dimensions of the X dataframe
  dim(Y)
  

  spls.holo <- spls(X = X, Y = Y, ncomp = 5, mode = 'regression')
  # repeated CV tuning of component count
  perf.spls.holo <- perf(spls.holo, validation = 'Mfold',
                         folds = 5, nrepeat = 100) 
  
  # set range of test values for number of variables to use from X dataframe
  list.keepX <- c(1:11)
  # set range of test values for number of variables to use from Y dataframe
  list.keepY <- c(20,30,40,seq(60,200,20),seq(350,ncol(Y),50)) 
  
  
  tune.spls.holo <- tune.spls(X, Y, ncomp = 3,
                              test.keepX = list.keepX,
                              test.keepY = list.keepY,
                              nrepeat = 100, folds = 5, # use 10 folds
                              mode = 'regression', measure = 'cor') 
 
  # extract optimal number of variables for X dataframe
  optimal.keepX <- tune.spls.holo$choice.keepX 
  
  # extract optimal number of variables for Y datafram
  optimal.keepY <- tune.spls.holo$choice.keepY
  
  optimal.ncomp <-  length(optimal.keepX) # extract optimal number of components
  
  # use all tuned values from above
  final.spls.holo <- spls(X, Y, ncomp = optimal.ncomp, 
                          keepX = optimal.keepX,
                          keepY = optimal.keepY,
                          mode = "regression") # explanitory approach being used, 
  # hence use regression mode
  
  
  # form new perf() object which utilises the final model
  perf.spls.holo <- perf(final.spls.holo, 
                         folds = 5, nrepeat = 100, # use repeated cross-validation
                         validation = "Mfold", 
                         dist = "max.dist",  # use max.dist measure
                         progressBar = FALSE)
  
  kept_motus <- final.spls.holo$loadings$Y%>%as.data.frame()%>%filter(comp1!=0|comp2!=0)%>%rownames(.)
  
  mixomics_plotlists[[i]][["init"]] <- spls.holo

  mixomics_plotlists[[i]][["perf"]] <- perf.spls.holo
  mixomics_plotlists[[i]][["tuned"]] <- tune.spls.holo
  
  mixomics_plotlists[[i]][["final"]] <- final.spls.holo
  
}
```

Plotting results
```{r}
perfplot <- (plot(mixomics_plotlists$lt$perf, criterion = 'Q2.total')+
  ggtitle("Perf plot long term"))/
  plot(mixomics_plotlists$st$perf, criterion = 'Q2.total')+
  ggtitle("Perf plot short term")

tuneplot <- (plot(mixomics_plotlists$lt$tuned, size.range = c(1,3))+
  ggtitle("Tuning plot long term"))/
  plot(mixomics_plotlists$st$tuned, size.range = c(1,3))+
  ggtitle("Tuning plot short term")+
  plot_layout(guides = "collect")

plot_stabz <- NULL
for(i in c("st","lt")){
stabX <- as.data.frame(mixomics_plotlists[[i]]$perf$features$stability.X)%>%
    mutate(features=rownames(.))%>%
    reshape2::melt()
stabY <- as.data.frame(mixomics_plotlists[[i]]$perf$features$stability.Y)%>%
    mutate(features=rownames(.))%>%
    reshape2::melt()

stabX_plot <- stabX%>%
  filter(value>0.65)%>%
  ggplot(aes(x=tidytext::reorder_within(features,-value,variable),y=value))+
  geom_bar(stat="identity",width = 1,color="white")+
  facet_wrap(.~variable,scales='free_x')+
  theme_classic2()+
  theme(axis.text.x = element_text(angle=45,hjust=1,vjust=1))+
  scale_y_continuous(expand=c(0,0))+
  ggtitle(paste0("Env variable",ifelse(i=="st"," Short term"," Long term")))+
  tidytext::scale_x_reordered() +
  xlab("")
stabY_plot <- stabY%>%
  filter(value>0.65)%>%
  ggplot(aes(x=tidytext::reorder_within(features,-value,variable),y=value))+
  geom_bar(stat="identity",width = 1,color="white")+
  facet_wrap(.~variable,scales='free_x')+
  theme_classic2()+
  theme(axis.text.x = element_text(angle=45,hjust=1,vjust=1))+
  scale_y_continuous(expand=c(0,0))+
  ggtitle("ASVs")+
  tidytext::scale_x_reordered()  +
  xlab("")

plot_stabz[[i]] <- stabX_plot/stabY_plot
}
plot_stabz[["lt"]]|plot_stabz[["st"]]

cutoff2use <- .4
plot_corcir <- NULL
store_corcir <- NULL
for(i in c("st","lt")){
  
  corcirvar <- plotVar(mixomics_plotlists[[i]]$final, cex = c(3,4), var.names = c(FALSE, TRUE))
  
  corcirvar%<>%
    mutate(Var2=gsub(paste0("_",i),"",rownames(.)))%>%
    left_join(names_df_clean)%>%
    mutate(fullname=ifelse(is.na(fullname),Var2,as.character(fullname)))%>%
    mutate(wellrep = ifelse(abs(x)>cutoff2use|abs(y)>cutoff2use,"yes","no"))%>%
    mutate(var_cat = ifelse(grepl("Cluster",fullname),"ASVs",'Environment'))
  store_corcir[[i]] <- corcirvar
  plot_corcir[[i]] <- ggplot(corcirvar, aes(x = x, y = y)) +
    ggforce::geom_circle(aes(x0=0,y0=0,r=1),color="black")+
    geom_point(data = filter(corcirvar,var_cat!="ASVs"),aes(color = var_cat),size=4,shape=17)+
    ggrepel::geom_text_repel(data =filter(corcirvar,var_cat!="ASVs"),aes(label=fullname,color = var_cat))+
    scale_color_manual(values =c(Environment= "darkcyan",
                                 ASVs="chocolate3"),                       
                       name="")+ 
    guides(color = guide_legend(override.aes = aes(label = "")))+
    ggnewscale::new_scale_color()+
    geom_point(data = filter(corcirvar,var_cat=="ASVs"), # add arrows for variables
               aes(color=var_cat,alpha=wellrep),size=3,shape=16) +
    scale_color_manual(values = "chocolate3",name="",label="ASVs")+
    scale_alpha_manual(values = c(.3,1),label = paste0(c("|cor|>","|cor|<"),cutoff2use), name = "ASVs correlation")+
    xlim(c(-1,1))+
    ylim(c(-1,1))+
    geom_vline(xintercept = 0,linetype="dashed")+
    geom_hline(yintercept = 0,linetype="dashed")+
    theme_classic2()+
    ylab("Component 2")+
    xlab("Component 1")+
    coord_fixed()+
    ggtitle(ifelse(i=="lt","Long term","Short term"))
}
plot_corcir$lt|plot_corcir$st+plot_layout(guides = "collect")


plot_hmap <- NULL
for(i in c("st","lt")){
  heatmap_data_mixom <- cim(mixomics_plotlists[[i]]$final, comp = 1:2, xlab = "clinic", ylab = "genes")
  corcirvar <- store_corcir[[i]]
  data <- heatmap_data_mixom$mat[gsub(paste0("_",i),"",heatmap_data_mixom$row.names)%in%corcirvar[corcirvar$var_cat!="ASVs","Var2"],corcirvar[corcirvar$var_cat=="ASVs","Var2"]]%>%
    as.data.frame()
  
  df_plot <- data %>%
    mutate(Env_var=gsub(paste0("_",i),"",rownames(.)))%>%
    reshape2::melt()%>%
    left_join(rename(names_df_clean,Env_var=Var2))%>%
    mutate(fullname=ifelse(is.na(fullname),Env_var,fullname))
           
  p2tmp <- df_plot%>%
    ggplot(aes(y=fullname,x=variable,fill=value))+
    geom_tile(color = "white",linewidth=.0001)+
    ylab('Environment')+
    theme(axis.text.x = element_text(angle = 90,vjust = .5,size=6),
          panel.background = element_blank(),
          legend.position = "right",
          axis.title = element_blank(),
          plot.margin = unit(c(0, 0, 0, 0), "lines"))+
    scale_fill_gradient2(low = "darkblue",mid = "lightyellow3", high = "#a30800",limits=c(-0.6,0.6),breaks=c(-.6,-.3,0,.3,.6))+
    scale_x_discrete(limits = colnames(data[,colnames(data)%in%df_plot$variable])[hclust(dist(t(data[,colnames(data)%in%df_plot$variable])))$order])+
    scale_y_discrete(limits = unique(left_join(data.frame(Env_var=gsub(paste0("_",i),"", rownames(data[gsub(paste0("_",i),"",rownames(data))%in%df_plot$Env_var,])[hclust(dist((data[gsub(paste0("_",i),"",rownames(data))%in%df_plot$Env_var,])))$order])),df_plot)$fullname))+
    ggtitle(ifelse(i=="st","Short term","Long term"))
  
  plot_hmap[[i]] <- p2tmp
}
```


## multiblock spls Mixomics

```{r}
library(mixOmics)
data_tmp <- meco_16s_relabfiltered
data_tmp <- clone(data_tmp)
mixomics_com <- t(data_tmp$otu_table)
cutoff2use <- .5
hmap_plot_list <- NULL
corcirplot_list <- NULL
ordered_list <- NULL
corcirplot_list_module <- NULL
for(i in c("lt","st")){
  
  mixomics_com <- mixomics_com[,which(colSums(mixomics_com!=0)!=1)] # remove samplewise singletons
  var_tmp <- get(paste0("var_",i))
  mixomics_com <- labdsv::hellinger(mixomics_com)
  
  mydata <- list(df1 = combined[c("ph",var_tmp,"nb_reads")],
                 df2 = mixomics_com,
                 df3 = pcnmtest$vectors) #Here you build your two datasets that should be integrated
  
  lapply(mydata, dim) # check dimensions
  
  rownames(mydata$df1) <- combined$Sample
  rownames(mydata$df2) <- gsub("[A-Z]|-|(?=_).*","",rownames(mixomics_com),perl = T)
  mydata$df2 <- mydata$df2[match(rownames(mydata$df1),rownames(mydata$df2)),]
  rownames(mydata$df3) <- combined$Sample
  
  basic.mbspls.model <- block.spls(mydata, indY = 1, # generate basic model
                                   ncomp = 5)
  
  choice.ncomp <- 5
  # choice.keepX <- list(df1 = rep(11,5), 
  #                    df2 = rep(c(1:15,seq(16,100,5),seq(101,822,30),822),5), 
  #                    df3 = rep(c(seq(1,35,5),34)),5)
  
  choice.keepX <- list(df1 = rep(11, 5), 
                       df2 = rep(50, 3), 
                       df3 = rep(15, 3))
  
  final.mbspls.model <-  block.spls(mydata, indY = 1,  
                                    ncomp = choice.ncomp, 
                                    keepX = choice.keepX)
  
  data_var <- plotVar(final.mbspls.model,var.names = T,
                      legend = TRUE, cutoff = 0,
                      pch = c(0,1,2))
  corcirvar <- data_var
  corcirvar%<>%
    mutate(names=rownames(.))%>%
    mutate(names=gsub(paste0("_",i),"",names))%>%
    left_join(rename(names_df_clean,names=Var2))%>%
    mutate(midname=ifelse(is.na(midname),names,midname))%>%
    mutate(var_cat=ifelse(grepl("Cluster",names),"ASVs",
                          ifelse(grepl("PCNM",names),"PCNMs","Variables")))%>%
    mutate(var_cat=as.factor(var_cat))%>%
    mutate(wellrep = ifelse(abs(x)>cutoff2use|abs(y)>cutoff2use,"yes","no"))%>%
    left_join(rename(net2$res_node_table,names=name))
  
  corcirplot_list[[i]] <- ggplot(corcirvar, aes(x = x, y = y)) +
    ggforce::geom_circle(aes(x0=0,y0=0,r=1),color="black")+
    geom_point(data = filter(corcirvar,var_cat=="ASVs"), # add arrows for variables
               aes(color=var_cat,alpha=wellrep),size=3,shape=16) +
    scale_color_manual(values = "darkred",name="",label="ASVs")+
    scale_alpha_manual(values = c(.3,1),label = paste0(c("|cor|>","|cor|<"),cutoff2use), name = "OTUs correlation")+
    ggnewscale::new_scale_color()+
    geom_point(data = filter(corcirvar,var_cat!="ASVs"&wellrep=="yes"),aes(color = var_cat),size=4,shape=17)+
    ggrepel::geom_text_repel(data =filter(corcirvar,var_cat!="ASVs"&wellrep=="yes"),aes(label=midname,color = var_cat))+
    scale_color_manual(values =c(PCNMs= "darkcyan",
                                 Variables="darkolivegreen4"), 
                       name="Variable categories")+ 
    guides(color = guide_legend(override.aes = aes(label = "")))+
    xlim(c(-1,1))+
    ylim(c(-1,1))+
    geom_vline(xintercept = 0,linetype="dashed")+
    geom_hline(yintercept = 0,linetype="dashed")+
    theme_classic2()+
    ylab("Component 2")+
    xlab("Component 1")+
    coord_fixed()+
    ggtitle(ifelse(grepl("lt",i),"Long term","Short term"))
  
  corcirplot_list_module[[i]] <- ggplot(corcirvar, aes(x = x, y = y)) +
    ggforce::geom_circle(aes(x0=0,y0=0,r=1),color="black")+
    geom_point(data = filter(corcirvar,var_cat=="ASVs"), # add arrows for variables
               aes(color=module,alpha=wellrep),size=3,shape=16) +
    scale_color_manual(values = module_col,name="Modules")+
    scale_alpha_manual(values = c(.3,1),label = paste0(c("|cor|>","|cor|<"),cutoff2use), name = "OTUs correlation")+
    ggnewscale::new_scale_color()+
    geom_point(data = filter(corcirvar,var_cat!="ASVs"&wellrep=="yes"),aes(color = var_cat),size=4,shape=17)+
    ggrepel::geom_text_repel(data =filter(corcirvar,var_cat!="ASVs"&wellrep=="yes"),aes(label=midname,color = var_cat))+
    scale_color_manual(values =c(PCNMs= "darkcyan",
                                 Variables="darkolivegreen4"), 
                       name="Variable categories")+ 
    guides(color = guide_legend(override.aes = aes(label = "")))+
    xlim(c(-1,1))+
    ylim(c(-1,1))+
    geom_vline(xintercept = 0,linetype="dashed")+
    geom_hline(yintercept = 0,linetype="dashed")+
    theme_classic2()+
    ylab("Component 2")+
    xlab("Component 1")+
    coord_fixed()+
    ggtitle(ifelse(grepl("lt",i),"Long term","Short term"))
  
  
  hmap_data_list <- list(hmap_data12=cim(final.mbspls.model,blocks = c('df1','df2')),
                         hmap_data13=cim(final.mbspls.model,blocks = c('df1','df3')),
                         hmap_data23=cim(final.mbspls.model,blocks = c('df2','df3')))
  
  for(j in names(hmap_data_list)){
    
    hmap_data_tmp <-hmap_data_list[[j]]
    
    data <- hmap_data_tmp$mat[which(rownames(hmap_data_tmp$mat)%in%rownames(data_var)),which(colnames(hmap_data_tmp$mat)%in%rownames(data_var))]%>%
      as.data.frame()
    df_plot <- data %>%
      mutate(Var=rownames(.))%>%
      reshape2::melt()
    
    hmap_plot_list[[i]][[j]] <-   df_plot%>%
      ggplot(aes(y=Var,x=variable,fill=value))+
      geom_tile(color = NA,linewidth=.0001)+
      ylab('Var')+
      theme(axis.text.x = element_text(angle = 90,vjust = .5,size=6),
            panel.background = element_blank(),
            legend.position = "right",
            axis.title = element_blank(),
            plot.margin = unit(c(0, 0, 0, 0), "lines"))+
      scale_fill_gradient2(low = "darkblue",mid = "lightyellow3", high = "#a30800")+
      scale_x_discrete(limits = colnames(data[,colnames(data)%in%df_plot$variable])[hclust(dist(t(data[,colnames(data)%in%df_plot$variable])))$order])+
      scale_y_discrete(limits = rownames(data[rownames(data)%in%df_plot$Var,])[hclust(dist((data[rownames(data)%in%df_plot$Var,])))$order])
    ordered_list[[i]][[j]][["colnames"]] <- colnames(data[,colnames(data)%in%df_plot$variable])[hclust(dist(t(data[,colnames(data)%in%df_plot$variable])))$order]
    
    ordered_list[[i]][[j]][["rownames"]] <- rownames(data[rownames(data)%in%df_plot$Var,])[hclust(dist((data[rownames(data)%in%df_plot$Var,])))$order]
  }
}
```

```{r}
ggsave("Figures/multispls_corcirvar.png",corcirplot_list$lt+corcirplot_list$st,width=15,height = 9)
ggsave("Figures/multispls_hmap.png",hmap_plot_list$lt$hmap_data12+hmap_plot_list$lt$hmap_data13+hmap_plot_list$lt$hmap_data23+hmap_plot_list$st$hmap_data12+hmap_plot_list$st$hmap_data13+hmap_plot_list$st$hmap_data23+plot_layout(widths = c(1,1,1),heights = c(1,1)),width=21,height = 16)


ggsave("Figures/multispls_corcirvar_module.png",corcirplot_list_module$lt+corcirplot_list_module$st,width=15,height = 9)
```


```{r}
hmap_data_list$hmap_data12$mat%>%View
layer_scales(hmap_plot_list$lt$hmap_data12)$x$range$range
```



##comp with countries

```{r}
    combined$distfrom01 <- c(0,distfrom01)

plots_comp <- NULL
for( i in c("Order_conf_rdp","Genus_conf_rdp")){
  for(j in c("meco_16s_ns","meco_16s_relabfiltered")){
    tmp16s <- clone(get(j))
    tmp16s$sample_table %<>% mutate(dumb_group = "sample")
    tmp16s$otu_table %<>% filter(rowSums(.)>1)
    tmp16s$tidy_dataset()
    
    tmp16s$cal_abund()
    tmp16s1 <- trans_abund$new(tmp16s,taxrank = i,ntaxa = 8,groupmean = "dumb_group")
    
    plot_data1 <- tmp16s1$data_abund
    use_taxanames <- tmp16s1$data_taxanames
    plot_data1$Taxonomy[!plot_data1$Taxonomy %in% c(use_taxanames,"unidentified")] <- "Others"
    plot_data1 %<>% 
      dplyr::group_by(!!!syms(c("Taxonomy","Sample"))) %>% 
      dplyr::summarise(Abundance = sum(Abundance)) %>% 
      as.data.frame(stringsAsFactors = FALSE)
    plot_data1$Taxonomy %<>% factor(., levels = c(use_taxanames[-9], "Others","unidentified"))
    plot_data1$label <- paste0(round(plot_data1$Abundance, 1),"%")
    donut_comp <- ggdonutchart(plot_data1,"Abundance",
                               fill="Taxonomy",
                               label = "label",
                               color = "white",
                               palette =  c(colorRampPalette(brewer.pal(8, "Dark2"))(9),"lightgrey"),
                               guide = guide_legend(reverse = TRUE) )+
      theme(legend.position = "right")
    
    tmp16s2 <- trans_abund$new(tmp16s,taxrank = i,ntaxa = 8)
    plot_data2 <- tmp16s2$data_abund
    plot_data2$Taxonomy[!plot_data2$Taxonomy %in% c(use_taxanames,"unidentified")] <- "Others"
    plot_data2$Taxonomy %<>% factor(., levels = rev(c(use_taxanames[-9], "Others","unidentified")))
    plot_data2 <- left_join(plot_data2,rename(combined[,c("sample_id","distfrom01","BIOME_NAME")],Sample=sample_id))
    plot_data2%<>%
      mutate(Sample=as.factor(Sample))%>%
      mutate(Sample=fct_relevel(Sample,unique(as.character(Sample))))
    bar_comp <- (plot_data2%>%
      ggplot(aes(x=Sample,y=Abundance,fill=Taxonomy),color=NA)+
      geom_bar(stat = "identity",width=1,position='fill')+
      scale_fill_manual(values =  rev(c(colorRampPalette(brewer.pal(8, "Dark2"))(9),"lightgrey")),
                        guide = guide_legend(reverse = TRUE) )+
      scale_y_continuous(expand = c(0,0))+
      theme(axis.text.x = element_blank(),
            axis.ticks.x = element_blank(),
            plot.margin = unit(c(0,0,0,0),units="mm"),
            axis.title.x = element_blank()))/(
    ggplot(plot_data2,aes(x=Sample,y=1,fill=Country))+
      geom_tile()+
      scale_fill_manual(values=country_color)+
      theme_void())+plot_layout(guides="collect",heights = c(9,1))
    
    
    
    plots_comp[[i]][[j]] <- donut_comp + bar_comp  +  plot_annotation(title = ifelse(j=="meco_16s_ns","No singletons","Filtered at 5% relative abundance")) & theme(plot.title = element_text(face='bold'))
  }
}
```

```{r}
ggsave("Figures/comp_order_ns_country.png",plots_comp$Order_conf_rdp$meco_16s_ns,width = 14)
ggsave("Figures/com_genus_ns_country.png",plots_comp$Genus_conf_rdp$meco_16s_ns,width = 14)
ggsave("Figures/comp_order_filt_country.png",plots_comp$Order_conf_rdp$meco_16s_relabfiltered,width = 14)
ggsave("Figures/com_genus_filt_country.png",plots_comp$Genus_conf_rdp$meco_16s_relabfiltered,width = 14)
```

